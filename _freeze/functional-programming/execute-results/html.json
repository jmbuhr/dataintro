{
  "hash": "0788765193b0dfa71bffc361751bc09a",
  "result": {
    "markdown": "# Functional Programming\n\n\n\n\n\n> ... which is all about functions, bringing the whole tidyverse together and\n  exploring advanced dplyr data wrangling techniques.\n\n\n{{< youtube B2RRRpjX1QU >}}\n\n\n\n## Todays goal\n\nMy goal today is to bring together everything\nwe learned so far and solidify\nour understanding of wrangling data in the tidyverse.\nIf all goes according to plan,\nwe will then have more mental capacity\nfreed up for the statistics starting next week.\nAnd our understanding of data will hopefully\nenable us to experiment and play with statistical\nconcepts without getting stuck too much\non data wrangling.\nThis also means that today's lecture might\nbe the most challenging so far, because\neverything learned up until now will -- in\none way or another -- be relevant.\n\nBut first, we load the libraries for today as usual.\nNote, that I am cheating a bit here by loading\nthe `gapminder` package as well.\nEven though we will be reading in actual `gapminder` dataset\nagain from files today, having access to\nthe vector of country colors is nice to have.\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-2_e58303939c821752b2b0b9e32ddf02a1'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(gapminder)\n```\n:::\n\n\nIn the lecture I also quickly go over some\nof the most important [resources](Resources) so far.\nThis mostly concerns the pure R resources,\nI will cover the resources for statistics and some of the maths\ninvolved in the next couple of lectures.\n\nAs you might be able to tell,\nmental models are one of my favorite topics.\nWe are starting today with a powerful mental model:\n**iteration**.\n\n## Iteration\n\nIteration is the basic idea of doing one thing multiple times.\nThis is an area where computers shine,\nso in this chapter we will learn to fully utilize the power at our fingertips. \n\nAs an example, we will be reading in multiple similar files.\nRemember the `gapminder` dataset?\nWell, we are working with it again,\nbut this time, our collaborator sent us one csv-file for each continent.\nYou can find them in the `data/04/` folder.\n\nWe already know how to read in *one* csv-file:\n  \n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-3_ff2cc8e4b4c025dfd4ac6068951c36e4'}\n\n```{.r .cell-code}\nread_csv(\"./data/04/Africa.csv\")\n```\n:::\n\n\n### The Imperative Programming Approach\n\nThe first solution to our problem is not my favorite one,\nbut I want to show it anyway for the sake of completeness.\nIn general, in Functional Programming, we **tell the computer what we want**, while in Imperative Programming, we **tell the computer what steps to do**.\nSo here, we tell R what steps to perform.\nFirst, we get a vector of file-path's with\nthe `fs` package, which stands for _file system_.\n`dir_ls` means _directory list_, so we get the\ncontents of a directory.\nWe then create a list to store the dataframes that we are\ngoing to read in.\nWe already define the length of the list because\nmaking a data structure longer is not R's strong suit when\nit doesn't know how much space to reserve for it.\nWe then iterate over the numbers from 1 to the length\nof our `paths`.\nAt each iteration we get the `i`s path, read it and store\nit in our results list at position `i`.\nFinally we bind the list into one dataframe:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-4_477c394513f5fa3c6d8cb0b8ddd04e27'}\n\n```{.r .cell-code}\npaths <- fs::dir_ls(\"./data/04/\")\n\nresult <- vector(mode = \"list\", length = length(paths))\nfor (i in 1:length(paths)) {\n  result[[i]] <- read_csv(paths[i])\n}\n\nbind_rows(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 × 5\n   country  year lifeExp      pop gdpPercap\n   <chr>   <dbl>   <dbl>    <dbl>     <dbl>\n 1 Algeria  1952    43.1  9279525     2449.\n 2 Algeria  1957    45.7 10270856     3014.\n 3 Algeria  1962    48.3 11000948     2551.\n 4 Algeria  1967    51.4 12760499     3247.\n 5 Algeria  1972    54.5 14760787     4183.\n 6 Algeria  1977    58.0 17152804     4910.\n 7 Algeria  1982    61.4 20033753     5745.\n 8 Algeria  1987    65.8 23254956     5681.\n 9 Algeria  1992    67.7 26298373     5023.\n10 Algeria  1997    69.2 29072015     4797.\n# ℹ 1,694 more rows\n```\n:::\n:::\n\n\nIn doing this we have lost the information about the `Continent`,\nwhich was in the file name,\nbut before dwelling on this for too long, let's leave the more convoluted and manual way behind and explore a,\nI dare say, more elegant approach.\n\n### The Functional Programming Approach\n\n> \"Of course someone has to write for-loops.\n  It doesn't have to be you.\"\n> --- Jenny Bryan\n\n<aside>\n<a href=\"https://purrr.tidyverse.org/\">\n![](images/purrr.png){width=200}\n</a>\n</aside>\n\nWe have a function (`read_csv`) that **takes** a file path and **returns**\n(spits out) the data.\nIn the Functional Programming style,\nthe next idea is to now have a function, that takes two things:\nvector (atomic or list) and a function.\nAnd it feeds the individual elements of the vector to the function,\none after another.\nIn mathematics, the relation between a set of inputs and a set of outputs is called a **map**,\nwhich is where the name of the following family of functions comes from.\nIn the tidyverse, these functional programming concepts live in the `purrr` package.\n\nIterating **Explicitly** with `map`s:\n\nFirst, we create the vector of things that we want to iterate over, the things\nthat will be fed into our function one after the other:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-5_4e8bf3bf21e0396f0fbfc24507a5418a'}\n\n```{.r .cell-code}\npaths <- fs::dir_ls(\"./data/04/\")\n```\n:::\n\n\nThen we map the `read_csv` function over our vector\nand bind the resulting list of dataframes into one dataframe:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-6_4634ef1198509d88f081df8a4c8c0a3e'}\n\n```{.r .cell-code}\nresult <- map(paths, read_csv)\nbind_rows(result)\n```\n:::\n\n\nThe operation of mapping over a vector and combining the resulting\nlist into one dataframe is actually so common that\nthere is a variant of `map` that does this step automatically:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-7_b652b6853001767e294e1d60a118311d'}\n\n```{.r .cell-code}\nmap_df(paths, read_csv, .id = \"continent\")\n```\n:::\n\n\nThis distills everything our initial for-loop did into just one line of code.\nUsing the `.id` argument we can save the name of the file path\nto a column in our dataset.\nThis allows us to extract the continent from it:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-8_81398211ae478707127a57071e2114a4'}\n\n```{.r .cell-code}\ngapminder <- map_df(paths, read_csv, .id = \"continent\") %>% \n  mutate(continent = str_extract(continent, \"(?<=/)\\\\w+(?=\\\\.csv)\"))\n\nhead(gapminder)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 6\n  continent country  year lifeExp      pop gdpPercap\n  <chr>     <chr>   <dbl>   <dbl>    <dbl>     <dbl>\n1 Africa    Algeria  1952    43.1  9279525     2449.\n2 Africa    Algeria  1957    45.7 10270856     3014.\n3 Africa    Algeria  1962    48.3 11000948     2551.\n4 Africa    Algeria  1967    51.4 12760499     3247.\n5 Africa    Algeria  1972    54.5 14760787     4183.\n6 Africa    Algeria  1977    58.0 17152804     4910.\n```\n:::\n:::\n\n\nMy way of extracting the continent from the file path seems magical at first,\nand I still refer to the cheat sheet of the `stringr` package a lot\nwhen I am having to deal with text:\n\n<aside>\n<a href=\"https://stringr.tidyverse.org/\">\n![](images/stringr.png){width=200}\n</a>\n</aside>\n\nIterating **implicitly** with vectorized functions:\n\nWe had our first encounter with iteration in a very implicit form.\nWhen we use\nR's basic math operators, the computer is iterating behind the scenes.\nTake this expression:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-9_23fef10451f1acaabaf7b92e02b88217'}\n\n```{.r .cell-code}\n1:3 + 1:3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2 4 6\n```\n:::\n:::\n\n\nThis operation is vectorized.\nWithout us having to tell R to do so, R will add the first element of the first vector to the first element of the second vector and so forth.\n\nNotice, how it looks like the operation happens all at the same time.\nBut in reality, this is not what happens.\nThe computer is just really fast at adding numbers, one after the other.\n\nThe mathematical operations in R call another programming language that does the\nactual addition.\nThis other programming language is closer to the way computers *think*,\nmaking it less fun to write for us humans,\nbut also faster because the instructions are easier to translate into actions for our computer processor.\n\nRemember, we only have to build our own iteration (e.g. with a `map` function),\nwhen we find a task that we want to apply to multiple things,\nand that is not already vectorized.\nAnd as it turns out, the `fs` and `readr` packages play very\nwell together, because `readr` can also just take a vector\nof file paths and does the combining automatically!\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-10_b792f3ae149d89ba1657c8bb99879bc1'}\n\n```{.r .cell-code}\nread_csv(paths, id = \"continent\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,704 × 6\n   continent            country  year lifeExp      pop gdpPercap\n   <chr>                <chr>   <dbl>   <dbl>    <dbl>     <dbl>\n 1 ./data/04/Africa.csv Algeria  1952    43.1  9279525     2449.\n 2 ./data/04/Africa.csv Algeria  1957    45.7 10270856     3014.\n 3 ./data/04/Africa.csv Algeria  1962    48.3 11000948     2551.\n 4 ./data/04/Africa.csv Algeria  1967    51.4 12760499     3247.\n 5 ./data/04/Africa.csv Algeria  1972    54.5 14760787     4183.\n 6 ./data/04/Africa.csv Algeria  1977    58.0 17152804     4910.\n 7 ./data/04/Africa.csv Algeria  1982    61.4 20033753     5745.\n 8 ./data/04/Africa.csv Algeria  1987    65.8 23254956     5681.\n 9 ./data/04/Africa.csv Algeria  1992    67.7 26298373     5023.\n10 ./data/04/Africa.csv Algeria  1997    69.2 29072015     4797.\n# ℹ 1,694 more rows\n```\n:::\n:::\n\n\nWhenever you encounter a new problem, ask yourself these questions:\n\n- Is there a function that already does that?\n- Is it already vectorized?\n- If not, is there a function that solves my problem for one instance?\n- Can I map it over many things?\n\nThe `purrr` package contains various variants of the `map` function.\n\n- `map` itself will always return a list.\n- `map_chr` always returns an atomic character (=text) vector.\n- `map_dbl` always returns numbers (dbl = double precision).\n- `map_lgl` always returns logical (yes or no, TRUE / FALSE) vectors.\n- `map_dfr` always returns a dataframe.\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-11_378381c445ededbba7235a366f9409d3'}\n\n```{.r .cell-code}\n# map_\n```\n:::\n\n\nThe for-loop-version had a lot more code, especially *boilerplate*, code that is just there to make the construct work and doesn't convey our intentions with the\ncode.\nFurthermore, the loop focuses the object that is iterated over (the file\npaths), while the `map`-version focuses on what is happening (the function, `read_csv`).\nBut the loop still works.\nIf you can't think of a way to solve a problem with a `map` function, it is absolutely OK to use for-loops.\n\n\n## \"If you copy and paste the same code more than three times, write a function.\"\n\nWriting our own functions can be very helpful for making our\ncode more readable.\nIt allows us to separate certain steps of your analysis\nfrom the rest, look at them in isolation to test and\nvalidate them, and also allows us to give them reasonable names.\n\nIt also allows us to re-use function across projects!\nLet's imagine we have some experiment where the read-out\nof the machine is always in a certain format and needs some\ncleaning up.\nIf we turn this into a function, e.g. like this:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-12_c13693f8b1e7e01c552f065130f618de'}\n\n```{.r .cell-code}\nread_experiment_data <- function(day) {\n  day <- str_pad(day, pad = 0, width = 2)\n  paths <- fs::dir_ls(paste0(\"./data/\",day,\"/\"))\n\n  gapminder <- map_df(paths, read_csv, .id = \"continent\") %>% \n    mutate(continent = str_extract(continent, \"(?<=/)\\\\w+(?=\\\\.csv)\"))\n\n  gapminder\n}\n```\n:::\n\n\nWe can put this function in a file (in my case `R/my_functions`)\nand `source` it, for example in multiple analysis Rmarkdown documents.\nThe `source` function is nothing special, it just runs the R\ncode in a file.\nAnd when we define functions in this file, those functions\nare then available to us:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-13_770d40c1ac5ac963b602b3b12e1438bf'}\n\n```{.r .cell-code}\nsource(\"R/my_functions.R\")\nread_experiment_data(4)\n```\n:::\n\n\nNote: This example function only make sense to use with\n`4` as the input, as the data for the other days\nis of course different, but I hope you get the gist.\n\nI like to store my regular R files (as opposed to Rmd files)\nin a folder of my project called `R`.\nThis makes it already look like an R package,\nin case I decide later on that the functions\ncould be helpful for others as well\nor I want to share them more easily\nwith colleagues.\nYou can read more about creating your\nown R packages [here](http://r-pkgs.had.co.nz/)\n[@wickhamPackagesOrganizeTest2015].\n\n## Implicit iteration with `dplyr`: build many models\n\n`dplyr`s idea of grouping allows us to express many\nideas that are implicitly also iterations.\n\nLet us start by looking at just one country at first:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-14_7b7be09dfa08462e39fc0a4f854c196f'}\n\n```{.r .cell-code}\nalgeria <- gapminder %>% \n  filter(country == \"Algeria\")\n```\n:::\n\n\nWe can plot the life expectancy over time with ggplot\nand add a **linear model** to our plot with\n`geom_smooth` using `method = \"lm\"`.\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-15_d2bb8225c3266e3a605950d7c97440aa'}\n\n```{.r .cell-code}\nalgeria %>% \n  ggplot(aes(year, lifeExp)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](functional-programming_files/figure-html/unnamed-chunk-15-1.png){width=100%}\n:::\n:::\n\n\nHowever, while `geom_smooth` allows us to easily add smoothing\nlines or linear trends to our plot, it does not\ngive us any information about the actual model.\nIn order to do that we need to fit it ourselves\nwith the `lm` function:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-16_5b6e50bd34a71224903cdc7e25bc8c3c'}\n\n```{.r .cell-code}\nmodel <- lm(lifeExp ~ year, data = algeria)\n```\n:::\n\n\nThe `~` symbol defines a _formula_, you can read it as:\n\"lifeExp depending on year\".\nThe `data` argument tells R where to look for the variables\n`lifeExp` and `year`, namely in our `algeria` tibble.\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-17_51ae640d07f126127114ec5550468ad7'}\n\n```{.r .cell-code}\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = lifeExp ~ year, data = algeria)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3844 -0.5935 -0.2703  0.5339  2.4992 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.068e+03  4.380e+01  -24.38 3.07e-10 ***\nyear         5.693e-01  2.213e-02   25.73 1.81e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.323 on 10 degrees of freedom\nMultiple R-squared:  0.9851,\tAdjusted R-squared:  0.9836 \nF-statistic: 661.9 on 1 and 10 DF,  p-value: 1.808e-10\n```\n:::\n:::\n\n\nThat is a lot of information about our model!\nThe `broom` package provides some functions for a cleaner\nand more specialized output:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-18_8889beff7255cc57c819278493504cd3'}\n\n```{.r .cell-code}\nbroom::tidy(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept) -1068.      43.8        -24.4 3.07e-10\n2 year            0.569    0.0221      25.7 1.81e-10\n```\n:::\n:::\n\n\nEvery 1 year the life expectancy in Algeria went up by about half a year.\nOf course, this is only valid in the limited linear regime of\nour datapoints.\nWe can't extrapolate this indefinitely.\nAfter all, the intercept tells us that there would be a negative\nlife expectancy at year 0.\n\nBut given the data that we have, how good does a line fit here?\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-19_d8695e52e3338d6769b06c53b1862b9a'}\n\n```{.r .cell-code}\nbroom::glance(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.985         0.984  1.32      662. 1.81e-10     1  -19.3  44.6  46.0\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\n\nR^2^ takes on values between 0 and 1, with 1 being a perfectly\nstraight line connecting all the points and 0 for the points\nbeing all over the place.\nSo 0.985 is a pretty good fit!\n\nUsing the dollar syntax, we get pull one column from\na tibble, so we can write a function that, given a model,\nreturns the R^2^\n\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-20_b7ee18e5bd31c9cbc66d25418243cb49'}\n\n```{.r .cell-code}\nget_r_squared <- function(model) {\n  broom::glance(model)$r.squared\n}\n```\n:::\n\n\nAnd now come the `dplyr` magic!\nIf we group by `country` (and `continent` for good measuere\njust so that we don't loose that column when summarizing),\nwe can calculate a linear model for every country!\n\nNote two things: Firstly, we don't use the `data` argument\nof `lm` here because the tidyverse functions already know\nwhere to look for `lifeExp` and `year` and they do so\n**respecting the groups**.\nSo within each group (i.e. for each country), `lifeExp` will only contain the life expectancy for that country,\nnot the life expectancy for all countries.\nSecondly, we wrap this part in `list` because we have\nto create a list column here (models don't fit into an atomic vector).\nOtherwise, `dplyr` will complain.\n\nIn the second step we calculate the `rsqured` value\nfor each model by mapping the function we created above\nover all models.\nWe use the `_dbl` variant here because we want the values\nas an atomic vector of numbers, not as a list.\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-21_56e2868c1cc92b3e6ddec870e8f4d7c5'}\n\n```{.r .cell-code}\nall_models <- gapminder %>% \n  group_by(country, continent) %>% \n  summarise(\n    model = list(lm(lifeExp ~ year)),\n    rsquared = map_dbl(model, get_r_squared)\n  )\n\nhead(all_models)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 4\n# Groups:   country [6]\n  country     continent model  rsquared\n  <chr>       <chr>     <list>    <dbl>\n1 Afghanistan Asia      <lm>      0.948\n2 Albania     Europe    <lm>      0.911\n3 Algeria     Africa    <lm>      0.985\n4 Angola      Africa    <lm>      0.888\n5 Argentina   Americas  <lm>      0.996\n6 Australia   Oceania   <lm>      0.980\n```\n:::\n:::\n\n\nFinally, we can add our calculated R^2^ values as a column to\nthe original gapminder dataset so that we can use it\nin the following visualization.\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-22_3b3c6f793f6e38812ee5c3d055e4d1a3'}\n\n```{.r .cell-code}\ngapminder <- gapminder %>% \n  left_join(select(all_models, -model))\n```\n:::\n\n\nHere, we highlight the irregularities (less linear countries)\nby making the transparency (= alpha value) depend\non the R^2^ value.\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-23_5f35205568ec28ec3d30dfe899c913ca'}\n\n```{.r .cell-code}\ngapminder %>% \n  ggplot(aes(year, lifeExp, color = country, alpha = 1/rsquared)) +\n  geom_line() +\n  guides(color = \"none\", alpha = \"none\") +\n  scale_color_manual(values = country_colors) +\n  facet_wrap(~continent, scales = \"free\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](functional-programming_files/figure-html/unnamed-chunk-23-1.png){width=100%}\n:::\n:::\n\n\nWe can highlight one continent by filtering and use the\n`ggrepel` package to allow for more flexible labels.\nFurthermore check out the source document of this lecture\nand the video of the lecture to find out how you can\nadd a figure caption and control the width and height\nof the plot via `knitr` chunk options.\nI also showcase a new way of writing chunk options\nin the latest version of the `knitr` package that is especially\nsuited for longer captions.\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-24_d7e242b433bc93207329c726025cb316'}\n\n```{.r .cell-code}\ngapminder %>% \n  filter(continent == \"Africa\") %>% \n  ggplot(aes(year, lifeExp, color = country, group = country)) +\n  geom_line(color = \"black\", alpha = 0.3) +\n  geom_line(data = filter(gapminder, rsquared <= 0.4), size = 1.1) +\n  ggrepel::geom_text_repel(aes(label = country),\n                           data = filter(gapminder, rsquared <= 0.4,\n                                         year == max(year)),\n                           nudge_x = 20,\n                           direction = \"y\"\n                           ) +\n  guides(color = \"none\", alpha = \"none\") +\n  scale_color_manual(values = country_colors) +\n  facet_wrap(~continent, scales = \"free\") +\n  labs(x = \"Year\", y = \"Life Expectancy at Birth\") +\n  theme_minimal() +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.2)))\n```\n\n::: {.cell-output-display}\n![Figure caption](functional-programming_files/figure-html/unnamed-chunk-24-1.png){width=100%}\n:::\n:::\n\n\nThe downward slope of our highlighted countries\nstarting in the 1990s is a result of the ravaging\nAIDS pandemic.\nThe prominent dips in two of the curves, orange for\nRwanda and Cambodia in gray, are the direct\nconsequences of genocides.\nThese dire realities can in no way be summarized\nin just a couple of colorful lines.\nI am also in no way qualified to lecture\non these topics.\nA good friend of mine, Timothy Williams,\nhowever is a researcher and teacher in the field of conflict and violence\nwith a focus on genocides.\nHe did field work in Cambodia and Rwanda\nand his book \"The Complexity of Evil. Perpetration and Genocide\" was [published here](https://www.rutgersuniversitypress.org/the-complexity-of-evil/9781978814295) on December 18 2020 [@williamsComplexityEvil].\n\n## Exercises\n\nI want to get you playing around with data,\nso keep in mind that the solutions for this exercise \nare not set in stone.\nThere is often more than one viable way of graphing\nthe same dataset and we will use the\nOffice Hour to talk about the advantages\nand disadvantages of approaches that you\ncame up with.\n\n### Roman emperors\n\nThe first exercise uses a dataset about roman emperors\nfrom the tidytuesday project\n([link](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-08-13)).\nYou can import it with:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-25_5f3db0564fc6c0fe070b1c41683df62d'}\n\n```{.r .cell-code}\nemperors <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv\")\n```\n:::\n\n\nThere is a slight error in the data because some of the dates are actually in BC time.\nIn order to fix this we will be using the [lubridate](https://lubridate.tidyverse.org/) package,\nwhich is installed with the tidyverse, but not automatically loaded.\nFor your convenience here is a function that you can use to fix the dataset:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-26_00a09c636c06e31104dad66016883369'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(lubridate)\n\nfix_emperors <- function(data) {\n  data %>% \n    mutate(\n      birth = case_when(\n        index %in% c(1, 2, 4, 6) ~ update(birth, year = -year(birth)),\n        TRUE                     ~ birth\n      ),\n      reign_start = case_when(\n        index == 1 ~ update(reign_start, year = -year(reign_start)),\n        TRUE       ~ reign_start\n      )\n    )\n}\n```\n:::\n\n\nHere are the questions to answer.\nDecide for yourself, if a particular question is best\nanswered using a visualization, a table, a simple sentence\nor a combination of the three.\n\n- What was the most popular way to rise to power?\n- I what are the most common causes of death among roman\n  emperors? What (or who) killed them?\n- Which dynasty was the most successful?\n  - Firstly, how often did each dynasty reign?\n  - Secondly, how long where the reigns?\n  - Which dynasty would you rather be a part of,\n    if your goal is to live the longest?\n    \n### Dairy Products in the US\n\nAnother dataset\n([link](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-29#milk_products_facts))\nconcerns dairy product consumption per person in the US across a number of years.\nLoad it with:\n\n\n::: {.cell hash='functional-programming_cache/html/unnamed-chunk-27_fca1bea62a50ef078bbe39b98064c99e'}\n\n```{.r .cell-code}\ndairy <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/milk_products_facts.csv\")\n```\n:::\n\n\n- All masses are given in lbs (pounds),\n  can you convert them to kg?\n- Which products lost their customer base over time,\n  which ones won? Which products have the greatest absolute\n  change in production when estimated with a straight line?\n\nAbove all, have some fun! If you make interesting\nfindings along the way, go ahead and produce plots\nto highlight it.\n\n## Resources\n\n- [purrr documentation](https://purrr.tidyverse.org/)\n- [stringr documentation](https://stringr.tidyverse.org/)\n- [dplyr documentation](https://dplyr.tidyverse.org/)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}