<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.157">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="description" content="This is where you will find all the resources for the course Introduction to Data Analysis with R">
<title>Introduction to Data Analysis with R - 5&nbsp; Probability and Hypothesis Testing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./distributions-summaries-and-dimensionality-reduction.html" rel="next">
<link href="./functional-programming.html" rel="prev">
<link href="./favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" href="style.css">
<meta property="og:title" content="Introduction to Data Analysis with R - 5&nbsp; Probability and Hypothesis Testing">
<meta property="og:description" content="This is where you will find all the resources for the course Introduction to Data Analysis with R">
<meta property="og:site-name" content="Introduction to Data Analysis with R">
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">
<span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probability and Hypothesis Testing</span>
</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Data Analysis with R</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/jmbuhr/dataintro" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle sidebar-tool" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Hello and welcome!</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data-wrangling.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data Wrangling</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tidy-data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Tidy data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./functional-programming.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Functional Programming</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability-and-hypothesis-testing.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probability and Hypothesis Testing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./distributions-summaries-and-dimensionality-reduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Distributions, Summaries and Dimensionality Reduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fallacies-correlation-and-regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Fallacies, Correlation and Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./freestyle.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Freestyle</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Appendices</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./resources.html" class="sidebar-item-text sidebar-link">Resources</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#motivation" id="toc-motivation" class="nav-link active" data-scroll-target="#motivation"><span class="toc-section-number">5.1</span>  Motivation</a></li>
  <li><a href="#statistically-significant" id="toc-statistically-significant" class="nav-link" data-scroll-target="#statistically-significant"><span class="toc-section-number">5.2</span>  Statistically Significant…</a></li>
  <li>
<a href="#getting-our-hands-dirty-with-probability" id="toc-getting-our-hands-dirty-with-probability" class="nav-link" data-scroll-target="#getting-our-hands-dirty-with-probability"><span class="toc-section-number">5.3</span>  Getting our Hands dirty with Probability</a>
  <ul class="collapse">
<li><a href="#definitions-hypothesis" id="toc-definitions-hypothesis" class="nav-link" data-scroll-target="#definitions-hypothesis"><span class="toc-section-number">5.3.1</span>  Definitions: Hypothesis</a></li>
  <li><a href="#testing-the-null-hypothesis-with-a-simulation" id="toc-testing-the-null-hypothesis-with-a-simulation" class="nav-link" data-scroll-target="#testing-the-null-hypothesis-with-a-simulation"><span class="toc-section-number">5.3.2</span>  Testing the Null Hypothesis with a Simulation</a></li>
  <li><a href="#getting-precise-with-the-binomial-distribution" id="toc-getting-precise-with-the-binomial-distribution" class="nav-link" data-scroll-target="#getting-precise-with-the-binomial-distribution"><span class="toc-section-number">5.3.3</span>  Getting precise with the Binomial Distribution</a></li>
  <li><a href="#but-how-much-better-understanding-effect-size-and-power-false-positives-and-false-negatives" id="toc-but-how-much-better-understanding-effect-size-and-power-false-positives-and-false-negatives" class="nav-link" data-scroll-target="#but-how-much-better-understanding-effect-size-and-power-false-positives-and-false-negatives"><span class="toc-section-number">5.3.4</span>  But how much better? Understanding Effect Size and Power, False Positives and False Negatives</a></li>
  </ul>
</li>
  <li>
<a href="#p-value-pitfalls" id="toc-p-value-pitfalls" class="nav-link" data-scroll-target="#p-value-pitfalls"><span class="toc-section-number">5.4</span>  P-Value Pitfalls</a>
  <ul class="collapse">
<li><a href="#multiple-testing-correction" id="toc-multiple-testing-correction" class="nav-link" data-scroll-target="#multiple-testing-correction"><span class="toc-section-number">5.4.1</span>  Multiple Testing Correction</a></li>
  <li><a href="#other-forms-of-p-hacking" id="toc-other-forms-of-p-hacking" class="nav-link" data-scroll-target="#other-forms-of-p-hacking"><span class="toc-section-number">5.4.2</span>  Other forms of p-hacking</a></li>
  </ul>
</li>
  <li><a href="#bayesian-statistics-and-the-base-rate-fallacy" id="toc-bayesian-statistics-and-the-base-rate-fallacy" class="nav-link" data-scroll-target="#bayesian-statistics-and-the-base-rate-fallacy"><span class="toc-section-number">5.5</span>  Bayesian Statistics and the Base Rate Fallacy</a></li>
  <li><a href="#concepts-discussed-today" id="toc-concepts-discussed-today" class="nav-link" data-scroll-target="#concepts-discussed-today"><span class="toc-section-number">5.6</span>  Concepts discussed today</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="toc-section-number">5.7</span>  Exercises</a></li>
  <li><a href="#a-fair-coin" id="toc-a-fair-coin" class="nav-link" data-scroll-target="#a-fair-coin"><span class="toc-section-number">5.8</span>  A Fair Coin</a></li>
  <li><a href="#an-unfair-game" id="toc-an-unfair-game" class="nav-link" data-scroll-target="#an-unfair-game"><span class="toc-section-number">5.9</span>  An Unfair Game</a></li>
  <li><a href="#discovering-a-new-distribution" id="toc-discovering-a-new-distribution" class="nav-link" data-scroll-target="#discovering-a-new-distribution"><span class="toc-section-number">5.10</span>  Discovering a new Distribution</a></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources"><span class="toc-section-number">5.11</span>  Resources</a></li>
  <li>
<a href="#distributions-summaries-and-dimensionality-reduction" id="toc-distributions-summaries-and-dimensionality-reduction" class="nav-link" data-scroll-target="#distributions-summaries-and-dimensionality-reduction"><span class="toc-section-number">6</span>  Distributions, Summaries and Dimensionality Reduction</a>
  <ul class="collapse">
<li>
<a href="#some-preparation" id="toc-some-preparation" class="nav-link" data-scroll-target="#some-preparation"><span class="toc-section-number">6.1</span>  Some Preparation</a>
  <ul class="collapse">
<li><a href="#sidenote-on-reproducible-environments-with-renv" id="toc-sidenote-on-reproducible-environments-with-renv" class="nav-link" data-scroll-target="#sidenote-on-reproducible-environments-with-renv"><span class="toc-section-number">6.1.1</span>  [Sidenote] on Reproducible Environments with <code>renv</code></a></li>
  </ul>
</li>
  <li>
<a href="#all-models-are-wrong-but-some-are-useful" id="toc-all-models-are-wrong-but-some-are-useful" class="nav-link" data-scroll-target="#all-models-are-wrong-but-some-are-useful"><span class="toc-section-number">6.2</span>  All models are wrong, but some are useful</a>
  <ul class="collapse">
<li><a href="#types-of-models" id="toc-types-of-models" class="nav-link" data-scroll-target="#types-of-models"><span class="toc-section-number">6.2.1</span>  Types of Models</a></li>
  </ul>
</li>
  <li><a href="#say-hello-to-spotify-data" id="toc-say-hello-to-spotify-data" class="nav-link" data-scroll-target="#say-hello-to-spotify-data"><span class="toc-section-number">6.3</span>  Say Hello to Spotify Data</a></li>
  <li><a href="#visualising-continuous-distributions" id="toc-visualising-continuous-distributions" class="nav-link" data-scroll-target="#visualising-continuous-distributions"><span class="toc-section-number">6.4</span>  Visualising Continuous Distributions</a></li>
  <li><a href="#summary-statistics" id="toc-summary-statistics" class="nav-link" data-scroll-target="#summary-statistics"><span class="toc-section-number">6.5</span>  Summary Statistics…</a></li>
  <li>
<a href="#mean-median-and-other-quartiles-range" id="toc-mean-median-and-other-quartiles-range" class="nav-link" data-scroll-target="#mean-median-and-other-quartiles-range"><span class="toc-section-number">6.6</span>  Mean, Median (and other Quartiles), Range</a>
  <ul class="collapse">
<li><a href="#variance" id="toc-variance" class="nav-link" data-scroll-target="#variance"><span class="toc-section-number">6.6.1</span>  Variance</a></li>
  <li><a href="#standard-deviation" id="toc-standard-deviation" class="nav-link" data-scroll-target="#standard-deviation"><span class="toc-section-number">6.6.2</span>  Standard deviation</a></li>
  <li><a href="#standard-error-of-the-mean" id="toc-standard-error-of-the-mean" class="nav-link" data-scroll-target="#standard-error-of-the-mean"><span class="toc-section-number">6.6.3</span>  Standard Error of the Mean</a></li>
  </ul>
</li>
  <li><a href="#or-how-to-lie-with-graphs" id="toc-or-how-to-lie-with-graphs" class="nav-link" data-scroll-target="#or-how-to-lie-with-graphs"><span class="toc-section-number">6.7</span>  … or: How to Lie with Graphs</a></li>
  <li>
<a href="#graphic-devices-fonts-and-the-ggplot-book" id="toc-graphic-devices-fonts-and-the-ggplot-book" class="nav-link" data-scroll-target="#graphic-devices-fonts-and-the-ggplot-book"><span class="toc-section-number">6.8</span>  Graphic Devices, Fonts and the ggplot Book</a>
  <ul class="collapse">
<li><a href="#ggplot-book" id="toc-ggplot-book" class="nav-link" data-scroll-target="#ggplot-book"><span class="toc-section-number">6.8.1</span>  ggplot book</a></li>
  <li><a href="#sidenote-graphics-devices" id="toc-sidenote-graphics-devices" class="nav-link" data-scroll-target="#sidenote-graphics-devices"><span class="toc-section-number">6.8.2</span>  [Sidenote] Graphics Devices</a></li>
  <li><a href="#log-normality" id="toc-log-normality" class="nav-link" data-scroll-target="#log-normality"><span class="toc-section-number">6.8.3</span>  Log-normality</a></li>
  </ul>
</li>
  <li><a href="#the-t-distribution" id="toc-the-t-distribution" class="nav-link" data-scroll-target="#the-t-distribution"><span class="toc-section-number">6.9</span>  The T-Distribution</a></li>
  <li><a href="#students-t-test" id="toc-students-t-test" class="nav-link" data-scroll-target="#students-t-test"><span class="toc-section-number">6.10</span>  Student’s T-Test</a></li>
  <li>
<a href="#wilcoxon-rank-sum-test" id="toc-wilcoxon-rank-sum-test" class="nav-link" data-scroll-target="#wilcoxon-rank-sum-test"><span class="toc-section-number">6.11</span>  Wilcoxon rank-sum test</a>
  <ul class="collapse">
<li><a href="#direction-of-testing" id="toc-direction-of-testing" class="nav-link" data-scroll-target="#direction-of-testing"><span class="toc-section-number">6.11.1</span>  Direction of Testing</a></li>
  <li><a href="#confidence-intervals" id="toc-confidence-intervals" class="nav-link" data-scroll-target="#confidence-intervals"><span class="toc-section-number">6.11.2</span>  Confidence Intervals</a></li>
  </ul>
</li>
  <li><a href="#chrunching-dimensions-with-dimensionality-reduction-pca" id="toc-chrunching-dimensions-with-dimensionality-reduction-pca" class="nav-link" data-scroll-target="#chrunching-dimensions-with-dimensionality-reduction-pca"><span class="toc-section-number">6.12</span>  Chrunching Dimensions with Dimensionality Reduction: PCA</a></li>
  <li>
<a href="#exercises-1" id="toc-exercises-1" class="nav-link" data-scroll-target="#exercises-1"><span class="toc-section-number">6.13</span>  Exercises</a>
  <ul class="collapse">
<li><a href="#the-plotty-horror-picture-show" id="toc-the-plotty-horror-picture-show" class="nav-link" data-scroll-target="#the-plotty-horror-picture-show"><span class="toc-section-number">6.13.1</span>  The Plotty Horror Picture Show</a></li>
  <li><a href="#take-a-sad-plot-and-make-it-better" id="toc-take-a-sad-plot-and-make-it-better" class="nav-link" data-scroll-target="#take-a-sad-plot-and-make-it-better"><span class="toc-section-number">6.13.2</span>  Take a Sad Plot and Make it Better</a></li>
  </ul>
</li>
  <li><a href="#resources-1" id="toc-resources-1" class="nav-link" data-scroll-target="#resources-1"><span class="toc-section-number">6.14</span>  Resources</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/jmbuhr/dataintro/issues/new" class="toc-action">Report an issue</a></p><p><a href="https://github.com/jmbuhr/dataintro/blob/main/probability-and-hypothesis-testing.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title d-none d-lg-block">
<span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probability and Hypothesis Testing</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><blockquote class="blockquote">
<p>… in which we reason about the nature of randomness and discover various statistical tests.</p>
</blockquote>
<p></p>
<div id="youtube-frame" style="position: relative; padding-bottom: 56.25%; /* 16:9 */ height: 0; margin-bottom: 1rem;"><iframe width="100%" height="" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" src="https://www.youtube.com/embed/LBU22HxJm6I" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="motivation" class="level2" data-number="5.1"><h2 data-number="5.1" class="anchored" data-anchor-id="motivation">
<span class="header-section-number">5.1</span> Motivation</h2>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-2_5810f9b0a6d07141531e6acef496513a">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the first four lectures we covered the fundamentals of handling data with R. Now, we will shift our focus away from the <strong>how</strong> and towards the <strong>why</strong> of data analysis. We will talk about different statistical tests, common mistakes, how to avoid them and how to spot them in other research. But of course, we will do so using R. So you will still learn one or the other useful function or technique along the way. In most instances it should be clear when I use R solely to demonstrate an idea from statistics and the code is just included for the curious, or whether the code is something you will likely also use for your own analysis. I am open for questions if things are unclear in any of the two cases. For purely aesthetic code I might also speed up the typing in the edit.</p>
<p>For the longer text parts it might be helpful to look at the script while watching the video or pause frequently to take your own notes (Rmarkdown is great for your lecture notes as well!).</p>
</section><section id="statistically-significant" class="level2" data-number="5.2"><h2 data-number="5.2" class="anchored" data-anchor-id="statistically-significant">
<span class="header-section-number">5.2</span> Statistically Significant…</h2>
<blockquote class="blockquote">
<p>…you keep using that word. I don’t think it means what you think it means.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="images/statistically-significant.jpg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">statistically significant</figcaption><p></p>
</figure>
</div>
<p>You will hear the phrases “statistically significant”, “significant” or even “very significant” thrown around quite a bit in academic literature . And while they are often used carelessly, they have a clearly defined meaning. A meaning we will uncover today. This meaning is related to the concept of so called p-values, which have an equally bad reputation for frequently being misused. The p in p-value stands for <strong>probability</strong>, so in order to understand p-values, we need to understand probability and learn how to deal with randomness, chance, or luck if you will. So…</p>
</section><section id="getting-our-hands-dirty-with-probability" class="level2" data-number="5.3"><h2 data-number="5.3" class="anchored" data-anchor-id="getting-our-hands-dirty-with-probability">
<span class="header-section-number">5.3</span> Getting our Hands dirty with Probability</h2>
<blockquote class="blockquote">
<p>To understand statistics means understanding the nature of randomness first.</p>
</blockquote>
<div class="cell" data-fig.asp="1" data-hash="probability-and-hypothesis-testing_cache/html/chess-board_35cef5603b0fc550fe355c4485309c69">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="probability-and-hypothesis-testing_files/figure-html/chess-board-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">A ggplot chessboard</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Say you and you friend are playing a game of chess, when your friend proudly proclaims:<br>
“I am definitely the better player!”.<br>
“Proof it!”, you reply.<br>
“That’s easy”, she says: “I won 7 out of the 8 rounds we played to today.”<br>
“Pah! That’s just luck.” is your less witty and slightly stubborn response.</p>
<p>As expected, we shall be using R to resolve this vital conflict.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="images/paste-5E31A2FF.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">R rainbow</figcaption><p></p>
</figure>
</div>
<section id="definitions-hypothesis" class="level3" data-number="5.3.1"><h3 data-number="5.3.1" class="anchored" data-anchor-id="definitions-hypothesis">
<span class="header-section-number">5.3.1</span> Definitions: Hypothesis</h3>
<p>Both of you involuntarily uttered an hypothesis, a testable assumption. And we want to test these hypothesis using statistics. The first hypothesis (“I am the better player.”) is what we call the <strong>alternative hypothesis</strong> (<span class="math inline">\(H_1\)</span>). The name can be a bit confusing, because most often, this is your actual scientific hypothesis, the thing you are interested in. So, alternative to what? It is alternative to the so called <strong>null hypothesis</strong> (<span class="math inline">\(H_0\)</span>), which is the second statement (“This is just luck”). The null hypothesis provides a sort of baseline for all our findings. It usually goes along the lines of “What if our observations are just based on chance alone?”, where “chance” can be any source of random variation in our system.</p>
<p>The tricky part is that there is no way to directly test the alternative Hypothesis, all we can test is the null hypothesis. Because for any null hypothesis we discard, there are always multiple alternative hypothesis that could explain our data. In our example, even if we end up discarding the idea of our friend’s chess success being only down to luck, this does not prove the alternative hypothesis that she is the better player (she could still be cheating for example). Do keep this in mind when we transfer this to a more scientific setting. Just because we show that something is unlikely to have arisen by chance does not mean that your favorite alternative hypothesis is automatically true.</p>
<p>So, after these words of warning, let’s test some null hypothesis!</p>
</section><section id="testing-the-null-hypothesis-with-a-simulation" class="level3" data-number="5.3.2"><h3 data-number="5.3.2" class="anchored" data-anchor-id="testing-the-null-hypothesis-with-a-simulation">
<span class="header-section-number">5.3.2</span> Testing the Null Hypothesis with a Simulation</h3>
<p>We will start off by building a little simulation. Before testing any hypothesis, it is important to have defined <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span> properly, which we did in the previous section. But we need to be a little more specific. Winning by chance would entail a completely random process, which we can model with a coin flip. R has the lovely function <code>sample</code> to take any number of things from a vector, with or without replacement after taking each thing:</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-3_06ebe13bbe9e28ffbf2f5e46879a1872">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">coin</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"heads"</span>, <span class="st">"tails"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">coin</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "tails" "heads"</code></pre>
</div>
</div>
<p>Not giving it a number of things to draw just shuffles the vector, which is fairly boring in the case of just two tings. We can’t sample 10 things from a vector of only two elements</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-4_7330edf22e2d1db5be9e9087abefa8ac">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">coin</span>, size <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>Error in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when 'replace = FALSE'</code></pre>
</div>
</div>
<p>But we can, if we put the thing back every time:</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-5_b3f9d7f3093f729c417802573f61b0c5">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">coin</span>, <span class="fl">10</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "tails" "heads" "heads" "tails" "tails" "heads" "tails" "tails" "heads"
[10] "heads"</code></pre>
</div>
</div>
<p>So, let’s make this a little more specific to our question:</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-6_2052550746b5e8ace91cba9188e91410">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">winner</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"you"</span>, <span class="st">"friend"</span><span class="op">)</span></span>
<span><span class="va">random_winners</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">winner</span>, size <span class="op">=</span> <span class="fl">8</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">random_winners</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "friend" "friend" "you"    "you"    "friend" "you"    "friend" "friend"</code></pre>
</div>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">random_winners</span> <span class="op">==</span> <span class="st">"friend"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  TRUE  TRUE FALSE FALSE  TRUE FALSE  TRUE  TRUE</code></pre>
</div>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fl">1</span> <span class="op">+</span> <span class="cn">TRUE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2</code></pre>
</div>
</div>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-7_316f9a2d025d59fe67b19266e748c6af">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fl">1</span> <span class="op">+</span> <span class="cn">FALSE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
</div>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-8_c75e4ec44bc31613cfdeb5d1d15f9294">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">random_winners</span> <span class="op">==</span> <span class="st">"friend"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5</code></pre>
</div>
</div>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-9_4436eca18d7705e3b1de5014dc36e95c">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">random_winners</span> <span class="op">==</span> <span class="st">"friend"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.625</code></pre>
</div>
</div>
<p>If we were to run this script a million times, the resulting proportion of random wins for both of you would be very, very close to 50-50 because we used a fair coin. However, we don’t have the time to play this much Chess and we sure don’t have the money to run a million replicates for each experiment in the lab. But here, in our little simulated world, we have near infinite resources (our simulation is not to computationally costly).</p>
<blockquote class="blockquote">
<p>One trick used above: When we calculate e.g.&nbsp;a sum or mean, R automatically converts TRUE to 1 and FALSE to 0.</p>
</blockquote>
<p>Let’s create a function that returns a random number of wins your friend would have gotten by pure chance for a number of rounds <code>N</code>.</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-10_4c351a19fdd0375e355bee2be0259635">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">get_n_win</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">N</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">winner</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"you"</span>, <span class="st">"friend"</span><span class="op">)</span></span>
<span>  <span class="va">random_winners</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">winner</span>, size <span class="op">=</span> <span class="va">N</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">random_winners</span> <span class="op">==</span> <span class="st">"friend"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu">get_n_win</span><span class="op">(</span><span class="fl">8</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3</code></pre>
</div>
</div>
<p>This number is different every time, so how does it change?</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-11_e7944b0f3d07ab88625d2c07c9b762f8">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_dbl</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">1000</span><span class="op">)</span>, <span class="va">get_n_win</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4 5 5 2 3 5</code></pre>
</div>
</div>
<p>A histogram is a type of plot that shows how often each value occurs in a vector. Usually, the values are put into bins first, grouping close values together for continuous values, but in this case it makes sense to just have one value per bin because we are dealing with discrete values (e.g.&nbsp;no half-wins). Histograms can either display the raw counts or the frequency e.g.&nbsp;as a percentage. In ggplot, we use <code>geom_bar</code> when we don’t need any binning, just counting occurrences, and <code>geom_histogram</code> when we need to bin continuous values.</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-12_f04f4c74c6af72ce24494863095c585a">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">result</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"N wins for friend"</span>,</span>
<span>       title <span class="op">=</span> <span class="st">"Throwing a coin 8 times"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">8</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="probability-and-hypothesis-testing_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p>As expected, the most common number of wins out of 8 is 4 (unless I got really unlucky when compiling this script). Let us see, how this <strong>distribution</strong> changes for different values of <code>N</code>. First, we set up a grid of numbers (all possible combinations) so that we can run a bunch of simulations:</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-13_b1a46c7ded069a7b96df29700657187a">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">simulation</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tidyr.tidyverse.org/reference/expand.html">crossing</a></span><span class="op">(</span></span>
<span>   N <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">15</span>,</span>
<span>   rep <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span></span>
<span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    wins <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_dbl</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">get_n_win</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And then we use our trusty ggplot to visualize all the distributions.</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-14_39d6bcc45f25a5375a151a877f0d1787">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">simulation</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">wins</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">N</span>, labeller <span class="op">=</span> <span class="va">label_both</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Flipping a coin N times"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="probability-and-hypothesis-testing_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p>With a fair coin, the most common number of wins should be half of the number of coin flips. Note, how it is still possible to flip a coin 15 times and and not win a single time. It is just very unlikely and the bars are so small that we can’t see them.</p>
<p>Let us go back to the original debate. The first statement: “I am better.” is something that can never be definitively proven. Because there is always the possibility, no matter how small, that the same result could have arisen by pure chance alone. Even if she wins 100 times and we don’t take a single game from her, this sort of outcome is still not <em>impossible</em> to appear just by flipping a coin. But what we can do, is calculate, how likely a certain event is under the assumption of the null hypothesis (only chance). And we can also decide on some threshold <span class="math inline">\(\alpha\)</span> at which we reject the null hypothesis. This is called the <strong>significance threshold</strong>. When we make an observation and then calculate that the probability for an observation like this or more extreme is smaller than the threshold, we deem the result <strong>statistically significant</strong>. And the probability thus created is called the <strong>p-value</strong>.</p>
<p>From our simulation, we find the that probability to win 7 out of 8 rounds under the null hypothesis is:</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-15_3c06502790700c9a1fabd6b371381afd">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">simulation</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">N</span> <span class="op">==</span> <span class="fl">8</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">wins</span> <span class="op">&gt;=</span> <span class="fl">7</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
  `mean(wins &gt;= 7)`
              &lt;dbl&gt;
1             0.038</code></pre>
</div>
</div>
<p>Which is smaller than the commonly used significance threshold of <span class="math inline">\(\alpha=0.05\)</span> (i.e.&nbsp;<span class="math inline">\(5\%\)</span>). So with 7 out of 8 wins, we would <strong>reject the null hypothesis</strong>. Do note that this threshold, no matter how commonly and thoughtlessly it is used throughout academic research, is completely arbitrary.</p>
</section><section id="getting-precise-with-the-binomial-distribution" class="level3" data-number="5.3.3"><h3 data-number="5.3.3" class="anchored" data-anchor-id="getting-precise-with-the-binomial-distribution">
<span class="header-section-number">5.3.3</span> Getting precise with the Binomial Distribution</h3>
<p>Now, this was just from a simulation with 1000 trials, so the number can’t be arbitrarily precise, but there is a mathematical formula for this probability. What we created by counting the number of successes in a series of yes-no-trials is a <strong>binomial distribution</strong>. For the most common distributions, R provides a set of functions. the functions starting with <code>d</code> give us the probability density function. In the case of discrete values like counting wins, this is equivalent to the actual probability, but for continuous values we obtain the probability by taking the integral. We get these integrals with the corresponding functions starting with <code>p</code> (for probability).</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-16_882c0dd97ef4435e197e0ac44c4f541e">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">7</span>, size <span class="op">=</span> <span class="fl">8</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.03125</code></pre>
</div>
</div>
<p>This is the probability to win <strong>exactly 7 out of 8</strong> games. But what we wanted was the probability for <strong>7 or more out of 8</strong>! So we move to the integral. This part can get a bit confusing, because the default for <code>pbinom</code> is <code>lower.tail = TRUE</code>, which according to the help page means that probabilities it returns <span class="math inline">\(P[X \le x]\)</span>.</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-17_748d3da322e5982d4e005f3c58dcde13">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span>q <span class="op">=</span> <span class="fl">7</span>, size <span class="op">=</span> <span class="fl">8</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9960938</code></pre>
</div>
</div>
<p>If we set <code>lower.tail</code> to <code>FALSE</code> , we get <span class="math inline">\(P[X &gt; x]\)</span>, so the probability for a random variable X being bigger than a number x. So to get the probability that we are interested in, we need to replace the 7 with a 6 as well:</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-18_a8d85b04da6f3d41fd61e21d993c5b7e">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span>q <span class="op">=</span> <span class="fl">6</span>, size <span class="op">=</span> <span class="fl">8</span>, prob <span class="op">=</span> <span class="fl">0.5</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.03515625</code></pre>
</div>
</div>
<p>Our simulation was pretty close! So the exact values agrees and we reject the null hypothesis of both opponents being equally good. Here is the full graph for the probability density function of the binomial distribution.</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-19_df4dcf0afc5204bad6618784e3657889">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html">stat_function</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, size <span class="op">=</span> <span class="fl">8</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>,</span>
<span>                geom <span class="op">=</span> <span class="st">"step"</span>,</span>
<span>                n <span class="op">=</span> <span class="fl">9</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>n.breaks <span class="op">=</span> <span class="fl">9</span>, limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">8</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="probability-and-hypothesis-testing_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p>And the integral, the probability <span class="math inline">\(P[X \le x]\)</span>.</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-20_d8d792b52456b1bbecf95a2291df0352">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html">stat_function</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">q</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span>q <span class="op">=</span> <span class="va">q</span>, size <span class="op">=</span> <span class="fl">8</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>,</span>
<span>                geom <span class="op">=</span> <span class="st">"step"</span>,</span>
<span>                n <span class="op">=</span> <span class="fl">9</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>n.breaks <span class="op">=</span> <span class="fl">9</span>, limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">8</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="probability-and-hypothesis-testing_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p>There is two more functions I want to showcase from this family. The third is the so called <strong>quantile function</strong>. Quantiles divide a probability distribution into pieces of equal probability. One example for a quantile is the 50th percentile, also known as the median, which divides the values such that half of the values are above and half are below. And we can keep dividing the two halves as well, so that we end up with more quantiles. Eventually, we arrive at the quantile function. It is the inverse of the probability function, so you obtain it by swapping the axis.</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-21_3d434b457551a75d414c206ede5e9749">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html">stat_function</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">qbinom</a></span><span class="op">(</span>p <span class="op">=</span> <span class="va">p</span>, size <span class="op">=</span> <span class="fl">8</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>,</span>
<span>                geom <span class="op">=</span> <span class="st">"step"</span>,</span>
<span>                n <span class="op">=</span> <span class="fl">9</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>n.breaks <span class="op">=</span> <span class="fl">10</span>, limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="probability-and-hypothesis-testing_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p>Quantiles will also be useful for deciding if a random sample follows a certain distribution with quantile-quantile plots.</p>
<p>Lastly, there is always also an <code>r</code> variant of the function, which gives us any number of random numbers from the distribution.</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-22_59126d11d3c3cf43c43588e1e14d1f31">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">8</span>, <span class="fl">0.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 5 5 6 4 4 2 5 3 5 3</code></pre>
</div>
</div>
</section><section id="but-how-much-better-understanding-effect-size-and-power-false-positives-and-false-negatives" class="level3" data-number="5.3.4"><h3 data-number="5.3.4" class="anchored" data-anchor-id="but-how-much-better-understanding-effect-size-and-power-false-positives-and-false-negatives">
<span class="header-section-number">5.3.4</span> But how much better? Understanding Effect Size and Power, False Positives and False Negatives</h3>
<p>We decided to abandon the null hypothesis that both players are equally good, which equates to a 50% win-chance for each player. But we have not determined <strong>how much better</strong> she is. And how much better does she need to be for us to reliably discard the null hypothesis after just 8 games? The generalization of the <strong>how much better</strong> part, the <strong>true difference</strong>, is called the <strong>effect size</strong>.</p>
<p>Our ability to decide that something is statistically significant when there is in fact a true difference is called the statistical <strong>power</strong>. It depends on the effect size, our significance threshold <span class="math inline">\(\alpha\)</span> and the sample size <span class="math inline">\(n\)</span> (the number of games). We can explore the concept with another simulation.</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-23_27c54282b63e49749e55add5f0181d2c">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">reps</span> <span class="op">&lt;-</span> <span class="fl">10000</span></span>
<span><span class="va">simulation</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tidyr.tidyverse.org/reference/expand.html">crossing</a></span><span class="op">(</span></span>
<span>  N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">100</span>, <span class="fl">1000</span>, <span class="fl">10000</span><span class="op">)</span>,</span>
<span>  true_prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span><span class="op">)</span></span>
<span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/rowwise.html">rowwise</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    wins <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">reps</span>, size <span class="op">=</span> <span class="va">N</span>,  prob <span class="op">=</span> <span class="va">true_prob</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/nest.html">unnest</a></span><span class="op">(</span><span class="va">wins</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span>q <span class="op">=</span> <span class="va">wins</span> <span class="op">-</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="va">N</span>, prob <span class="op">=</span> <span class="fl">0.5</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">simulation</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 4
      N true_prob  wins     p
  &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;
1     8       0.5     3 0.855
2     8       0.5     3 0.855
3     8       0.5     4 0.637
4     8       0.5     1 0.996
5     8       0.5     3 0.855
6     8       0.5     6 0.145</code></pre>
</div>
</div>
<p>I also introduced a new piece of advanced dplyr syntax. <code>rowwise</code> is similar to <code>group_by</code> and essentially puts each row into its own group. This can be useful when working with list columns or running a function with varying arguments and allows us to treat the inside of <code>mutate</code> a bit like as if we where using one of the <code>map</code> functions. For more information, see <a href="https://dplyr.tidyverse.org/articles/rowwise.html">the documentation article</a>.</p>
<p>It leaves us with 10000 simulated numbers of wins at N games for different true probabilities of her winning (i.e.&nbsp;how much better our friend is). We then calculate the probability to have this or a greater number of wins under the null hypothesis (equal probability for win and loss), in other words: the p-value.</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-24_c6b2d2bd7c83ab53d28642a21ae2b651">
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">simulation</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span> <span class="va">true_prob</span> <span class="op">+</span> <span class="va">N</span>,</span>
<span>             labeller <span class="op">=</span> <span class="va">label_both</span>,</span>
<span>             scales <span class="op">=</span> <span class="st">"free_y"</span>,</span>
<span>             ncol <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0.05</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"p-value"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"frequency"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="probability-and-hypothesis-testing_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p>We notice a couple of things in this plot. As the number of games played approaches very high numbers, the p-values for the case where the null hypothesis is in fact true (both players have the same chance of winning), start following a uniform distribution, meaning for a true null hypothesis, all p-values are equally likely. This seems counterintuitive at first, but is a direct consequence of the definition of the p-value. The consequence of this is, that if we apply our regular significance threshold of 5%, by definition we will say that there is a true difference, even though there is none (i.e.&nbsp;the null hypothesis is true but we falsely reject it and favor of our alternative hypothesis). This is called a <strong>false positive</strong>. By definition, we will get at least <span class="math inline">\(\alpha\)</span> false positives in all of our experiments. Later, we will learn, why the real number of false positives is even higher. Another name for false positives is <strong>Type I errors</strong>.</p>
<p>On the other side of the coin, there are also cases where there is a true difference (we used winning probabilities of 0.8 and 0.9), but we don’t reject the null hypothesis because we get a p-values larger than <span class="math inline">\(alpha\)</span>. These are all <strong>false negatives</strong> and their rate is sometimes referred to as <span class="math inline">\(\beta\)</span>. Another name for false negatives is <strong>Type II errors</strong>. People don’t particularly like talking about negative things like errors, so instead you will often see the inverse of <span class="math inline">\(\beta\)</span>, the <strong>Statistical Power</strong> <span class="math inline">\(1-\beta\)</span>. The proportion of correctly identified positives out of the actual positives is also shown on the plot below. For example, say her true win probability is 90% and we play 8 games. If this experiment runs in an infinite number of parallel universes, we will conclude that she is better than chance in 80% of those. We could set our significance threshold higher to detect more of the true positives, but this would also increase our false positives.</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-25_bf61fab70e900bfd20fab51e762ac8c4">
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">simulation</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">true_prob</span>, <span class="va">N</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span>signif <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">p</span> <span class="op">&lt;=</span> <span class="fl">0.05</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">true_prob</span>, <span class="va">signif</span>, fill <span class="op">=</span> <span class="va">true_prob</span> <span class="op">==</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_col</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html">geom_text</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>label <span class="op">=</span> <span class="va">signif</span><span class="op">)</span>, vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">N</span>,</span>
<span>             labeller <span class="op">=</span> <span class="va">label_both</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>expand <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/expansion.html">expansion</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_viridis.html">scale_fill_viridis_d</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>y <span class="op">=</span> <span class="st">"Proportion of significant results"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="probability-and-hypothesis-testing_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p>There are also packages out there, which have a function to compute the power for the binomial test, but I think the simulation was way more approachable. The cool thing about simulations is also, that they work even when there is no analytical solution, so you can use them to play around when planning an experiment.</p>
</section></section><section id="p-value-pitfalls" class="level2" data-number="5.4"><h2 data-number="5.4" class="anchored" data-anchor-id="p-value-pitfalls">
<span class="header-section-number">5.4</span> P-Value Pitfalls</h2>
<p>Let us look into some of the pitfalls of p-values. Remember from the definition of p-values, that we will get a significant result even if there is no true difference in 5% of cases (assuming we use this as our alpha)? Well, what if we test a bunch of things? This is called <strong>Multiple Testing</strong> and there is a problem associated with it:</p>
<p>If you test 20 different things, and your statistical test will produce a significant result by chance alone in 5% of cases, the expected number of significant results is 1. So we are not very surprised. Speaking of surprised: In his book, available for free online, <a href="https://www.statisticsdonewrong.com/">“Statistics done wrong”</a>, Alex Reinhart describes p-values as a “measure of surprise”:</p>
<blockquote class="blockquote">
<p>»A p value is not a measure of how right you are, or how significant the difference is; it’s a measure of how surprised you should be if there is no actual difference between the groups, but you got data suggesting there is. A bigger difference, or one backed up by more data, suggests more surprise and a smaller p value.« — Alex Reinhart <span class="citation" data-cites="reinhartStatisticsDoneWrong2015">(<a href="references.html#ref-reinhartStatisticsDoneWrong2015" role="doc-biblioref">Reinhart 2015</a>)</span></p>
</blockquote>
<p>So, we are not very surprised, but if you focus to hard on the one significant result, trouble ensues. In a “publish or perish” mentality, this can easily happen, and negative findings are not published nearly enough, so most published findings are likely exaggerated. John Bohannon showcased this beautifully by running a study on chocolate consumption and getting it published: <a href="https://io9.gizmodo.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800">I Fooled Millions Into Thinking Chocolate Helps Weight Loss. Here’s How.</a></p>
<p>What can we do about this?</p>
<section id="multiple-testing-correction" class="level3" data-number="5.4.1"><h3 data-number="5.4.1" class="anchored" data-anchor-id="multiple-testing-correction">
<span class="header-section-number">5.4.1</span> Multiple Testing Correction</h3>
<p>The simplest approach is to take all p-values calculate when running a large number of comparisons and dividing them by the number of tests performed. This is called the <strong>Bonferroni correction</strong></p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-26_cac595de858bc3b489c3639ee0839b47">
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.05</span>, <span class="fl">0.3</span>, <span class="fl">0.0001</span>, <span class="fl">0.003</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/p.adjust.html">p.adjust</a></span><span class="op">(</span><span class="va">p_values</span>, method <span class="op">=</span> <span class="st">"bonferroni"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.0000 0.2500 1.0000 0.0005 0.0150</code></pre>
</div>
</div>
<p>Of course, this looses some statistical power (remember, no free lunch). A slightly more sophisticated approach to controlling the false discovery rate (FDR) is the Benjamini-Hochberg procedure. It retains a bit more power. Here is what happens:</p>
<ul>
<li>Sort all p-values in ascending order.</li>
<li>Choose a FDR <span class="math inline">\(q\)</span> you are willing to accept and call the number of tests done <span class="math inline">\(m\)</span>.</li>
<li>Find the largest p-value with: <span class="math inline">\(p \leq iq/m\)</span> with its index <span class="math inline">\(i\)</span>.</li>
<li>This is your new threshold for significance</li>
<li>Scale the p-values accordingly</li>
</ul>
<p>And this is how you do it in R:</p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-27_ebe1a2ef52dab39d8bbf79c830a9df75">
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/p.adjust.html">p.adjust</a></span><span class="op">(</span><span class="va">p_values</span>, method <span class="op">=</span> <span class="st">"fdr"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.50000000 0.08333333 0.37500000 0.00050000 0.00750000</code></pre>
</div>
</div>
</section><section id="other-forms-of-p-hacking" class="level3" data-number="5.4.2"><h3 data-number="5.4.2" class="anchored" data-anchor-id="other-forms-of-p-hacking">
<span class="header-section-number">5.4.2</span> Other forms of p-hacking</h3>
<p>This sort of multiple testing is fairly obvious. You will notice it, when you end up with a large number of p-values, for example when doing a genetic screening and testing thousands of genes. Other related problems are harder to spot. For a single research question there are often different statistical tests that you could run, but trying them all out and then choosing the one that best agrees with your hypothesis is not an option! Likewise, simply looking at your data is a form of comparison if it influences your choice of statistical test. Ideally, you first run some exploratory experiments that are not meant to test your hypothesis, then decide on the tests you need, the sample size you want for a particular power and then run the actual experiments designed to test your hypothesis.</p>
<p>At this point, here is another shout-out to Alex Reinharts book <span class="citation" data-cites="reinhartStatisticsDoneWrong2015">(<a href="references.html#ref-reinhartStatisticsDoneWrong2015" role="doc-biblioref">Reinhart 2015</a>)</span>. It is a very pleasant read and also shines more light on some of the other forms of <strong>p-hacking</strong>.</p>
</section></section><section id="bayesian-statistics-and-the-base-rate-fallacy" class="level2 page-columns page-full" data-number="5.5"><h2 data-number="5.5" class="anchored" data-anchor-id="bayesian-statistics-and-the-base-rate-fallacy">
<span class="header-section-number">5.5</span> Bayesian Statistics and the Base Rate Fallacy</h2>
<div class="page-columns page-full"><p>There is another more subtle problem called the base rate fallacy. As an example, we assume a medical test, testing for a certain condition. In medical testing, different words are used for the same concepts we defined above<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;This is a slightly annoying trend in statistics; as it enters different fields, people come up with new names for old things (perhaps the most notorious field for this is machine learning).</p></li></div></div>
<p>Here, we have:</p>
<ul>
<li>Sensitivity = Power = true positive rate = <span class="math inline">\(1-\beta\)</span>
</li>
<li>Specificity = true negative rate = <span class="math inline">\(1-\alpha\)</span>
</li>
</ul>
<p>Let us assume a test with a sensitivity of 90% and a specificity of 92%. When we visit the doctor to get a test, and get a positive result, what is the probability, that we are in fact positive (i.e.&nbsp;a true positive)? Well, the test has a specificity of 92%, so if we where negative, it would have detected that in 92% of cases, does this mean, that we can be 92% certain, that we are actually positive?</p>
<p>Well, <strong>no</strong>. What we are ignoring here is <strong>base rate</strong>, which for diseases is called the <strong>prevalence</strong>. It is the proportion at which a disease exists in the general population.</p>
<p>So, let us say, we are picking 1000 people at random from the population and testing them. We are dealing with a hypothetical condition that affects 1% of people, so we assume 10 people in our sample to be positive. Of those 10 people, 9 will be tested positive (due to our sensitivity), those will be our true positives. The remaining 1 will be a false negative. However, we are of course also testing the negatives (if we knew ahead of time there would be no point in testing) and of those due to our specificity, 8% will also be tested positive, which is 0.08 * 990, so we get 79 false positives. Because there are so many negatives in our sample, even a relatively high specificity will produce a lot of false positives. So that actual probability of being positive with a positive test result is</p>
<p><span class="math display">\[\frac{true~positives}{true~positives + false~positives}=10\%\]</span></p>
<div class="cell" data-hash="probability-and-hypothesis-testing_cache/html/unnamed-chunk-28_f173fd378a60d2a393a800287be18034">
<div class="cell-output-display">
<p><img src="probability-and-hypothesis-testing_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p>Formally, this is described by Bayes’s Formula</p>
<p><span class="math display">\[P(A|B)=\frac{P(B|A)*P(A)}{P(B)}\]</span></p>
<p>Read: The probability of A given B is the probability of B given A times the probability of A divided by the probability of B.</p>
<p>In bayesian statistics, the prevalences are known as <strong>priors</strong>.</p>
</section><section id="concepts-discussed-today" class="level2" data-number="5.6"><h2 data-number="5.6" class="anchored" data-anchor-id="concepts-discussed-today">
<span class="header-section-number">5.6</span> Concepts discussed today</h2>
<p>After today you should be familiar with the following concepts:</p>
<ul>
<li>Null and alternative hypothesis</li>
<li>P-values and statistical significance</li>
<li>Binomial distribution</li>
<li>Probability density, probability and quantile functions</li>
<li>Effect size and statistical power</li>
<li>False positives, false negatives</li>
<li>Multiple testing and p-hacking</li>
<li>Bayes’s Theorem</li>
</ul></section><section id="exercises" class="level2" data-number="5.7"><h2 data-number="5.7" class="anchored" data-anchor-id="exercises">
<span class="header-section-number">5.7</span> Exercises</h2>
</section><section id="a-fair-coin" class="level2" data-number="5.8"><h2 data-number="5.8" class="anchored" data-anchor-id="a-fair-coin">
<span class="header-section-number">5.8</span> A Fair Coin</h2>
<p>We have a regular old coin and flip it 100 times. Given a significance threshold <span class="math inline">\(\alpha\)</span> of 0.05, with what probability do we (mistakenly) reject the null hypothesis i.e. conclude that the coin is not fair even though it is? Can you show this with a simulation? As a tip I can tell you that due to the vectorized nature of the functions involved you won’t need a <code>map</code> or loop. The shortest version I could think of uses only 3 functions.</p>
</section><section id="an-unfair-game" class="level2" data-number="5.9"><h2 data-number="5.9" class="anchored" data-anchor-id="an-unfair-game">
<span class="header-section-number">5.9</span> An Unfair Game</h2>
<p>We are playing a game where you have to roll the most sixes in order to win. Someone is trying to fool us and is using a loaded die. The die is manipulated such that the chance of rolling a six is 35% instead of the usual 1/6. At the same significance threshold as above, what is the chance of us rejecting the null hypothesis (= a fair die) and thus concluding correctly that we are being tricked after rolling the die 20 times? You will have to run a simulation here again.</p>
</section><section id="discovering-a-new-distribution" class="level2" data-number="5.10"><h2 data-number="5.10" class="anchored" data-anchor-id="discovering-a-new-distribution">
<span class="header-section-number">5.10</span> Discovering a new Distribution</h2>
<p>The binomial distribution was concerned with sampling with replacement (you can get head or tails any number of times without using up the coin). In this exercise you will explore sampling <strong>without</strong> replacement. The common model for this is an urn with two different colored balls in it. The resulting distribution is called the <strong>hypergeometric distribution</strong> and the corresponding R functions are <code>&lt;r/d/p/q&gt;hyper</code></p>
<ul>
<li>Imagine you are a zoo manager.
<ul>
<li>We got a gift from another zoo! It consists of 8 red pandas and 2 giant pandas. What is the probability that they end up properly separated, if we randomly take 8 animals, put them in one enclosure and put the rest in another?</li>
<li>Our penguin colony hatched eggs and we have a bunch of newcomers. We have have 15 males and 10 females. If we look at a random subset of 12 penguins, what does the distribution of the number of males look like? Which number is most likely? How likely is it, to get at least 9 males in the sample?</li>
</ul>
</li>
</ul></section><section id="resources" class="level2" data-number="5.11"><h2 data-number="5.11" class="anchored" data-anchor-id="resources">
<span class="header-section-number">5.11</span> Resources</h2>
<ul>
<li><a href="https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108" class="uri">https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108</a></li>
<li><a href="https://jimgruman.netlify.app/post/education-r/" class="uri">https://jimgruman.netlify.app/post/education-r/</a></li>
<li><a href="http://varianceexplained.org/statistics/interpreting-pvalue-histogram/">P-Value histograms blogpost by David Robinson</a></li>
<li><a href="https://www.statisticsdonewrong.com/">“Statistics done wrong”</a></li>
</ul>


</section><section id="distributions-summaries-and-dimensionality-reduction" class="level1 page-columns page-full" data-number="6"><h1 data-number="6">
<span class="header-section-number">6</span> Distributions, Summaries and Dimensionality Reduction</h1>
<pre class="{r}"><code>#| include: false
source("./_common.R")</code></pre>
<blockquote class="blockquote">
<p>… in which we explore continuous distributions with spotify data, find out about the central limit theorem and related statistical tests and become N-dimensional whale sharks.</p>
</blockquote>
<p>As it turns out this lecture got quite long. So I separated two small interludes that are not crucial to the bigger picture out into a bonus video. You can recognize the corresponding parts of the script by a prefix of [Sidenote] in the section heading. They should be interesting to watch and read but are not required for the exercises.</p>
<p>Here is the main lecture video:</p>
<p></p>
<div id="youtube-frame" style="position: relative; padding-bottom: 56.25%; /* 16:9 */ height: 0; margin-bottom: 1rem;"><iframe width="100%" height="" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" src="https://www.youtube.com/embed/uBCsxqw2kEM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>And here are the bonus bits:</p>
<p></p>
<div id="youtube-frame" style="position: relative; padding-bottom: 56.25%; /* 16:9 */ height: 0; margin-bottom: 1rem;"><iframe width="100%" height="" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" src="https://www.youtube.com/embed/zGJ_Zsw8QqY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="some-preparation" class="level2 page-columns page-full" data-number="6.1"><h2 data-number="6.1" class="anchored" data-anchor-id="some-preparation">
<span class="header-section-number">6.1</span> Some Preparation</h2>
<p>Today, we will explore the process of modeling and look at different types of models. In part, we will do so using the <strong>tidymodels</strong> framework. The tidymodels framework extends the tidyverse with specialized tools for all kinds of modeling tasks that fit neatly in with all the tools we already know. Go ahead and install them with:</p>
<p><code>{r inst-tidy-models, eval=FALSE} install.packages("tidymodels")</code></p>
<p>Now we are ready to get started</p>
<pre class="{r}"><code><a href="https://tidyverse.tidyverse.org">library(tidyverse)
library(tidymodels)</a></code></pre>
<section id="sidenote-on-reproducible-environments-with-renv" class="level3 page-columns page-full" data-number="6.1.1"><h3 data-number="6.1.1" class="anchored" data-anchor-id="sidenote-on-reproducible-environments-with-renv">
<span class="header-section-number">6.1.1</span> [Sidenote] on Reproducible Environments with <code>renv</code>
</h3>
<aside><a href="https://rstudio.github.io/renv/"> <img src="images/renv.svg" class="img-fluid" width="200"></a>
</aside><p>At this point, we have installed quite a lot of packages. On one hand, this is great fun because the extend what we can do and make tedious tasks fun. On the other hand, every package that we add introduces what is called a dependency. If a user doesn’t have the package installed, our analysis will not run. If we are feeling experimental and use functions from packages that are under active development and might change in the future, we will run into trouble when we update the package. But never updating anything ever again is no fun! I will show you, how to get the best of both worlds: All the packages and functions that your heart desires while maintaining complete reproducibility. This is to make sure that you can come back to your old projects 2 years from now and they still just run as they did at the time.</p>
<p>This solution is a package called <code>renv</code>. The idea is as follows: Instead of installing all your packages into one place, where you can only have one version of a package at a time, <code>renv</code> installs packages locally <strong>in your project</strong> folder. It also meticulously writes down the version numbers of all the packages you installed and keeps a cache, so it will not copy the same version twice.</p>
<p>It is an R package like any other, so first, we install it with:</p>
<p><code>{r inst-renv, eval=FALSE} install.packages("renv")</code></p>
<p>Then, in our RStudio project in the R console, we initialize the project to use <code>renv</code> with:</p>
<p><code>{r eval=FALSE} renv::init()</code></p>
<p>This does a couple of things. It creates a file named <code>.Rprofile</code>, in which it writes <code>source("renv/activate.R")</code>. The R-profile file is run automatically every time you start a R session in this folder, so it makes sure <code>renv</code> is active every time you open the project. It also creates a folder called <code>renv</code>. This is the where it will install packages you want to use in the project. The most important file is the <code>renv.lock</code> file. You can have a look at it, it is just a text file with all the packages and their exact versions.</p>
<p>You notice, that after initializing renv, we have no packages, so for example we can’t load the tidyverse as usual. We will have to install it again! However, in this case it should be fairly fast, because renv knows that it was already installed globally so it simply copies the files, which is fast. After having installed a new package, we call:</p>
<p><code>{r, eval=FALSE} renv::snapshot()</code></p>
<p>Renv tells us, what we changed in our environment and after we confirm, it notes down the changes.</p>
<p>Not it is also really easy to collaborate with other people. Because after we send them our project folder, all they have to do is run:</p>
<p><code>{r, eval=FALSE} renv::restore()</code></p>
<p>To install all packages noted down in the lockfile. We can also use this ourselves if we installed a few to many packages or did an update we regret and want to go back to what is written in the lockfile.</p>
<p>Finally, renv also provides functions to update or install new packages. They work like <code>install.packages</code>, but a bit more versatile. For example, let me show you the different locations from which we can install packages.</p>
<ol type="1">
<li>The main location is <a href="https://cran.r-project.org/">CRAN</a> (The Comprehensive R Archive Network). This is also from where you installed R itself. R packages on there are subject to certain standards and usually stable and tested.</li>
<li>We can also install packages directly from the source code other people uploaded. <a href="https://github.com/">GitHub</a> is a platform where you can upload code and track changes to it. A lot of times, you can find the current developement version of an R package, or packages that are not yet on CRAN on GitHub.</li>
</ol>
<p><code>renv</code> can install packages from GitHub as well, for example let us say, we want to test out the latest version of the <code>purrr</code> package to give feedback to the developers.</p>
<p><a href="https://github.com/tidyverse/purrr" class="uri">https://github.com/tidyverse/purrr</a> here it says:</p>
<p><code>{r eval=FALSE} # ... # Or the the development version from GitHub: # install.packages("devtools") devtools::install_github("tidyverse/purrr")</code></p>
<p>Well, we don’t need devtools for this, because <code>renv</code> can do this with the regular install function:</p>
<p><code>{r eval=FALSE} renv::install("tidyverse/purrr")</code></p>
<p>Giving it just a package name installs a package from CRAN, a pattern of <code>"username/packgename"</code> installs from GitHub. Now, back to the actual topic of today!</p>
<p>After having initialized <code>renv</code> we need to install the packages that we need for the project even if we already have them in our global package cache, just so that <code>renv</code> knows about them.</p>
</section></section><section id="all-models-are-wrong-but-some-are-useful" class="level2 page-columns page-full" data-number="6.2"><h2 data-number="6.2" class="anchored" data-anchor-id="all-models-are-wrong-but-some-are-useful">
<span class="header-section-number">6.2</span> All models are wrong, but some are useful</h2>
<blockquote class="blockquote">
<p><em>“All models are wrong, but some are useful”</em> — George Box</p>
</blockquote>
<p>What this means is that any model is but a simplification of reality and must always omit details. No model can depict the complete underlying reality. However, models are useful, and to understand what they are useful for, we must first look at the different types of models out there.</p>
<section id="types-of-models" class="level3 page-columns page-full" data-number="6.2.1"><h3 data-number="6.2.1" class="anchored" data-anchor-id="types-of-models">
<span class="header-section-number">6.2.1</span> Types of Models</h3>
<aside><a href="https://www.tidymodels.org/"> <img src="images/tidymodels.svg" class="img-fluid" width="200"></a>
</aside><p>The <a href="https://www.tmwr.org/software-modeling.html#types-of-models">tidymodels book</a> names three types of models, where any particular model can fall into multiple categories at once:</p>
<ol type="1">
<li>
<strong>Descriptive Models</strong>&nbsp; are purely used to describe the underlying data to make patters easier to see. When we add a smooth line to a ggplot with <code>geom_smooth</code>, the default method is a so called LOESS curve, which stands for Locally Estimated Scatterplot Smoothing. It does produce insights by revealing patterns to us, but by itself can not be used e.g.&nbsp;to make predictions. It is just a pretty looking smooth line.</li>
</ol>
<p><code>{r echo=FALSE, out.width="20%"} mpg %&gt;%    ggplot(aes(displ, hwy)) +   geom_smooth() +   geom_point()</code></p>
<ol start="2" type="1">
<li><p><strong>Inferential Models</strong>&nbsp; are designed to test hypothesis or make decisions. They rely heavily on our assumptions about the data (e.g.&nbsp;what probability distribution the populations follows) and will be most likely encountered by you to answer research questions. They are the models that typically produce a p-value, which you compare to a threshold like we did last week.</p></li>
<li><p><strong>Predictive Models</strong>&nbsp; are designed to process the data we have and make predictions about some response variable upon receiving new data. When done correctly, we also hold out on some of the data that our model never gets to see, until it is time to evaluate and test how it performs on unseen data. Depending on how much we know (or want to know) about the underlying processes, we differentiate between <strong>mechanistic</strong> models like fitting a physically meaningful function to data and <strong>empirically driven</strong> models, which are mainly concerned with creating good predictions, no matter the underlying mechanism.</p></li>
</ol>
<p>We will now explore different examples. First, let me introduce our dataset for today:</p>
</section></section><section id="say-hello-to-spotify-data" class="level2" data-number="6.3"><h2 data-number="6.3" class="anchored" data-anchor-id="say-hello-to-spotify-data">
<span class="header-section-number">6.3</span> Say Hello to Spotify Data</h2>
<p>I created a playlist on spotify, which is quite diverse so that we can look at a range of features. You can even listen to it <a href="https://open.spotify.com/playlist/2Ljg7QjvftQ7qNbGiM2Qzd?si=_DqZqE1xTmKoFqp898cftA">here</a> while you do the exercises if you want. I am doing so, as I write this. The cool thing about spotify is, that they have an API, an Application Interface. APIs are ways for computer programs to talk to each other. So while we use the spotify app to look up songs, computers use the API to talk to the spotify server. And because R has a rich ecosystem of packages, someone already wrote a package that allows R to talk to this API: <a href="https://www.rcharlie.com/spotifyr/index.html"><code>spotifyr</code></a>.</p>
<p>If you check out the R folder in this lecture, you can see how I downloaded and processed that data about the playlist. Note that the script will not work for you right away, because you first need to register with spotify as a developer and then get a so called token, like a username and password in one long text, to be allowed to send bots their way. You probably just want to download the data from my github repository.</p>
<p>Let’s have a look, shall we?</p>
<pre class="{r}"><code>songs &lt;- read_csv("data/06/spotify_playlist.csv")</code></pre>
<p>We can get a quick overview of all columns with:</p>
<pre class="{r}"><code>glimpse(songs)</code></pre>
<p>Finally some decent numbers! Not just these measly discrete values we had last week. For each song in the playlist, we get the artist, the year it arrived and a number of features like how danceable, how loud or fast the song is. You can easily imagine spotify using these numbers to suggest new songs based on the features of those that you have listened to. And in fact, we are going to lay the foundations for such an algorithm today.</p>
</section><section id="visualising-continuous-distributions" class="level2" data-number="6.4"><h2 data-number="6.4" class="anchored" data-anchor-id="visualising-continuous-distributions">
<span class="header-section-number">6.4</span> Visualising Continuous Distributions</h2>
<p>When dealing with a continuous distribution, like we have for a lot of our features in the spotify songs dataset, there are always multiple ways to represent the same data. First, we just look at the numbers. We will use the <code>valence</code> values for our songs:</p>
<pre class="{r}"><code>head(songs$valence)</code></pre>
<p>Notice anything interesting in the numbers? I don’t either. Our brain is way better suited for looking at graphical representations, so: <strong>To the ggplot cave</strong>!</p>
<pre class="{r}"><code>songs %&gt;% 
  ggplot(aes(x = "", y = valence)) +
  geom_point()</code></pre>
<p>This is kind of hard to see, because points overlap. We can get a better picture of the distribution by using transparency or a bit of jitter:</p>
<pre class="{r}"><code>songs %&gt;% 
  ggplot(aes(x = "", y = valence)) +
  geom_jitter(width = 0.1)</code></pre>
<p>Using a histogram, we can put the points into bins and get a plot similar to what we got for discrete values. Note that the plot is flipped on it’s side now.</p>
<pre class="{r}"><code>songs %&gt;% 
  ggplot(aes(valence)) +
  geom_histogram()</code></pre>
<p>And we might want to play around with the bin size to get a better feel for the distribution. Another way is to apply a smoothing function and estimate the density of points along a continuous range, even in places where we originally had no points:</p>
<pre class="{r}"><code>songs %&gt;% 
  ggplot(aes(valence)) +
  geom_density(fill = "midnightblue", alpha = 0.6)</code></pre>
<p>Both of these plots can be misleading, if the original number of points is quite small, and in most cases, we are better off, showing the actual individual points as well. This is the reason, why the first plots I did where vertical, because there is a cool way of showing both the points and the distribution, while still having space to show multiple distributions next to each other. Imagine taking the density plot, turning it 90 degrees and then mirroring through the middle. What we get is a so called <strong>violin plot</strong>. To overlay the points on top, we will use something a little more predictable than <code>jitter</code> this time: From the <code>ggbeeswarm</code> package I present: <code>geom_quasirandom</code>.</p>
<pre class="{r}"><code>songs %&gt;% 
  ggplot(aes(x = "", y = valence)) +
  geom_violin(fill = "midnightblue", alpha = 0.6) +
  ggbeeswarm::geom_quasirandom(width = 0.35)</code></pre>
<p>This is cool, because now we can easily compare two different distributions next to each other and still see all the individual points. For example, we might ask:</p>
<blockquote class="blockquote">
<p>“Do songs in major cord have a higher valence than songs in minor cord in our dataset?”</p>
</blockquote>
<pre class="{r}"><code>songs %&gt;% 
  filter(!is.na(mode), !is.na(valence)) %&gt;% 
  ggplot(aes(x = factor(mode), y = valence)) +
  geom_violin(fill = "midnightblue", alpha = 0.6) +
  ggbeeswarm::geom_quasirandom(width = 0.35) +
  scale_x_discrete(labels = c(`0` = "minor", `1` = "major"))</code></pre>
<blockquote class="blockquote">
<p><strong>Note</strong>: This jittering only works, because the feature on the x-axis is discrete. If it where continuous, we would be changing the data by jittering on the x-axis.</p>
</blockquote>
<p>We might also want to add summaries like the mean for each group to the plot with an additional marker. This leads us to the general concept of <strong>summary statistics</strong>. There is a number of them, and they can be quite useful to, well, summarise a complex distribution. But they can also be very misleading, as can any simplification be.</p>
</section><section id="summary-statistics" class="level2" data-number="6.5"><h2 data-number="6.5" class="anchored" data-anchor-id="summary-statistics">
<span class="header-section-number">6.5</span> Summary Statistics…</h2>
</section><section id="mean-median-and-other-quartiles-range" class="level2" data-number="6.6"><h2 data-number="6.6" class="anchored" data-anchor-id="mean-median-and-other-quartiles-range">
<span class="header-section-number">6.6</span> Mean, Median (and other Quartiles), Range</h2>
<p>Let us start by considering different things we can say about our distribution in one number. First, we might look at the range of our numbers, the maximum and minimum. We will do this per mode, so we can compare the values. Next, we want to know the centers of the points. There are different notions of being at the center of the distribution. The <strong>mean</strong> or <em>average</em> is the sum of all values divided by the number of values. The <strong>median</strong> is what we call a quantile, a point that divides a distribution in equally sized parts, specifically such that 50% values are below and 50% are above the median.</p>
<pre class="{r}"><code>songs %&gt;% 
  drop_na(valence, mode) %&gt;% 
  group_by(mode) %&gt;% 
  summarise(
    min = min(valence),
    max = max(valence),
    mean = mean(valence),
    median = median(valence)
  )</code></pre>
<p>It appears the valence can assume values between 0 and 1. A shortcut for this is the <code>range</code> function:</p>
<pre class="{r}"><code>range(songs$valence)</code></pre>
<p>The median is just one of the many percentiles we can think of. If we display the 50th as well as the 25th and 75th percentile on one plot, we get what is called a boxplot:</p>
<pre class="{r}"><code># in the lecture I used filter(!is.na(mode), !is.na(valence)),
# but drop_na is more elegant.

songs %&gt;% 
  drop_na(valence, mode) %&gt;% 
  ggplot(aes(x = factor(mode), y = valence)) +
  geom_boxplot(fill = "midnightblue", alpha = 0.6, outlier.color = NA) +
  ggbeeswarm::geom_quasirandom(width = 0.35) +
  scale_x_discrete(labels = c(`0` = "minor", `1` = "major"))</code></pre>
<p>The “whiskers” of the box extend to 1.5 times the box size or to the last data point, whichever makes smaller whiskers. Points that are more extreme than the whiskers are labeled outliers by the boxplot and usually displayed as their own points. Like with the violin plot, we also have the option to plot the original un-summarized points on top. In this case, we need to make sure to change the outlier color for the boxplot to <code>NA</code>, because otherwise we are plotting them twice.</p>
<p>This hints at one downside of boxplots (when used without adding the raw datapoints as well): The box is a very prominent focus point of the plot, but by definition, it only contains 50% of all datapoints. The rest is delegated to thin whiskers.</p>
<section id="variance" class="level3" data-number="6.6.1"><h3 data-number="6.6.1" class="anchored" data-anchor-id="variance">
<span class="header-section-number">6.6.1</span> Variance</h3>
<p>Finally, we want to know, how far the values scatter around their means and the potential population mean. This is encompassed in two closely related measures: the <strong>variance</strong> and the <strong>standard deviation</strong>.</p>
<p>For illustrative purposes, we can plot all datapoints for e.g the valence in the order in which they appear in the data and add a line for the mean.</p>
<p><code>{r valence-mean} songs %&gt;%   filter(!is.na(valence)) %&gt;%    mutate(index = 1:n()) %&gt;%    ggplot(aes(index, valence)) +   geom_segment(aes(y = mean(valence),                    yend = mean(valence),                    x = 0,                    xend = length(valence))) +   geom_segment(aes(xend = index, yend = mean(valence)),                color = "darkred", alpha = 0.6) +   annotate(x = length(songs$valence),            y = mean(songs$valence, na.rm = TRUE),            label = "Mean",            geom = "text") +   geom_point()</code></p>
<blockquote class="blockquote">
<p>The variance is the expected value of the squared deviation of a random variable from its mean.</p>
</blockquote>
<p>In other words: Take the distance of all points to the mean and sum them (add all red lines in the plot above together) and then divide by <span class="math inline">\(n-1\)</span>.</p>
<p><span class="math display">\[var(X) = \frac{\sum_{i=0}^{n}{(x_i-\bar x)^2}}{(n-1)}\]</span></p>
<p>“Hang on!”, I hear you saying: “Why <span class="math inline">\(n-1\)</span>?”. And it is an excellent question. The first statement talked about an expected value. (One example of an expected value is the mean, which is the expected value of… well, the values). And indeed, and expected value often has the term <span class="math inline">\(1/n\)</span>. But the statement was talking about the expected value (of the squared deviation) for <strong>the whole population</strong>. We can only use the uncorrected version when we have the whole population (e.g.&nbsp;all songs that ever existed) and want to talk about that population. But usually, all we have is a <strong>sample</strong>, from which we want to draw conclusions about the population. But when we are using the sample to estimate the variance of the population, it will be biased. We can correct for this bias by using <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span>. This is known as Bessel’s correction. I am yet to come by a really intuitive explanation, but here is one idea: The thing we are dividing by is not necessarily the sample size any time we want to try to calculate the expected value of an estimator, it just happens to be the sample size in a bunch of cases. What the term really represents here is the <strong>degrees of freedom</strong> (DF) of the deviations. DFs can be thought of as the number of independent things. The degrees of freedom are <span class="math inline">\(n\)</span> reduced by <span class="math inline">\(1\)</span>, because if we know the mean of a sample (we use it in our calculation), once we know all but <span class="math inline">\(1\)</span> of the individual values, the last value is automatically known and thus doesn’t count towards the degrees of freedom.</p>
</section><section id="standard-deviation" class="level3" data-number="6.6.2"><h3 data-number="6.6.2" class="anchored" data-anchor-id="standard-deviation">
<span class="header-section-number">6.6.2</span> Standard deviation</h3>
<p>Next up: The <strong>Standard Deviation</strong> (SD) is the square root of the variance. Which is more commonly used on error bars, because the square root inverts the squaring that was done to get the variance. So we are back in the dimensions of the data.</p>
<p><span class="math display">\[\sigma_X=\sqrt{var(X)}\]</span></p>
</section><section id="standard-error-of-the-mean" class="level3" data-number="6.6.3"><h3 data-number="6.6.3" class="anchored" data-anchor-id="standard-error-of-the-mean">
<span class="header-section-number">6.6.3</span> Standard Error of the Mean</h3>
<p>Finally, we have the <strong>Standard Error of the Mean</strong>, sometimes only called Standard Error (SEM, SE). It is also used very commonly in error bars. The reason for a lot of people to favor it over the SD might just be, that it is smaller, but they have distinct use-cases.</p>
<p><span class="math display">\[SEM=\sigma / \sqrt{n}\]</span></p>
<p>We take the standard deviation and divide it by the square-root of <span class="math inline">\(n\)</span>. Imagine this: We actually have the whole population available. Like for example all penguins on earth. And then we repeatedly take samples of size <span class="math inline">\(n\)</span>. The means of these individual samples will vary, so it will have it’s own mean, standard deviation and variance. The standard error is the standard deviation of these means. So it is a measure of how far the means of repeated samples scatter around the true population mean. However, we don’t usually have the whole population! Measuring some property of all penguins in the world takes a long time, and running an experiment in the lab for all cells that exist and will ever exist takes an infinite amount of time. This is probably more than our research grant money can finance. So, instead, the Standard Error of the Mean used the standard deviation of our sample in the formula above. It is our best estimate for the standard deviation of the whole population. So, when you are trying so make inferences about the mean of the whole population based on your sample, it makes sense to also give the SEM as a way of quantifying the uncertainty.</p>
<p>While R has functions for <code>sd</code>, <code>mean</code> and <code>var</code>, there is not built in function for the <code>sem</code>, but we can easily write one ourselves:</p>
<pre class="{r}"><code>sem &lt;- function(x) sd(x) / sqrt(length(x))</code></pre>
<pre class="{r}"><code>songs %&gt;% 
  drop_na(mode, valence) %&gt;% 
  group_by(mode) %&gt;% 
  summarise(
    mean = mean(valence),
    var = var(valence),
    sd = sd(valence),
    sem = sem(valence)
  )</code></pre>
</section></section><section id="or-how-to-lie-with-graphs" class="level2" data-number="6.7"><h2 data-number="6.7" class="anchored" data-anchor-id="or-how-to-lie-with-graphs">
<span class="header-section-number">6.7</span> … or: How to Lie with Graphs</h2>
<p>However, be very wary of simple bar graphs with error bars; there is a lot that can be misleading about them.</p>
<p><code>{r horrible-plot} songs %&gt;%    drop_na(speechiness, mode) %&gt;%    group_by(mode) %&gt;%   summarise(across(speechiness, list(m = mean, sd = sd, sem = sem))) %&gt;%    ggplot(aes(factor(mode), speechiness_m, fill = factor(mode))) +   geom_errorbar(aes(ymin = speechiness_m - speechiness_sem,                     ymax = speechiness_m + speechiness_sem,                     color = factor(mode)),                 size = 1.3, width = 0.3, show.legend = FALSE) +   geom_col(size = 1.3, show.legend = FALSE) +   coord_cartesian(ylim = c(0.06, 0.08)) +   scale_fill_manual(values = c("#1f6293", "#323232")) +   scale_color_manual(values = c("#1f6293", "#323232")) +   labs(title = "Don't Do This at Home!",        y = "Speechiness",        x = "Mode (Minor / Major)") +   theme(     plot.title = element_text(size = 44, family = "Daubmark",                               color = "darkred")   )</code></p>
<p>When people say “The y-axis has to include 0”, this is the reason for it. It is no always true, when there is another sensible baseline that is not 0, but especially for barplots not having the y-axis start at 0 is about the most misleading thing you can do. The main reason for this is that humans perceive the height of the bars via their area, and this is no longer proportional when the bars don’t start at 0. This plot also makes no indication of the type of error-bars used or the sample size in each group. It uses the <code>speechiness</code> feature, but it hides the actual distribution behind just 2 numbers (mean and SEM) per group.</p>
<pre class="{r}"><code>songs %&gt;% 
  ggplot(aes(speechiness, color = factor(mode), fill = factor(mode))) +
  geom_density(alpha = 0.3)</code></pre>
<p>So the next time you see a barplot ask the question:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="images/summary_statistics.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Summary statistics by <span class="citation" data-cites="ArtworkAllisonHorst">Horst (<a href="references.html#ref-ArtworkAllisonHorst" role="doc-biblioref">2020</a>)</span></figcaption><p></p>
</figure>
</div>
<p>I hope you can take some inspiration from this chapter and now have the vocabulary to know where to look when it comes to your own data.</p>
</section><section id="graphic-devices-fonts-and-the-ggplot-book" class="level2" data-number="6.8"><h2 data-number="6.8" class="anchored" data-anchor-id="graphic-devices-fonts-and-the-ggplot-book">
<span class="header-section-number">6.8</span> Graphic Devices, Fonts and the ggplot Book</h2>
<section id="ggplot-book" class="level3" data-number="6.8.1"><h3 data-number="6.8.1" class="anchored" data-anchor-id="ggplot-book">
<span class="header-section-number">6.8.1</span> ggplot book</h3>
<p>Firstly, for all things <code>ggplot</code>, the third edition of the <strong>ggplot book</strong> is currently being worked on by three absolute legends of their craft <span class="citation" data-cites="WelcomeGgplot2 wickhamGgplot2ElegantGraphics2016">(<a href="references.html#ref-WelcomeGgplot2" role="doc-biblioref"><span>“Welcome | Ggplot2,”</span> n.d.</a>; <a href="references.html#ref-wickhamGgplot2ElegantGraphics2016" role="doc-biblioref">Wickham 2016</a>)</span>. <a href="http://hadley.nz/">Hadley Wickham</a> is the author of the original ggplot and ggplot2 package, <a href="https://djnavarro.net/">Danielle Navaro</a> makes amazing artwork with and teaches ggplot and <a href="https://www.data-imaginist.com/about">Thomas Lin Pedersen</a> is the current maintainer of ggplot2 and constantly makes cool features for it. The under-development book is already available online for free: <a href="https://ggplot2-book.org/" class="uri">https://ggplot2-book.org/</a>.</p>
</section><section id="sidenote-graphics-devices" class="level3" data-number="6.8.2"><h3 data-number="6.8.2" class="anchored" data-anchor-id="sidenote-graphics-devices">
<span class="header-section-number">6.8.2</span> [Sidenote] Graphics Devices</h3>
<p>Secondly, we need to briefly talk about a concept we have only brushed by: <strong>graphics devices</strong> are to R what your printer is to your computer. When we create a plot in R, it starts out as mere numbers, but something has to turn these numbers into pixels (in the case of raster-images) or vectors (in the case of vector images; you might know svg or pdf files. Sorry, but these are not the vectors in R but rather descriptions of lines). This is the job ob the graphics device. When we use the <code>ggsave</code> function for example, it figures out what to use based on the file extension, but we can also specify it manually. I am mentioning this here, because in the plot I just showed you, I used a different font than the default. This is something that can be incredibly tricky for graphics devices, because fonts are handled differently on every operating system. Luckily, it is about to get way easier, because Thomas Lin Pedersen is working on another package, a graphics device, that is both really fast and works well with fonts. You can check the current development version here: <a href="https://ragg.r-lib.org/" class="uri">https://ragg.r-lib.org/</a></p>
<p>Here are some examples of using graphics devices manually by opening the device first and then finalizing the plot by closing the device:</p>
<p>```{r, eval=FALSE} png(“myplot.png”)</p>
<p>songs %&gt;% ggplot(aes(speechiness, color = factor(mode), fill = factor(mode))) + geom_density(alpha = 0.3)</p>
<p>dev.off()</p>
<pre><code>
```{r, eval=FALSE}
svg("myplot.svg")

songs %&gt;% 
  ggplot(aes(speechiness, color = factor(mode), fill = factor(mode))) +
  geom_density(alpha = 0.3)

dev.off()</code></pre>
<p>Or by manually specifying the device in <code>ggsave</code>.</p>
<p>```{r, eval=FALSE} plt &lt;- songs %&gt;% ggplot(aes(speechiness, color = factor(mode), fill = factor(mode))) + geom_density(alpha = 0.3)</p>
<p>ggsave(“newplot.png”, plt, device = ragg::agg_png)</p>
<pre><code>
## The Normal Distribution and the Central Limit Theorem

There are many different distributions out there.
Luckily, one of them is quite special and can
be used in a multitude of settings.
It is the harmlessly named **Normal Distribution**.
R has the usual functions for it (density,
probability, quantile, random).

```{r, out.width="50%", fig.show='hold'}
tibble(x = seq(-3, 3, 0.01)) %&gt;% 
  ggplot(aes(x)) +
  geom_function(fun = dnorm) +
  stat_function(geom = "area", fun = dnorm,
              fill = "darkblue", alpha = 0.3) +
  labs(y = "density", title = "Normal Distribution Density")

tibble(x = seq(-3, 3, 0.01)) %&gt;% 
  ggplot(aes(x)) +
  geom_function(fun = pnorm) +
  labs(y = "probability", title = "Cummulative Probability")</code></pre>
<p>Now, why is is distribution so special?</p>
<blockquote class="blockquote">
<p>The <strong>Central Limit Theorem</strong> (CLT) states that the sample mean of a sufficiently large number of independent random variables is approximately normally distributed. The larger the sample, the better the approximation.</p>
</blockquote>
<p>For a great visualization of the central limit theorem, check out this interactive tutorial by <a href="https://seeing-theory.brown.edu/probability-distributions/index.html#section3">Seeing Theory</a>.</p>
<p>Because a lot of values we measure are actually the sum of many random processes, distributions of things we measure can often be approximated with a normal distribution.</p>
<p>We can visually test if some values follow the normal distribution by using a quantile-quantile plot, which plots the quantiles of our sample against where the quantiles should be on the normal distribution. A straight line means it is perfectly normal.</p>
<pre class="{r}"><code>qqnorm(songs$valence)
qqline(songs$valence, col = "red")</code></pre>
<p>The values close to the mean are pretty normal, but the tails of the distribution stray further from the normal distribution. There are way more very small and very large values than would be expected from a normal distribution.</p>
</section><section id="log-normality" class="level3" data-number="6.8.3"><h3 data-number="6.8.3" class="anchored" data-anchor-id="log-normality">
<span class="header-section-number">6.8.3</span> Log-normality</h3>
<p>There is one thing that comes up a lot in biological data: because a lot of processes in biology are reliant on signal cascades, they tend to be the result of many multiplicative effects, rather than additive effects, as would be required for the Central Limit Theorem. As a result, they are not distributed normally, but rather log-normally, because taking the logarithm of all values transforms multiplicative effects into additive effects!</p>
</section></section><section id="the-t-distribution" class="level2" data-number="6.9"><h2 data-number="6.9" class="anchored" data-anchor-id="the-t-distribution">
<span class="header-section-number">6.9</span> The T-Distribution</h2>
<p>The CLT is only valid for <strong>large sample sizes</strong>. For smaller sample sizes, the distribution of means has fatter tails than a normal distribution. This is why for most statistical tests, we use the <strong>t-distribution</strong> instead of the normal distribution. As the degrees of freedom get higher, the t-distribution approaches the normal distribution.</p>
<p>```{r tdist, fig.cap=“t-distributions; normal distribution in black.”} base &lt;- ggplot() + xlim(-5, 5)</p>
<p>base + geom_function(aes(colour = “t, df = 1”), fun = dt, args = list(df = 1), size = 1.2) + geom_function(aes(colour = “t, df = 3”), fun = dt, args = list(df = 3), size = 1.2) + geom_function(aes(colour = “t, df = 30”), fun = dt, args = list(df = 30), size = 1.2) + geom_function(aes(colour = “normal”), fun = dnorm, size = 1.2) + guides(color = guide_legend(title = ““)) + scale_color_viridis_d()</p>
<pre><code>
Remember the valence plot by mode?

```{r}
songs %&gt;% 
  ggplot(aes(factor(mode), valence)) +
  geom_violin(fill = "darkblue", alpha = 0.3) +
  ggbeeswarm::geom_quasirandom(alpha = 0.6)</code></pre>
<p>For our purposes we are going to treat these two distributions as close enough to a normal distribution at first so that we can look at some hypothesis tests:</p>
</section><section id="students-t-test" class="level2" data-number="6.10"><h2 data-number="6.10" class="anchored" data-anchor-id="students-t-test">
<span class="header-section-number">6.10</span> Student’s T-Test</h2>
<p>The first test is called student’s t-test. “Student” was the pseudonym of it’s inventor. And the “t” stands for the t-distribution. We can use it to test the null hypothesis, that two samples come from the same (approximately normal) distribution.</p>
<pre class="{r}"><code>t.test(valence ~ mode, data = songs)</code></pre>
<p>The two samples are so similar that is is quite likely for those values to have come form the same distribution, so we would not reject the null hypothesis.</p>
<p>Let us pretend for a moment that there is in fact a difference by creating some fake data (don’t do this in the lab…).</p>
<pre class="{r}"><code>fake_songs &lt;- songs %&gt;% 
  drop_na(mode, valence) %&gt;% 
  mutate(valence = if_else(mode == 1, valence + 0.2, valence))</code></pre>
<pre class="{r}"><code>fake_songs %&gt;% 
  ggplot(aes(valence, color = factor(mode), fill = factor(mode))) +
  geom_density(alpha = 0.3)</code></pre>
<p>Now we end up with a statistically significant p-value.</p>
<pre class="{r}"><code>t.test(valence ~ mode, data = fake_songs)</code></pre>
<p>Note, that the p-value itself says nothing about the effect size, the difference in means between the sample. You can get a significant p-value either by showing a tiny difference with lot’s of data points or by showing a larger difference with less data points.</p>
<p>Tests, that rely on the assumption of normality are called <strong>parametric tests</strong>, but when this assumption can not be met, we need <strong>non-parametric tests</strong>.</p>
</section><section id="wilcoxon-rank-sum-test" class="level2" data-number="6.11"><h2 data-number="6.11" class="anchored" data-anchor-id="wilcoxon-rank-sum-test">
<span class="header-section-number">6.11</span> Wilcoxon rank-sum test</h2>
<p>The Wilcoxon rank-sum test, or Mann–Whitney U test, is one of these. I get’s around the assumption of normality by transforming the data into <strong>ranks</strong> first. i.e.&nbsp;all points (independent of group) are ordered and their values replaced by their position in the ordering (their rank). If we think of the t-test as testing for a difference in means, we can think of the Wilcoxon rank-sum test as testing for a difference in medians.</p>
<pre class="{r}"><code>x &lt;- c(1, 3, 2, 42, 5, 1000)
x
rank(x)</code></pre>
<pre class="{r}"><code>wilcox.test(valence ~ mode, data = songs)</code></pre>
<section id="direction-of-testing" class="level3" data-number="6.11.1"><h3 data-number="6.11.1" class="anchored" data-anchor-id="direction-of-testing">
<span class="header-section-number">6.11.1</span> Direction of Testing</h3>
<p>Both tests have the argument <code>alternative</code>, which can be any of <code>c("two.sided", "less", "greater")</code>. This is the direction of our alternative hypothesis. Are we testing, for x being greater or less than y? Or are we testing for a difference in any direction (the default)? Having a hypothesis about the direction beforehand will result in smaller p-values (half of the two-sided ones), but you need to have this hypothesis before looking at the data, and especially not after running e.g.&nbsp;the two sided test and then deciding, that you want a smaller p-value! This is not how p-values work.</p>
<pre class="{r}"><code>t.test(valence ~ mode, data = fake_songs, alternative = "less")</code></pre>
<pre class="{r}"><code>fake_songs %&gt;% 
  ggplot(aes(valence, color = factor(mode), fill = factor(mode))) +
  geom_density(alpha = 0.3)</code></pre>
<p>If you are unsure about how to tell the functions, which of two groups is supposed to be greater or lesser, you can also supply the data as <code>x</code> and <code>y</code> instead of using the formula interface as I did above:</p>
<pre class="{r}"><code>valence_major &lt;- fake_songs %&gt;% filter(mode == 1) %&gt;% pull(valence)
valence_minor &lt;- fake_songs %&gt;% filter(mode == 0) %&gt;% pull(valence)

t.test(valence_major, valence_minor, alternative = "greater")</code></pre>
<p>If we save the result of the test, we can inspect the object further and extract information from it.</p>
<pre class="{r}"><code>test &lt;- t.test(valence_major, valence_minor, alternative = "greater")
test$p.value</code></pre>
</section><section id="confidence-intervals" class="level3" data-number="6.11.2"><h3 data-number="6.11.2" class="anchored" data-anchor-id="confidence-intervals">
<span class="header-section-number">6.11.2</span> Confidence Intervals</h3>
<p>The t.test on a lonely sample can also be used to create confidence intervals around a mean. In short for example a 95% confidence interval is the range in which we would expect the mean of a sample to fall in 95% of cases when we repeat an experiment an infinite amount of times. These confidence intervals are also sometimes used as error bars in plots.</p>
<pre class="{r}"><code>test &lt;- t.test(songs$valence)
test$conf.int</code></pre>
</section></section><section id="chrunching-dimensions-with-dimensionality-reduction-pca" class="level2" data-number="6.12"><h2 data-number="6.12" class="anchored" data-anchor-id="chrunching-dimensions-with-dimensionality-reduction-pca">
<span class="header-section-number">6.12</span> Chrunching Dimensions with Dimensionality Reduction: PCA</h2>
<p>Lastly for today, we are going a bit out of scope. We are leaving the realm of looking at individual features and try to condense all the information into as little space as possible.</p>
<p>The general notion of Dimensionality Reduction is to take all the features that we have and construct new features from them, so that we can represent our data with fewer features while loosing little information.</p>
<p>For example, when two features are highly correlated i.e.&nbsp;one changes when the other does, we might be better off replacing them with a single new feature, that goes along the axis of maximum variance between the two. A number along this line accounts for most of the variance in these points, and the rest can be accounted for by a number describing the distance to that line (a perpendicular axis), which is less important than the first axis we found.</p>
<pre class="{r}"><code>songs %&gt;% 
  ggplot(aes(x = energy,
             y = loudness,
             label = track_name)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)</code></pre>
<p>Imagine you are whale shark!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="images/whaleshark.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Whale shark by <span class="citation" data-cites="ArtworkAllisonHorst">Horst (<a href="references.html#ref-ArtworkAllisonHorst" role="doc-biblioref">2020</a>)</span></figcaption><p></p>
</figure>
</div>
<p>And want to orient your mouth in such a way that you can eat the greatest amount of krill in one sweep.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="images/krill.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Krill by <span class="citation" data-cites="ArtworkAllisonHorst">Horst (<a href="references.html#ref-ArtworkAllisonHorst" role="doc-biblioref">2020</a>)</span></figcaption><p></p>
</figure>
</div>
<p>This is your first principal component. The second is perpendicular to the first. This is a throwback to “Math for Natural Scientists” and linear algebra, we are defining a new coordinate system here.</p>
<p>But whale sharks swim in 3 dimensions, not 2, and our data has even more dimensions, with features being represented dimensions.</p>
<blockquote class="blockquote">
<p>It can be quite hard for humans to imaging being an N-dimensional whale shark.</p>
</blockquote>
<p>But R and tidymodels has us covered.</p>
<p>PCA is not a model in itself, but rather a data preprocessing step that generates new features (the principal components), which we can later use for other models. But today, we will do just the preprocessing by itself.</p>
<p>In tidymodels, preprocessing is done by defining a <strong>recipe</strong>:</p>
<pre class="{r}"><code>songs_rec &lt;- recipe( ~ ., data = songs) %&gt;% 
  update_role(track_name, track_artists, track_uri, new_role = "id variable") %&gt;% 
  step_naomit(all_predictors()) %&gt;% 
  step_normalize(all_predictors()) %&gt;% 
  step_pca(all_predictors(), id = "pca")

songs_rec</code></pre>
<p>We then take the recipe and <strong>prepare</strong> it.</p>
<pre class="{r}"><code>songs_prep &lt;- prep(songs_rec)
songs_prep</code></pre>
<p>We can now explore, how the data looks like in these new dimensions. We do so, by <strong>baking</strong> the prepared recipe.</p>
<pre class="{r}"><code>songs_baked &lt;- bake(songs_prep, songs)
songs_baked</code></pre>
<p>The original features where replace by <strong>Principal Components</strong> that explain most of the variance. From the prepared recipe, we extract a tidy form of the step we care about (usually the last one) to see, what happened to our data. We can see, which features ended up contributing to which components by getting the results of the pca step of our recipe.</p>
<pre class="{r}"><code>terms &lt;- tidy(songs_prep, id = "pca") %&gt;% 
  mutate(component = parse_number(component))

terms</code></pre>
<p>Let’s make this a plot!</p>
<pre class="{r}"><code>colors &lt;- fishualize::fish_pal(option = "Centropyge_loricula")(5)[3:4]

terms %&gt;% 
  filter(component &lt;= 3) %&gt;% 
  mutate(terms = tidytext::reorder_within(terms, by = value, within = component)) %&gt;% 
  ggplot(aes(value, terms, fill = factor(sign(value)))) +
  geom_col() +
  scale_fill_manual(values = colors) +
  facet_wrap(~component, labeller = label_both, scales = "free") +
  tidytext::scale_y_reordered() +
  guides(fill = "none")</code></pre>
<p>We had to use 2 little helper functions from the <code>tidytext</code> package to properly order the bar. The first component is largely comprised of a high acousticness and instrumentalness and less energy in the positive direction. So we expect e.g.&nbsp;classical music to be very high on that axis. A high value on the second component means a high danceability while being low in tempo.</p>
<p>So where do our songs end up in principle component space?</p>
<pre class="{r}"><code>plt &lt;- songs_baked %&gt;% 
  ggplot(aes(PC1, PC2)) +
  geom_point(aes(text = paste(track_name, ",", track_artists)))

plotly::ggplotly(plt)</code></pre>
<p>You can now imagine, using this simpler representation of the songs in principal component space, to for example propose new songs to users based on songs that are close to songs they listened to in this representation.</p>
<p>Lastly, I want to stress, that the principal components are not created equal. The first component is always the most important. Here, we see, that almost 27% of the variance can be explained just by the first component, so exploring more than 2 really makes little sense here.</p>
<pre class="{r}"><code>tidy(songs_prep)
tibble(
  sdev = songs_prep$steps[[3]]$res$sdev,
  explained_variance = sdev^2 / sum(sdev^2),
  pc = 1:length(sdev)
) %&gt;% 
  ggplot(aes(pc, explained_variance)) +
  geom_col(fill = "darkgreen") +
  geom_text(aes(label = scales::percent_format()(explained_variance)),
            size = 3,
            vjust = 1.1,
            color = "white") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = NULL, y = "Percent variance explained by each PCA component")</code></pre>
</section><section id="exercises-1" class="level2" data-number="6.13"><h2 data-number="6.13" class="anchored" data-anchor-id="exercises-1">
<span class="header-section-number">6.13</span> Exercises</h2>
<p>The <strong>tidytuesday</strong> project also had a spotify dataset. This one es even more interesting, because it ranges across different playlists of various genres and is annotated with said genres. And it has more data (Over 30000 songs)! <strong>Download</strong> it here:</p>
<p><a href="https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md" class="uri">https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md</a></p>
<section id="the-plotty-horror-picture-show" class="level3" data-number="6.13.1"><h3 data-number="6.13.1" class="anchored" data-anchor-id="the-plotty-horror-picture-show">
<span class="header-section-number">6.13.1</span> The Plotty Horror Picture Show</h3>
<p>Sometimes we have to experience true horror to see the light in the darkness. Take the spotify data and make a plot that is truly horrible! I would appreciate a couple of sentences about your thought process and what makes your plot particularly bad. You can strike terror into the reader’s heart in multiple ways. Here are some ideas, mix and match what suits you:</p>
<ul>
<li>Make it really ugly by experimenting with different theme options.</li>
<li>Make it really misleading by defying viewer expectations and breaking all norms. You are an artist now, norms don’t apply to your art.</li>
<li>What even are axis labels?</li>
<li>Experiment with different (manual) color schemes! Using <strong>Red</strong> and <strong>Green</strong> is an excellent choice if you want to make sure your plot is unreadable for every 12th man (due to the high prevalence of red-green-blindness).</li>
<li>Try out different geoms and combinations of aesthetics, maybe find the ones that are the worst possible choice for the features.</li>
</ul></section><section id="take-a-sad-plot-and-make-it-better" class="level3" data-number="6.13.2"><h3 data-number="6.13.2" class="anchored" data-anchor-id="take-a-sad-plot-and-make-it-better">
<span class="header-section-number">6.13.2</span> Take a Sad Plot and Make it Better</h3>
<p>The title of this exercise is stolen from <a href="https://alison.rbind.io/talk/2018-ohsu-sad-plot-better/">this talk</a> by Alison Hill.</p>
<p>Now use what you learned to make a great plot! Pick some features that you are interested in and visualize them as informative and beautiful as possible, while still staying honest to the data. Maybe you are interested in changes over time, maybe you find your favorite artist and want to situate them in the context of other works. Maybe you want to explore how different features relate to each other or even want to attempt to recreate the PCA to see, if you can find clusters of genres. It is your call.</p>
<p>I am curious to see, what you come up with!</p>
</section></section><section id="resources-1" class="level2" data-number="6.14"><h2 data-number="6.14" class="anchored" data-anchor-id="resources-1">
<span class="header-section-number">6.14</span> Resources</h2>
<ul>
<li><a href="https://www.tidymodels.org/">Tidymodels website</a></li>
<li><a href="https://www.tmwr.org/">Tidymodels book</a></li>
<li><a href="https://ggplot2-book.org/">ggplot book</a></li>
<li><a href="https://ragg.r-lib.org/">ragg graphics device</a></li>
</ul>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-ArtworkAllisonHorst" class="csl-entry" role="doc-biblioentry">
Horst, Allison. 2020. <span>“Artwork by @Allison_horst.”</span> https://github.com/allisonhorst/stats-illustrations. <a href="https://github.com/allisonhorst/stats-illustrations">https://github.com/allisonhorst/stats-illustrations</a>.
</div>
<div id="ref-reinhartStatisticsDoneWrong2015" class="csl-entry" role="doc-biblioentry">
Reinhart, Alex. 2015. <em>Statistics <span>Done Wrong</span>: <span>The Woefully Complete Guide</span></em>. 1 edition. <span>San Francisco</span>: <span>No Starch Press</span>.
</div>
<div id="ref-WelcomeGgplot2" class="csl-entry" role="doc-biblioentry">
<span>“Welcome | Ggplot2.”</span> n.d. https://ggplot2-book.org/.
</div>
<div id="ref-wickhamGgplot2ElegantGraphics2016" class="csl-entry" role="doc-biblioentry">
Wickham, Hadley. 2016. <em>Ggplot2: <span>Elegant Graphics</span> for <span>Data Analysis</span></em>. 2nd ed. 2016 edition. <span>New York, NY</span>: <span>Springer</span>.
</div>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./functional-programming.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Functional Programming</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./distributions-summaries-and-dimensionality-reduction.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Distributions, Summaries and Dimensionality Reduction</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>