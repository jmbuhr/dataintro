[{"path":"index.html","id":"welcome","chapter":"Hello and welcome!","heading":"Hello and welcome!","text":"… latest iteration introductory R course, learn analyse data style.Current course dates\nWS21/22\n21.10.21 – 09.12.21\nLecture online time\nSeminar weekly Fridays 9:15 – 10:45\nSign-(Heidelberg University): see discord\nLanguage: Lectures English seminar can German choose \n(case can always ask questions German well).Warning: site still development, restructuring lectures improve learning experience.curious ahead time style teaching topics covered, check website previous year : https://jmbuhr.de/dataIntro20/course, handle different kinds data, create pretty insightful visualizations, compute different statistics data also explore statistical concepts mean.\npenguins p-values, got covered.\nFigure 0.1: One plots creating first lecture.\n","code":""},{"path":"index.html","id":"prerequisits","chapter":"Hello and welcome!","heading":"0.1 Prerequisits","text":"prior knowledge necessary.Software install:RRstudio","code":""},{"path":"index.html","id":"structure-of-the-course","chapter":"Hello and welcome!","heading":"0.2 Structure of the course","text":"current course WS21/22 Heidelberg University.\nparticipants biochemistry bachelor (master) students,\nmaterial open anyone!8 lectures total, accompanied :\nvideo lecture top page\nlecture script, consists code written lecture\n(plus code generate illustrative graphics) explanations\nExercises complete send \nseminar discuss exercises\ndiscord server ask questions share solutions\nvideo lecture top pageThe lecture script, consists code written lecture\n(plus code generate illustrative graphics) explanationsExercises complete send inA seminar discuss exercisesA discord server ask questions share solutionsI recommend watch lecture time, use lecture script afterwards look concepts code want revisit.\nCode chunks also copy-button, helpful quickly playing around , make sure actually walk lecture typing first,\nmuscle memory server well future.","code":""},{"path":"index.html","id":"exe","chapter":"Hello and welcome!","heading":"0.2.1 Exercises","text":"complete course, hand least 5 8 exercises.\nimportant part exercise perfect solution,\nencounter questions struggles attempt exercise, make sure include pain points well can cover Seminar.\nPlease hand solutions seminar via direct message discord.\nearlier week submit solutions,\ntime prepare answers seminar.","code":""},{"path":"index.html","id":"seminar","chapter":"Hello and welcome!","heading":"0.2.2 Seminar","text":"week, meet discuss exercises answer questions might popped .\nCurrently looks like possible person, case meet :Mathematikon (INF 205), IWR CIP-Pool 3. OGEven though technically computer rooms, great bring laptop can code along known able apply learned course well.\nAlso, might able install necessary software computer room.","code":""},{"path":"index.html","id":"discord","chapter":"Hello and welcome!","heading":"0.2.3 Discord and signup","text":"biochemistry student Heidelberg University,\nclick link: https://discord.gg/jVZcNPCrp7 join discord server sign course.\nlink doesn’t work, please send message via contact formOnce sure drop message name name matriculation number can put course onto official transcript records.\nserver, able ask questions can answered fellow learners, hand exercises receive feedback.Discord good choice , messages support code formatting can easily open voice call question get complicated.","code":""},{"path":"intro.html","id":"intro","chapter":"Lesson 1 Introduction","heading":"Lesson 1 Introduction","text":"Hi ! material first lecture appear.\nsign , check welcome page… get started R RStudio,\nlearn literate programming build first\nplot discovering Grammar Graphics.","code":""},{"path":"intro.html","id":"what-you-will-learn","chapter":"Lesson 1 Introduction","heading":"1.1 What You will Learn","text":"Throughout scientific career — potentially outside — encounter various forms data. Maybe experiment measured fluorescence molecular probe, simply count penguins local zoo. Everything data form another. raw numbers without context meaningless tables numbers boring look , often hide actual structure data.course learn handle different kinds data. learn create pretty insightful visualizations, compute different statistics data also statistical concepts mean. penguins p-values, got covered.course held English, concepts covered directly transfer research , working language English. said, feel free ask questions language understand, German also fine. Latin little rusty, thought.course, using programming language R. R language particularly well suited data analysis, initially designed statisticians interactive nature language, makes easier get started. don’t fret first encounter programming, take one step time.datasets chosen illustrate various concepts tools particularly centered around Biology. Rather, chose general datasets require less introduction enable us focus learning R statistics. talking penguins, racing games life expectancy instead intricate molecular measurements.","code":""},{"path":"intro.html","id":"execute-r-code","chapter":"Lesson 1 Introduction","heading":"1.2 Execute R Code","text":"consolescripta script like recipe, keeping important keeping e.g.\nplots come !can now execute commands R console bottom left. example can calculate mathematical expression:generate numbers one 10:rarely type directly console. want results reproducible, write code script first, next person 1 can see replicate analysis. see reproducibility quite near dear , pop twice. scientists, sure understand importance.script like recipe. important part data analysis\nworkflow, long recipe, can recreate whatever\nproducts (e.g. plots, statistics, tables) ease.create new script, click little button top left corner. script can type regular R code, won’t get executed straight away. send line code console executed, hit Ctrl+Enter. Go ahead, try :","code":"\n1 + 1[1] 2\n1:10 [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"intro.html","id":"get-to-know-rstudio","chapter":"Lesson 1 Introduction","heading":"1.3 Get to know RStudio","text":"projectspanes / layoutimportant settings:\nnever restore .Rdata startup\nnever restore .Rdata startuptheme (via packages,\ntalk later today)get deeper R,\nlet’s talk little bit Home working R:\nRStudio.one important setting like change:\nTools -> Global Options make sure “Restore .RData workspace startup”\nunchecked.\nworkspace RStudio save .RData contains objects created session, , can see Environment pane (default top right panel, bottom right setup). want load objects created last session current session automatically? reason reproducibility. want make sure everything analysis needs script. creates variables plots raw data sole source truth.Check lecture video customization RStudio\ne.g. themes make sure also use RStudio Projects structure work.","code":""},{"path":"intro.html","id":"expressions-tell-r-to-do-things","chapter":"Lesson 1 Introduction","heading":"1.4 Expressions: Tell R to do things","text":"R can lot’s things, let’s start basics, like calculating.\nEverything starts # comment ignored R.Create vectors : operator, e.g. numbers :toAnd mathematical operations automatically “vectorized”:fact, R scalars (individual values), just vectors length 1.","code":"\n1 + 1 # addition[1] 2\n32 / 11 # division[1] 2.909091\n3 * 4 # multiplication[1] 12\n13 %% 5 # modulo[1] 3\n13 %/% 5 # integer division[1] 2\n1:4[1] 1 2 3 4\n1:3 + 1:3[1] 2 4 6"},{"path":"intro.html","id":"variables-boxes-for-things","chapter":"Lesson 1 Introduction","heading":"1.5 Variables: Boxes for things","text":"Often, want store result computation reuse, give sensible name make code readable.\nvariables . can assign value variable using assignment operator <- (RStudio, shortcut : Alt+Minus):Executing code give output, use name variable, can see content.can operations variables:NOTE careful order execution! R enables work interactively execute code write script order Ctrl+Enter, execute (=“source”) whole script, executed top bottom.Furthermore, code executed automatically, change dependency expression later . second assignment x doesn’t change y.Variable names can contain letters (capitalization matters), numbers (first character) underscores _. 2A depiction various naming styles Allison Horst3A good convention always use snake_case.","code":"\nmy_number <- 42\nmy_number[1] 42\nx <- 41\ny <- 1\nx + y[1] 42\nx <- 1\ny <- x + 1\nx <- 1000\ny[1] 2\n# snake_case\nmain_character_name <- \"Kvothe\"\n\n# or camelCase\nbookTitle <- \"The Name of the Wind\"\n\n# you can have numbers in the name\nx1 <- 12"},{"path":"intro.html","id":"atomic-datatype","chapter":"Lesson 1 Introduction","heading":"1.6 Atomic datatype","text":"First numbers (internally called numeric double), whole numbers (integer)well rarely used complex numbers (complex)Text data however used often (character, string).\nEverything enclosed quotation marks treated text.\nDouble single quotation marks fine.Logical values can contain yes , rather TRUE FALSE programming terms (boolean, logical).special types mix type. Like NULL value NA Assigned.NA contagious. computation involving NA return NA (R way knowing answer):functions can remove NAs giving us answer:can ask datatype object function typeof:also concept called factors (factor) categorical data, talk later, get deeper vectors.","code":"\n12\n12.5\n1L # denoted by L\n1 + 3i # denoted by the small i for the imaginary part\n\"It was night again.\"\n'This is also text'\nTRUE\nFALSE\nNULL\nNA\nNA + 1[1] NA\nmax(NA, 12, 1)[1] NA\nmax(NA, 12, 1, na.rm = TRUE)[1] 12\ntypeof(\"hello\")[1] \"character\""},{"path":"intro.html","id":"functions-calculate-run-and-automate-things","chapter":"Lesson 1 Introduction","heading":"1.7 Functions: Calculate, run and automate things","text":"R, everything exists object, everything something function.Functions main workhorse data analysis. example, mathematical functions, like sin, cos etc.Functions take arguments (sometimes called parameters) sometimes also return things. sin function takes just one argument x returns sine. returned value us. can use directly another computation store variable. don’t anything return value, R simply prints console.Note, = inside function parenthesis gives x = 0 function separate x defined outside function. example:learn function R, execute ? function name press F1 mouse function. actually one important things learn today, help pages can … well… incredibly helpful.can pass arguments name order appearance. following two expressions equivalent.notable functions start :Combine elements vector:Convert datatypes :Calculate summary value vectore:Create sequences numbers:just learned functions sin, seq max. wait, ! sense functions R (kind language two verbs?!), also powerful way:can define functions!syntax (\\(\\leftarrow\\) grammar programming languages) follows.function ends reaches return keyword. also ends reaches end function body implicitly returns last expression. written bit shorter fact often see people omitting explicit return end:can call freshly defined function:Got error like Error add(23, 19) : find function \"add\"? Check fact execute code defines function (.e. put cursor line function keyword hit Ctrl+Enter.).","code":"\nsin(x = 0)[1] 0\nx <- 10\ncos(x = 0)[1] 1\n# x outside of the function is still 10\nx[1] 10\n?sin\nsin(x = 12)\nsin(12)\nc(1, 3, 5, 31)[1]  1  3  5 31\nas.numeric(\"1\")[1] 1\nas.character(1)[1] \"1\"\nx <- c(1, 3, 5, 42)\nmax(x)[1] 42\nmin(x)[1] 1\nmean(x)[1] 12.75\nrange(x)[1]  1 42\nseq(1, 10, by = 2)[1] 1 3 5 7 9\nname_for_the_function <- function(parameter1, parameter2, ...) { # etc.\n  # body of the function\n  # things happen\n  result <- parameter1 + parameter2\n  # Something the function should return to the caller\n  return(result)\n}\nadd <- function(x, y) {\n  x + y\n}\nadd(23, 19)[1] 42"},{"path":"intro.html","id":"packages-sharing-functions","chapter":"Lesson 1 Introduction","heading":"1.8 Packages: Sharing functions","text":"one using R.\nwelcoming helpful community .\npeople also write bunch functions put together called package.\npeople even went step .\ntidyverse collection packages play well together also iron quirkier ways R works.4\nprovide consistent interface enable us learn less special cases.\nR function install.packages(\"<package_name_here>\") installs packages CRAN curated set R packages.R packages, especially ones using, often come\ngreat manuals help pages added link\npackage website \npackages hexagonal icons package script,\nmake sure click icons.don’t link hand can also always find\nhelp internet.\npackages publish source code site\ncalled GitHub, able find\nlinks, help documentation searching\nr  github.\nSometimes can helpful write R’s full name\nsearching (turns lot thing \nletter R): rstats.","code":""},{"path":"intro.html","id":"literate-programming-with-rmarkdown-code-is-communication","chapter":"Lesson 1 Introduction","heading":"1.9 Literate Programming with Rmarkdown: Code is communication","text":"first package like install called Rmarkdown.\nGo ahead install :one exception effort everything script just console. don’t want R trying install package every time run script, needs happen . can either turn comment, delete script, type console. can also use RStudio’s built-panel package installation.Rmarkdown enables us, combine text code produce range output formats like pdf, html, word documents, presentations etc. fact, whole website, including slides, created Rmarkdown. Sounds exciting? Let’s dive !Open new Rmarkdown document file extension .Rmd New File menu top left corner RStudio: File → New File → R Markdown choose html output format. particularly like html, don’t worry page breaks easily works screens different sizes, like phone.Rmarkdown document consists three things:Metadata:\nInformation document author date format called YAML. YAML header starts ends three minus signs ---.Text:\nRegular text interpreted markdown, meaning supports things like creating headings prefixing line #, text bold output surrounding **.Code chunks:\nStarting line 3 backticks {r} ending 3 backticks. interpreted R code. write code like .R script file. can insert new chunks button top right editor window use shortcut Ctrl+Alt+.Use document thoughts alongside code data analysis. Future (reviewer number 2) happy! run code inside chunks, use,little play button chunk, tried true Ctrl+Enter run one line, Ctrl+Shift+Enter run whole chunk. chunks can large small want, try maintain sensible structure.lecture video also demonstrates different output formats,\nexercises using html_document.knitshow output formats\nhtml_document\npdf_document\ndocx_document\nhtml_documentpdf_documentdocx_documentshow visual editorCute little monsters Rmarkdown Wizards Allison Horst","code":"\ninstall.packages(\"rmarkdown\")"},{"path":"intro.html","id":"the-tidyverse","chapter":"Lesson 1 Introduction","heading":"1.9.1 The Tidyverse","text":"Go ahead install tidyverse packages ","code":"\ninstall.packages(\"tidyverse\")"},{"path":"intro.html","id":"our-first-dataset-the-palmer-penguins","chapter":"Lesson 1 Introduction","heading":"1.10 Our First Dataset: The Palmer Penguins","text":"three penguin species Palmer Archipelago, Allison HorstSo let’s explore first dataset together fresh Rmarkdown document. setup chunk special. gets executed automatically chunk document run. makes good place load packages. dataset working today actually comes package, need install well (Yes, lot installing today, ):populate setup chunk withThis gives us penguins dataset:5","code":"\ninstall.packages(\"palmerpenguins\")\nlibrary(tidyverse)\nlibrary(palmerpenguins)\npenguins"},{"path":"intro.html","id":"dataframes-rs-powerfull-tables","chapter":"Lesson 1 Introduction","heading":"1.10.1 Dataframes: R’s powerfull tables","text":"Let’s talk shape penguins object. str function reveals structure object us.penguins variable contains tibble, tidyverse\nversion dataframe.\nbehaves way prints nicer.\nlist columns, columns (usually) vectors.","code":"\nstr(penguins)tibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ..."},{"path":"intro.html","id":"the-grammar-of-graphics-translate-data-into-visualizations","chapter":"Lesson 1 Introduction","heading":"1.11 The Grammar of Graphics: Translate data into visualizations","text":"probably took course want build cool visualizations data. order , let us talk can describe visualizations. Just like language grammar, smart people came grammar graphics,6 slightly modified turned R package can talk also create visualizations using grammar.7\npackage called ggplot2, already loaded included tidyverse. looking code, can describe need order create graphic.grammar means:\n- can build complex visualizations\nbasic building blocks\nfit together according \nrules (grammar)\n- just like lego bricks\n- just learn building blocks \ndifferent function \ndifferent types plots\n(e.g. barplot, scatterplot, lineplot,\npiechart)can build plot step step. data foundation plot, just gives us empty plotting canvas. assigning individual steps going variable, can sequentially add elements, can one step shown ., add aesthetic mapping plot. creates relation features dataset (like flipper length penguin) visual property, like position x-axis, color shape.Still, plot empty, coordinate system certain scale. geometric objects represent aesthetics. Elements plot added using + operator geometric elements ggplot knows start geom_. Let’s add points:Look help page geom_point find aesthetics understands. exact way features mapped aesthetics regulated scales starting scale_ name aesthetic:can add change labels (like x-axis-label) adding labs function.overall look plot regulated themes like pre-made theme_ functions finely regulated theme() function, uses element functions create look individual elements. Autocomplete helps us lot (Ctrl+Space).summary, plot needs:dataaesthetic mappinggeom(s)(stat(s))coordinate systemguidesscalesthemeWe can save plot ggsave function.\nalso arguments control dimentions resolution\nimage.Next week get rid annoying NA legend sex.","code":"\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\npenguins %>%\n  ggplot(aes(flipper_length_mm, bill_length_mm,\n             color = species,\n             shape = sex)) +\n  geom_point(size = 2.5) +\n  geom_smooth(aes(group = species), method = \"lm\", se = FALSE,\n              show.legend = FALSE) +\n  labs(x = \"Flipper length [mm]\",\n       y = \"Bill length [mm]\",\n       title = \"Penguins!\",\n       subtitle = \"The 3 penguin species can be differentiated by their flipper- and bill-lengths.\",\n       caption = \"Datasource:\\nHorst AM, Hill AP, Gorman KB (2020). palmerpenguins:\\nPalmer Archipelago (Antarctica) penguin data.\\nR package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/\",\n       color = \"Species\",\n       shape = \"Sex\") +\n  theme_minimal() +\n  scale_color_brewer(type = \"qual\") +\n  theme(plot.caption = element_text(hjust = 0))\nplt <- ggplot(penguins)\n\nplt\nplt <- ggplot(penguins,\n              aes(x = flipper_length_mm,\n                  y = bill_length_mm,\n                  color = species,\n                  shape = sex))\n\nplt\nplt <- plt +\n  geom_point()\n\nplt\nplt <- plt +\n  scale_color_manual(values = c(\"red\", \"blue\", \"orange\"))\n\nplt\nplt <- plt +\n    labs(x = \"Flipper length [mm]\",\n         y = \"Bill length [mm]\",\n         title = \"Penguins!\",\n         subtitle = \"The 3 penguin species can differentiated by their flipper and bill lengths\")\nplt <- plt + \n  theme_minimal() +\n  theme(legend.text = element_text(face = \"bold\"))\n\nplt\nmy_plot <- ggplot(penguins,\n                  aes(x = flipper_length_mm,\n                      y = bill_length_mm,\n                      shape = sex,\n                      color = species)) +\n  geom_point() +\n  scale_color_manual(values = c(\"red\", \"blue\", \"orange\")) +\n  labs(title = \"Penguins\") +\n  theme(plot.title = element_text(colour = \"purple\"))\n\nmy_plot \nggsave(\"my_plot.png\", my_plot)"},{"path":"intro.html","id":"the-community-there-to-catch-you.","chapter":"Lesson 1 Introduction","heading":"1.12 The Community: There to catch You.","text":"Comunity Teamwork Allison HorstGoogling Error Message","code":""},{"path":"intro.html","id":"bonus-get-more-rstudio-themes","chapter":"Lesson 1 Introduction","heading":"1.13 Bonus: Get more RStudio themes","text":"talk packages come fromhttps://github.com/gadenbuie/rsthemes","code":""},{"path":"intro.html","id":"exercises","chapter":"Lesson 1 Introduction","heading":"1.14 Exercises","text":"course graded, need way confirming indeed take part course. order get confirmation, send solutions minimum 5 8 exercises Seminar Fridays. week like create fresh Rmarkdown document solutions code well questions arose lecture. help lot improving course.done solving exercises, hit knit button (top editor panel) send resulting html document via discord (confirm looks way expected beforehand).today’s tasks:","code":""},{"path":"intro.html","id":"put-your-flippers-in-the-air","chapter":"Lesson 1 Introduction","heading":"1.14.1 Put your flippers in the air!","text":"fresh Rmarkdown document (without example template content),\nload tidyverse palmerpenguins packages.Write section text previous experience data analysis /programming (optional, can use information customize course).Produce scatterplot (meaning plot points) bill length vs. bill depth, colorcoded species.\nImaginary bonus points manage use colors penguin-image (hint: look help page scale_color_manual() find . Note, R can work ’s built-color names, rgb() specifications hex-codes #1573c7). Even bonus points also look theme() function ’s arguments, theme_<...>() functions make plot prettier.\nImaginary bonus points manage use colors penguin-image (hint: look help page scale_color_manual() find . Note, R can work ’s built-color names, rgb() specifications hex-codes #1573c7). Even bonus points also look theme() function ’s arguments, theme_<...>() functions make plot prettier.Create vector odd numbers 1 99 store variable.\nCreate second variable contains squares first.\nStore variables named list turn list tibble (enhanced version data.frame\nDiscover shortcut three steps using function tibble. Specifically, look third bullet point description ?tibble::tibble (two colons :: specify package function coming . need tibble(...) code tibble package loaded automatically tidyverse. , specify directly send correct help page).\nCreate scatterplot two variables stored tibble using ggplot.\ngeom_ function need add plot add line connects points?\nCreate second variable contains squares first.Store variables named list turn list tibble (enhanced version data.frameDiscover shortcut three steps using function tibble. Specifically, look third bullet point description ?tibble::tibble (two colons :: specify package function coming . need tibble(...) code tibble package loaded automatically tidyverse. , specify directly send correct help page).Create scatterplot two variables stored tibble using ggplot.geom_ function need add plot add line connects points?Check metadata (YAML) Rmarkdown document make sure contains name author: .\ncouple YAML options can try feel adventurous.\ncouple YAML options can try feel adventurous.Knit ship !","code":""},{"path":"intro.html","id":"learn-more","chapter":"Lesson 1 Introduction","heading":"1.15 Learn more:","text":"Check dedicated Resources page.","code":""},{"path":"data-wrangling.html","id":"data-wrangling","chapter":"Lesson 2 Data Wrangling","heading":"Lesson 2 Data Wrangling","text":"… explore typical data analysis workflow tidyverse, wrangle different kinds data learn factors.Note:\ntry vocal code plain English type learning “translations” symbols keywords can help , . , programming can feel lot like conversation digital assistant helpful friend. boundary human languages computer languages blurry might think.Right setup-chunk, specify common code execution\noptions like showing code (echo) hiding messages warnings,\nfirst thing usually top new analysis load \npackages going used.\nlater find need , come back add\nlist, people reading code can see straight away,\ninstall order run code .","code":"\nlibrary(tidyverse)"},{"path":"data-wrangling.html","id":"a-data-analysis-workflow","chapter":"Lesson 2 Data Wrangling","heading":"2.1 A Data Analysis Workflow","text":"getting close importing first dataset file R.\nGenerally, first thing needs happen data analysis cover today.\ndata provided already pretty tidy start build visualizations.\ncommunicate-part also covered, working Rmarkdown ,\ndesigned communicate findings.\nNext week also look less tidy data,\ndefined “tidy data” .Figure Hadley Wickham Garrett Grolemund8.","code":""},{"path":"data-wrangling.html","id":"reading-data-with-readr","chapter":"Lesson 2 Data Wrangling","heading":"2.2 Reading Data with readr","text":" package responsible loading data tidyverse called readr, start loading whole tidyverse.Note, general, also load just readr package library(readr), need rest tidyverse later anyways.\nalso option load package rather use one function package prefixing function package name two colons (::) Like :\nreadr::read_csv(\"...\").Without ado, let’s download data today.\nfact, multiple ways go .\ndownload whole course folder GitHub following link\nsays “View book source”\nleft sidebar (pancake-menu mobile view) using download button\nGitHub:data folder called data organized sub-folders\nlecture number.\neverything need today can found folder 02.GitHub, can also download individual files,\nplain text files need remember one extra step.\nalready clicked file GitHub can\nsee ’s content, tempting copy paste link\nbrowser bar use R’s download.file function.\nHowever, just link part website\nGitHub shows file, link actual file.\ncan get correct link clicking Raw button:can use download file:look source lecture find \nset chunk option eval=FALSE, meaning code run.\ndon’t want download file every time make change \ncourse script.common error see people download.file trying download\nfile e.g. folder called data without first creating said folder.\nget one file directory errors, \nlikely cause.read gapminder data (csv)read csv also works url\nprobably also want local copy\nwrite_csv friends\nprobably also want local copywrite_csv friendsView ctrl+clickWith data downloaded, can make use RStudio’s autocompletion\ncomplete file-path data inside quotation marks.\ncan trigger explicitly ctrl+space tab.readr also tell datatypes guessed columns.\nLet’s inspect dataset:gapminder dataset9 excerpt\ngapminder project contains life expectancy birth 142 countries 5 year intervals 1952 2007.\nalso contains population Gross Domestic Product (GDP) per Inhabitant.\nbuilt visualization later .cool trick data variable\nView function.\neffect can reached ctrl+clicking \nusing button next environment panel.noted read_csv function can also\nread data links download automatically.\nHowever, order data nice safe,\nmight want save somewhere, just case\n(links can change, especially someone else’s link).","code":"\ndownload.file(\"https://raw.githubusercontent.com/jmbuhr/dataintro/main/data/02/gapminder.csv\", \"example-download.csv\")\ngapminder <- read_csv(\"data/02/gapminder.csv\")\ngapminder\nour_data <- read_csv(\"https://raw.githubusercontent.com/jmbuhr/dataintro/main/data/02/gapminder.csv\")\n\nwrite_csv(our_data, \"our-data.csv\")"},{"path":"data-wrangling.html","id":"a-project-based-workflow","chapter":"Lesson 2 Data Wrangling","heading":"2.3 A Project-based Workflow","text":"Last week simply went ahead created script file Rmarkdown file folder computer.\nR known, script ?\nknow, look, tell read file save plot?\nmain folder R starts called working directory.\nfind , current working directory , execute function getwd() get working directory:RStudio projects set working directory automatically, convenient.\nmakes easier us share code projects, simply copying whole\nfolder.\nfollow one prerequisite.\nfile paths need relative, absolute.\nabsolute file path starts root operating system,\nwindows see something like C:\\\\User\\Jannik\\Documents\\...\nmac linux starts /home/jannik/Documents/....\nexample, read gapminder dataset :terrible idea!\never move analysis folder, file path longer\ncorrect someone else tries run code\ncertainly called Jannik exact \ndirectory structure.\nalso work.order work portable, robust shareable,\nneed file paths relative root\nproject (set RStudio project)., ./ refers current working directory,\nset RStudio project.\ncan also omitted (e.g. data/02/...),\npath can’t start / \nmark absolute path.also function set working directory\n(called setwd),\nask never use .\norder use , specify\nworking directory using absolute path,\nrendering script useless anyone .\nUse RStudio projects instead.one thing didn’t tell Rmarkdown documents, yet.\nworking directory always folder ,\neven subdirectory project.\nway also means don’t necessarily need project work Rmarkdown,\none anyway makes easier keep track files \nconsistent structure.","code":"\ngetwd()[1] \"/home/jannik/Documents/projects/teaching/dataintro\"\nread_csv(\"/home/jannik/Documents/projects/teaching/dataintro/data/02/gapminder.csv\")\nread_csv(\"./data/02/gapminder.csv\")"},{"path":"data-wrangling.html","id":"common-hurdles-when-importing-data","chapter":"Lesson 2 Data Wrangling","heading":"2.3.1 Common Hurdles when Importing Data","text":", importing gapminder csv went smoothly.\nalways case.\nnow look common hurdles importing data.function just used called read_csv, reads file format consists comma separated values.\nLook raw file text editor (word) like notepad RStudio see .\nfile extension .csv can sometimes lying…German, comma used separate decimal numbers\n(vs. dot English),\nlot Software output different type csv-file configured German.\nstill call csv,\nactually separated semicolons!\nspecial function :looking autocompletion options pop typing function name, might noticed similar function read.csv read.csv2.\nfunctions come R, without packages like tidyverse.\ncan course use well,\ntidyverse functions provide consistent experience \nless surprising quirks.\nteaching tidyverse first allows \nlearn less edge cases.look yet another file gapminder_tsv.txt,\nnotice file extension doesn’t tell us much format, text (opposed binary format computers can read).\nlook file:notice values separated “, special sequence stands tab character. read_tsv function job.\nshowing output just\ngapminder dataset .separator (also called delimiter) even obscure,\ncan use general function read_delim.\nSay co-worker misunderstood us thought tsv stands “Tilde separated values”,\ncan still read file.ways raw data can messy hard read depending machine can’t show .\nOne common thing encounter though measurement machines writing additional information first couple lines actual data\n(like time measurement).\nexample:first 2 lines part data.\nReading file normally csv produce something weird:\nfirst line contain commata, assume file contains one column also report bunch parsing failures.\nParsing act turning data represented raw text useful format,\nlike table numbers.can fix telling R skip first 2 lines entirely:using n_max argument functions save space lecture script.can also read excel files using function readxl package.\npackage automatically installed tidyverse,\nloaded along packages via library(tidyverse).\ncan either load library(readxl) \nrefer single function package without loading whole thing\nusing double colons (::) like :Remember, read gapminder dataset first\ntime day, saved variable called gapminder,\ngoing use going forward.","code":"\nread_csv2(\"data/02/gapminder_csv2.csv\")\nread_lines(\"data/02/gapminder_tsv.txt\", n_max = 3)[1] \"country\\tcontinent\\tyear\\tlifeExp\\tpop\\tgdpPercap\"    \n[2] \"Afghanistan\\tAsia\\t1952\\t28.801\\t8425333\\t779.4453145\"\n[3] \"Afghanistan\\tAsia\\t1957\\t30.332\\t9240934\\t820.8530296\"\nread_tsv(\"data/02/gapminder_tsv.txt\")\nread_delim(\"data/02/obscure_file.tsv\", \"~\")\nread_lines(\"data/02/gapminder_messier.csv\", n_max = 5)[1] \"# Some comment about the data\"                   \n[2] \"And maybe a personal note\"                       \n[3] \"country,continent,year,lifeExp,pop,gdpPercap\"    \n[4] \"Afghanistan,Asia,1952,28.801,8425333,779.4453145\"\n[5] \"Afghanistan,Asia,1957,30.332,9240934,820.8530296\"\nread_csv(\"data/02/gapminder_messier.csv\", skip = 2, n_max = 3)\nreadxl::read_xlsx(\"data/02/gapminder.xlsx\")"},{"path":"data-wrangling.html","id":"wrangling-data-with-dplyr","chapter":"Lesson 2 Data Wrangling","heading":"2.4 Wrangling Data with dplyr","text":" number ways can manipulate data.\ncourse mean manipulate ’s original sense, malicious one.\nsometimes referred data wrangling within tidyverse,\njob dplyr package (short data plyer, tool see logo).dplyr provides functions various operations data.\nTheses functions sometimes also called dplyr verbs.\ntake tibble data.frame input (plus additional parameters) always return tibble.\nenough talk, let’s go wrangling!Let’s go data wrangling! Artwork Allison Horst","code":""},{"path":"data-wrangling.html","id":"select","chapter":"Lesson 2 Data Wrangling","heading":"2.4.1 select","text":"first verb introduce used select columns.\nhence, called select.\nfirst argument always data, followed arbitrary number column names.\ncan recognize functions take arbitrary number additional arguments ... autocompletion help page.might confusing don’t need quotation marks around column names like \nlanguages even parts R.concept known quasiquotation data masking.\nquite unique R, allows functions known content data passed use environment computations search variable names.\nvariable country doesn’t exist global environment,\nexist column gapminder tibble.dplyr functions always look data first search names.help page select tells us different ways can select columns.\ncouple examples without output,\nrun R session confirm think \n(look help pages , quite well written).","code":"\nselect(gapminder, country, year, gdpPercap)\nselect(gapminder, year:pop)\nselect(gapminder, starts_with(\"co\"))\nselect(gapminder, where(is.numeric))\nselect(gapminder, where(is.character))\nselect(gapminder, c(1, 3, 4))"},{"path":"data-wrangling.html","id":"filter","chapter":"Lesson 2 Data Wrangling","heading":"2.4.2 filter","text":"selecting columns natural ask select rows.\nachieved function filter.Filter data. Artwork Allison HorstHere, select rows, year greater 2000\ncountry New Zealand.text comparisons cases sensitive, missed\nNew Zealand written lowercase letters.\norder make sure find correct country,\ncan helpful simply convert country names\nlower case, fact can use functions columns\nstraight inside dplyr verb.\nFunctions deal text (strings character R’s language)\ntidyverse start str_, easy find\nautocompletion.Instead combining conditions , (works \n& ), can also use | meaning .\n, get rows country New Zealand \ncountry Afghanistan.particular comparison can written succinctly,\nasking (every row), particular country %% vector?","code":"\nfilter(gapminder, year > 2000, country == \"New Zealand\")\nfilter(gapminder, year > 2000, str_to_lower(country) == \"new zealand\")\nfilter(gapminder, country == \"New Zealand\" | country == \"Afghanistan\")\nfilter(gapminder, country %in% c(\"New Zealand\", \"Afghanistan\"))"},{"path":"data-wrangling.html","id":"mutate","chapter":"Lesson 2 Data Wrangling","heading":"2.4.3 mutate","text":"back manipulating columns, time creating new ones changing old ones.\ndplyr verb called mutate.\nexample, might want calculate total GDP GDP per Capita population:Notice, none functions changed original variable gapminder.\ntake input return output,\nmakes easier reason code later chain pieces code together.\nchange ?\nUse Force! … ahem, mean, assignment operator (<-)., power dplyr shines.\nknows pop gdpPercap columns tibble \ngdp refers new name freshly created column.","code":"\nmutate(gapminder, gdp = pop * gdpPercap)\ngapminder <- mutate(gapminder, gdp = pop * gdpPercap)"},{"path":"data-wrangling.html","id":"interlude-begind-the-magic-handling-data-with-base-r","chapter":"Lesson 2 Data Wrangling","heading":"2.4.4 Interlude: Begind the magic, handling data with base-R","text":"section meant show happens behind scenes.\nstrictly necessary understand details order work effectively tidyverse, helps especially things don’t go planned.Let’s create tibble play :Instead tidyverse functions, can also use\ncalled subsetting, getting subset datasctructure,\nsquare brackets:selected first third column.\nalso works lone vectors:want select columns names without \ntidyverse, pass names character vector\n(hence quotation marks).two things square brackets, separated comma,\nfirst refers rows second refers columns.\ne.g. “first row columns 1 2”:Internally, tibbles / dataframes lists columns.\nLists ways accessing elements.\n$ symbol gets us element list:want use numbers (=indices) get single\nelement list (column tibble),\not use double square brackets:reason : Single square brackets give us subset\nlist, still packed list.\nwant unpack work need \ncontent just one element [[ us.pull function tidyverse works like $.Subsetting works looking things,\nalso allows us replace part subsetting:Note:\nbase-R tidyverse way mutually exclusive.\nSometimes can mix match.","code":"\ntest_tibble <- tibble(\n  x = 1:5,\n  y = x ^ 2,\n  z = c(\"hello\", \"world\", \"test\", \"four\", \"five\")\n)\n\ntest_tibble\ntest_tibble[c(1, 3)]\nevens <- seq(0, 10, 2)\nevens[c(1, 3)][1] 0 4\ntest_tibble[c(\"x\", \"z\")]\ntest_tibble[1, 1:2]\ntest_tibble$x[1] 1 2 3 4 5\ntest_tibble[[1]][1] 1 2 3 4 5\npull(test_tibble, x)[1] 1 2 3 4 5\nx <- 1:10\nx[1] <- 42\nx [1] 42  2  3  4  5  6  7  8  9 10"},{"path":"data-wrangling.html","id":"the-pipe","chapter":"Lesson 2 Data Wrangling","heading":"2.4.5 The pipe %>%","text":"tidyverse functions easier compose (.e. chain together).\nfacilitate , introduce another operator, bit like + numbers + add ggplot components, specially functions.\npipe, can either type insert RStudio Ctrl+Shift+M,\ntakes ’s left side passes first argument function right sideWhy useful?\nImagine data processing involves bunch steps,\nsave output intermediate variables.However, don’t really need intermediate variables\njust clutter code.\npip allows us express data processing series \nsteps:can read pipe head “” “take … pass …”.main tidyverse functions take data first argument,\ncan chain together fluently\nAdditionally, enables autocompletion column names inside function\ngets data.Next tidyverse pipe %>%, might also see |> point.\nlatter pipe introduced base-R whole\npiping thing got popular making part core language.","code":"\nsubset_gapminder <- select(gapminder, country, year, pop)\nfiltered_gapminder <- filter(subset_gapminder, year > 200)\nfinal_gapminder <- mutate(filtered_gapminder, pop_thousands = pop / 1000)\nfinal_gapminder\nfinal_gapminder <- gapminder %>% \n  select(country, year, pop) %>% \n  filter(year > 2000) %>% \n  mutate(pop_thousands = pop / 1000)\n\nfinal_gapminder"},{"path":"data-wrangling.html","id":"arrange","chapter":"Lesson 2 Data Wrangling","heading":"2.4.6 arrange","text":"simple thing might want table sort based column. arrange :helper function desc marks column arranged descending order.\ncan arrange multiple columns, first important.","code":"\ngapminder %>% \n  arrange(year)\ngapminder %>% \n  arrange(desc(year), pop)"},{"path":"data-wrangling.html","id":"summarise","chapter":"Lesson 2 Data Wrangling","heading":"2.4.7 summarise","text":"condense one multiple columns summary values, use summarise.\nLike mutate, can calculate multiple things one step.condensing whole columns one value, flattening tibble style Super Mario jumping mushrooms, often need.\nrather know summaries within certain groups.\nexample maximal gdp per country. group_by .","code":"\ngapminder %>% \n  summarise(\n    max_year = min(year),\n    pop = max(pop),\n    mean_life_expectancy = mean(lifeExp)\n  )"},{"path":"data-wrangling.html","id":"group_by","chapter":"Lesson 2 Data Wrangling","heading":"2.4.8 group_by","text":"group_by considered adverb, doesn’t change data changes subsequent functions handle data. example, tibble groups, summaries calculated within groups:summarize removes one level grouping.\ndata grouped multiple features, means groups remain.\ncan make sure data longer grouped ungroup.Groups also work within mutate filter.\nexample, can get rows gdp per Person highest per country:","code":"\ngapminder %>% \n  group_by(year) %>% \n  summarise(\n    lifeExp = mean(lifeExp)\n  )\ngapminder %>% \n  group_by(year, continent) %>% \n  summarise(\n    lifeExp = mean(lifeExp)\n  ) %>%\n  ungroup()\ngapminder %>%\n  group_by(country) %>% \n  filter(gdpPercap == max(gdpPercap))\ngapminder %>% \n  group_by(year) %>%\n  mutate(pop = pop / sum(pop))"},{"path":"data-wrangling.html","id":"others","chapter":"Lesson 2 Data Wrangling","heading":"2.4.9 others:","text":"can rename columns rename:Sometimes want refer size current group inside mutate summarise. function just called n(). example, wonder many rows data per year.shortcut group_by summarise n() count function:general, might find solving particular problem couple steps elegant solution. discouraged ! simply means always learn, tools already know now get long way set right track.think learned enough dplyr verbs now. can treat little ggplot visualization.","code":"\ngapminder %>% \n  rename(population = pop)\ngapminder %>% \n  group_by(year) %>% \n  mutate(n = n())\ngapminder %>% \n  count(year, country) %>% \n  count(n)"},{"path":"data-wrangling.html","id":"visualization-and-our-first-encounter-with-factors","chapter":"Lesson 2 Data Wrangling","heading":"2.5 Visualization and our first encounter with factors","text":" facet_wrap function slices plot theses subplots, style plot sometimes referred small multiples. point might wonder: “control order facets?” answer : factor!time vector can thought representing discrete categories (ordered unordered), can express turning vector factor factor function. enables R’s functions handle appropriately. Let’s create little example. start character vector.Note new information R gives us, Levels, possible values can put factor. automatically ordered alphabetically creation. can also pass vector levels creation.factor can contain elements levels, omitted whale shark, turned NA. tidyverse contains forcats package help factors. functions package start fct_.example, fct_relevel function,\nkeeps levels let’s us change order:Using action, get:Note: fct_relevel might constructed example.\noften need cousin fct_reoder\nreorder factor values column.Let’s make plot bit prettier adding color!\ngapminder package provided dataset also included nice color palette. included .csv file data/ folder can practice importing data . also take shortcut getting straight package (gapminder::country_colors). , using head function look first couple rows tibble look first couple elements named vector package.named vector means can access individual elements\nnames, ggplot can use names\nmatch example colors countries\npass scale_ function.final plot also add guides(color = \"none\"),\nshow guide (discrete colors typically legend),\nfill whole plot.","code":"\ngapminder %>% \n  ggplot(aes(year, lifeExp, group = country)) +\n  geom_line() +\n  facet_wrap(~continent)\nanimals <- c(\"cat\", \"dog\", \"bear\", \"shark\")\nanimals <- factor(animals)\nanimals[1] cat   dog   bear  shark\nLevels: bear cat dog shark\nanimals <- c(\"cat\", \"dog\", \"bear\", \"shark\")\nanimals <- factor(animals, levels = c(\"cat\", \"dog\"), ordered = TRUE)\nanimals[1] cat  dog  <NA> <NA>\nLevels: cat < dog\nanimals <- c(\"cat\", \"dog\", \"bear\", \"shark\")\nanimals <- factor(animals)\nfct_relevel(animals, c(\"shark\", \"dog\"))[1] cat   dog   bear  shark\nLevels: shark dog bear cat\ngapminder %>% \n  mutate(continent = fct_relevel(continent, \"Oceania\")) %>% \n  ggplot(aes(year, lifeExp, group = country)) +\n  geom_line(alpha = 0.3) +\n  facet_wrap(~ continent)\ncountry_colors <- read_csv(\"data/02/country_colors.csv\")\ncolor <- country_colors$color\nnames(color) <- country_colors$country\nhead(color)         Nigeria            Egypt         Ethiopia Congo, Dem. Rep. \n       \"#7F3B08\"        \"#833D07\"        \"#873F07\"        \"#8B4107\" \n    South Africa            Sudan \n       \"#8F4407\"        \"#934607\" \nx <- c(first = 1, second = 3, hello = 5)\nx[\"first\"]first \n    1 \ngapminder %>% \n  mutate(continent = fct_relevel(continent, c(\"Oceania\"))) %>% \n  ggplot(aes(year, lifeExp, color = country)) +\n  geom_line() +\n  facet_wrap(~continent) +\n  guides(color = \"none\") +\n  scale_color_manual(values = color)"},{"path":"data-wrangling.html","id":"exercises-1","chapter":"Lesson 2 Data Wrangling","heading":"2.6 Exercises","text":"Drink cup coffee tea, relax, \njust worked quite long video.Familiarize folders computer.\nMake sure understand, directories files live.Download data today one ways taught.\ncan refer script anytime.file ./data/02/exercise1.txt unfamiliar format.\nFind structured read readr.\nCreate scatterplot x y column ggplot.\nLook help page geom_point.\ndifference geom_point(aes(color = <something>)) geom_point(color = <something>)?\nrelevant hint section ...-argument.\nMake plot pretty coloring points,\nkeeping mind distinction.\nFind structured read readr.Create scatterplot x y column ggplot.Look help page geom_point.\ndifference geom_point(aes(color = <something>)) geom_point(color = <something>)?\nrelevant hint section ...-argument.Make plot pretty coloring points,\nkeeping mind distinction.Read gapminder dataset readr\nUsing combination dplyr verbs / \nvisualizations ggplot,\nanswer following questions:\ncontinent highest life expectancy average\ncurrent year? two options .\nFirst, calculate simple mean countries\ncontinent. , remember countries\ndifferent population sizes, really need\nweighted mean using R’s function weighted.mean().\nrelationship GDP per capita \nlife expectancy? visualization might helpful.\npopulation countries change time?\nMake plot informative adding color,\nfacets labels (geom_text). Can find ,\nadd country name label last year?\nHint: look data argument geom_-functions\n.\nUsing combination dplyr verbs / \nvisualizations ggplot,\nanswer following questions:continent highest life expectancy average\ncurrent year? two options .\nFirst, calculate simple mean countries\ncontinent. , remember countries\ndifferent population sizes, really need\nweighted mean using R’s function weighted.mean().relationship GDP per capita \nlife expectancy? visualization might helpful.population countries change time?\nMake plot informative adding color,\nfacets labels (geom_text). Can find ,\nadd country name label last year?\nHint: look data argument geom_-functions\n.","code":""},{"path":"data-wrangling.html","id":"resources","chapter":"Lesson 2 Data Wrangling","heading":"2.7 Resources","text":"Don’t miss dedicated Resources page.","code":""},{"path":"data-wrangling.html","id":"package-documentation","chapter":"Lesson 2 Data Wrangling","heading":"2.7.1 Package Documentation","text":"tidyverse websiteThe readr package website cheatsheetThe dplyr package website cheatsheet","code":""},{"path":"data-wrangling.html","id":"getting-help","chapter":"Lesson 2 Data Wrangling","heading":"2.7.2 Getting Help","text":"find helpR4DS online learning community","code":""},{"path":"tidy-data.html","id":"tidy-data","chapter":"Lesson 3 Tidy data","heading":"Lesson 3 Tidy data","text":"… explore concept Tidy Data learn \nadvanced data wrangling techniquesOnce , start loading tidyverse.\nlecture video can also see recap, speed run sorts,\nlectures 1 2.","code":"\nlibrary(tidyverse)"},{"path":"tidy-data.html","id":"tidy-data-1","chapter":"Lesson 3 Tidy data","heading":"3.1 Tidy data","text":"Let’s get started pivotal topic.","code":""},{"path":"tidy-data.html","id":"what-and-why-is-tidy-data","chapter":"Lesson 3 Tidy data","heading":"3.1.1 What and why is tidy data?","text":"one concept also lends ’s name \ntidyverse want talk .\nTidy Data way turning datasets uniform shape.\nmakes easier develop work tools get consistent interface.\nknow turn dataset tidy dataset,\nhome turf can express ideas fluently code.\nGetting can sometimes tricky,\ngive important tools.tidy data, variable (feature) forms ’s column.\nobservation forms row.\ncell single value (measurement).\nFurthermore, information things belongs one table.Figure https://r4ds..co.nz/tidy-data.html Wickham Grolemund10","code":""},{"path":"tidy-data.html","id":"make-data-tidy","chapter":"Lesson 3 Tidy data","heading":"3.1.2 Make data tidy","text":"tidyr package.“Happy families alike; every unhappy family unhappy way”\n— Leo Tolstoy (https://tidyr.tidyverse.org/articles/tidy-data.html)quote holds true messy datasets well.\ntidyr package contained tidyverse provides small example datasets \ndemonstrate means practice.\nHadley Wickham Garrett Grolemund use book well (https://r4ds..co.nz/tidy-data.html)11.Let’s make data tidy!table1, table2, table3, table4a, table4b,\ntable5 display number TB cases documented \nWorld Health Organization Afghanistan, Brazil,\nChina 1999 2000.\nfirst tidy format, others :nicely qualifies tidy data.\nEvery row uniquely identified country year,\ncolumns properties specific country\nspecific year.","code":"\ntable1"},{"path":"tidy-data.html","id":"pivot_wider","chapter":"Lesson 3 Tidy data","heading":"3.1.3 pivot_wider","text":"Now gets interesting.\ntable2 still looks organized, tidy (definition).\nNote, doesn’t say format useless — ’s places —\nfit snugly tools.\ncolumn type feature country,\nrather actual features hidden column \nvalues count column.order make tidy, dataset needs become wider.","code":"\ntable2\ntable2 %>% \n  pivot_wider(names_from = type, values_from = count)"},{"path":"tidy-data.html","id":"separate","chapter":"Lesson 3 Tidy data","heading":"3.1.4 separate","text":"table3, two features jammed one column.\nannoying, can’t easily calculate\nvalues; stored text \nseparated slash like cases/population.Ideally, want separate column two:","code":"\ntable3\ntable3 %>% \n  separate(col = rate, into = c(\"cases\", \"population\"), sep = \"/\")"},{"path":"tidy-data.html","id":"pivot_longer","chapter":"Lesson 3 Tidy data","heading":"3.1.5 pivot_longer","text":"table4a table4b split data two different tables,\nmakes harder calculate .\ndata closely related, want one table.\nanother principle tidy data violated.\nNotice column names?\n1999 feature Afghanistan can .\nRather, value feature (namely year),\nvalues 1999 column fact\nvalues feature population (table4a)\ncases (table4b).another case similar\nthing twice.\ngeneral rule thumb says:“copy paste code 3 times,\nprobably write function.”advantage reducing code duplication\nenabling us potentially reuse code\nlater another project, also aids readability\nforced give stop name.can use function tables.","code":"\ntable4a\ntable4b\ntable4a %>% \n  pivot_longer(-country, names_to = \"year\", values_to = \"cases\")\ntable4b %>% \n  pivot_longer(-country, names_to = \"year\", values_to = \"population\")\nclean_wide_data <- function(data, values_column) {\n  data %>% \n    pivot_longer(-country, names_to = \"year\", values_to = values_column)\n}\nclean4a <- table4a %>% \n  clean_wide_data(\"cases\")\nclean4b <- table4b %>% \n  clean_wide_data(\"population\")"},{"path":"tidy-data.html","id":"left_join","chapter":"Lesson 3 Tidy data","heading":"3.1.6 left_join","text":"Now time join clean4a clean4b together.\n, need operation known databases\njoin.\nfact, whole concept \ntidy data closely related databases \nsomething called Codd`s normal forms12\nthrowing references just case interested \ntheoretical foundations.\nwithout ado:","code":"\nleft_join(clean4a, clean4b, by = c(\"country\", \"year\"))"},{"path":"tidy-data.html","id":"unite","chapter":"Lesson 3 Tidy data","heading":"3.1.7 unite","text":"table5, problem table3 \nadditionally opposite problem!\ntime, feature one column (namely year)\nspread across two columns (century year).want unite one,\nalso deal problem.\nHowever, find newly\ncreated year, cases population columns\nactually stored text, numbers!\nnext step, convert numbers\nparse_number function.parse_number bit like less strict version .numeric.\n.numeric can deal text contains number\nnothing else, parse_number can help us extracting numbers\neven non-number text around :parse_number handles , questions asked:Notice, applied function parse_number \nmultiple columns data?\nnotice pattern, lot’s code repetition,\nchances elegant solution.\ndon’t find elegant solution first try,\nkeeping open mind improve code long run.\ncase, let tell across function.\ncan use inside dplyr verbs mutate summarise\napply function multiple columns:’s first argument takes vector column names\n(c(...) bit) tidy-select specification (see ?dplyr_tidy_select)\n’s second argument either one function even list functions (names).Another way specifying columns use \nsay “every column country”\n-country.","code":"\ntable5\ntable5 %>% \n  unite(\"year\", century, year, sep = \"\") %>% \n  separate(rate, c(\"cases\", \"population\")) %>% \n  mutate(\n    year = parse_number(year),\n    cases = parse_number(cases),\n    population = parse_number(population)\n  )\nas.numeric(\"we have 42 sheep\")[1] NA\nparse_number(\"we have 42 sheep\")[1] 42\ntable5 %>% \n  unite(\"year\", century, year, sep = \"\") %>% \n  separate(rate, c(\"cases\", \"population\")) %>% \n  mutate(\n    across(c(year, cases, population), parse_number)\n  )\ntable5 %>% \n  unite(\"year\", century, year, sep = \"\") %>% \n  separate(rate, c(\"cases\", \"population\")) %>% \n  mutate(\n    across(-country, parse_number)\n  )"},{"path":"tidy-data.html","id":"another-example","chapter":"Lesson 3 Tidy data","heading":"3.1.8 Another example","text":"Let us look one last example data needs tidying,\nalso provided tidyr package example:lot columns!\n76 weeks song entered top 100 (assume USA)\nposition recorded.\nmight format made data entry easier,\nprevious person wanted make plots excel,\nwide format used denote multiple traces.\nevent, style visualizations grammar \ngraphics, want column represent feature,\ndata needs get longer:Let’s save variable.\n, can save extra mutate-step\nperforming transformation text numbers\nright inside pivot_longer function.Yes, pivot functions really powerful!notable difference often happens long-\nwide-format data way missing data handled.every row needs number columns,\nwide format every column week,\nbound lot NA values wherever\nsong simply longer top 100 \nspecified week.\nmissing values explicit.long format option make missing values\nimplicit simply omitting row \nmeaningful information.\nfunction na.omitt example, can remove\nrows NA somewhere:Let’s reward little visualization.\n, also introducing plotly package,\nhandy function ggplotly turn \nregular ggplot interactive plot.\nPlotly also way building plots,\nmight want check advanced interactive\n3-dimensional plots: https://plotly.com/r/,\npart don’t need worry due amazingly\nsimple ggplotly translation function.whole tidy data idea might seem like just another\nway moving numbers around.\nbuild mental model ,\ntruly transform way able think data.\ndata wrangling dplyr, shown last week,\nalso data visualization ggplot,\njourney began first week \nstill well underway.","code":"\nhead(billboard)\nbillboard %>% \n  pivot_longer(starts_with(\"wk\"), names_to = \"week\", values_to = \"placement\") %>% \n  mutate(week = parse_number(week)) %>% \n  head()\ntidy_bilboard <- billboard %>% \n  pivot_longer(starts_with(\"wk\"),\n    names_to = \"week\",\n    values_to = \"placement\",\n    names_prefix = \"wk\",\n    names_transform = list(week = as.integer)\n  )\n\ntidy_bilboard %>% head(10)\ntidy_bilboard %>%\n  head(10) %>% \n  na.omit()\nplt <- tidy_bilboard %>% \n  ggplot(aes(week, placement)) +\n  geom_point(aes(label = paste(artist, track))) +\n  geom_line(aes(group = paste(artist, track)))\n\nplotly::ggplotly(plt)"},{"path":"tidy-data.html","id":"more-shapes-for-data","chapter":"Lesson 3 Tidy data","heading":"3.2 More shapes for data","text":"Data comes many shapes R just\nvectors dataframes / tibbles.\ncourse omitting matrices,\nstore data type 2 dimensions,\n’s multi-dimensional equivalent arrays.omitting, fact already teased\nnever properly defined lists.","code":""},{"path":"tidy-data.html","id":"lists","chapter":"Lesson 3 Tidy data","heading":"3.2.1 Lists","text":"first glance, lists similar atomic vectors,\none dimensional data structures \ncan names.sets apart atomic vectors can \ncontain data type (like numbers text),\nlist can contain anything, even lists!turns , dataframes internally also lists,\nnamely list columns.\njust properties\n(R calls attributes) tell R display \nfamiliar rectangular shape.","code":"\nc(first = 1, second = 2) first second \n     1      2 \nlist(first = 1, second = 2)$first\n[1] 1\n\n$second\n[1] 2\nx <- list(first = 1, second = 2, \"some text\", list(1, 2), 1:5)\nx$first\n[1] 1\n\n$second\n[1] 2\n\n[[3]]\n[1] \"some text\"\n\n[[4]]\n[[4]][[1]]\n[1] 1\n\n[[4]][[2]]\n[1] 2\n\n\n[[5]]\n[1] 1 2 3 4 5\npalmerpenguins::penguins %>% head()"},{"path":"tidy-data.html","id":"nested-data","chapter":"Lesson 3 Tidy data","heading":"3.2.2 Nested data","text":"tidyr package provides tools dealing\ndata various shapes.\njust discovered first set operations called pivots\njoins get feel tidy data obtain various formats.\ndata always rectangular like can show spreadsheet.\nSometimes data already comes nested\nform, sometimes create nested data serves\npurpose.\n, mean nested?Remember lists can contain elements type, even lists.\nlist contains lists, call nested e.g.nested list always fun work ,\nstraightforward way represent\ndata rectangular, flat format,\nlikely want .\ndeal data rectangling today well.\nfirst, another implication\nnested lists:dataframes (tibbles) built top\nlists, can nest !\ncan sometimes come really handy.\ndataframe contains column \natomic vector list (list list),\ncall list column:Use View function, click environment panel inspect\nnested data better overview.course unlikely build nested tibbles hand\ntibble function.\nInstead, data usually comes dataset working .\nLet’s take familiar penguins dataset nest .nest syntax similar mutate, first specify name\ncolumn create (call data ),\nfollowed specification columns nest list column.data column now list tibbles individual tibble \nlist contains data species row.\nLooking data column’s first element, can see indeed\nregular tibble didn’t take personal get stuffed \nlist column.unnest column use function unnest.\nSometimes need specific use unnest_wider\nunnest_longer, automatic unnest makes\nright choices already.","code":"\nlist(\n  c(1, 2),\n  list(\n    42, list(\"hi\", TRUE)\n  )\n)\nexample <- tibble(\n  x = 1:3,\n  y = list(\n    \"hello\",\n    TRUE,\n    1:4\n  )\n)\n\nexample\n# View(example)\nnested <- palmerpenguins::penguins %>% \n  nest(data = -island)\n\nnested\nnested$data[[1]]\nnested %>% \n  unnest(data)"},{"path":"tidy-data.html","id":"exercises-2","chapter":"Lesson 3 Tidy data","heading":"3.3 Exercises","text":"","code":""},{"path":"tidy-data.html","id":"tidy-data-2","chapter":"Lesson 3 Tidy data","heading":"3.3.1 Tidy data","text":"first set exercises cheating little\ntake (absolutely brilliant) book\nR Data Science13 \noriginal creator much tidyverse.\n, first part, solve / answer 4 questions\nfound : https://r4ds..co.nz/tidy-data.html#exercises-24I give another hint, haven’t mentioned\nfar: introduced variables told \ncan contain letters, underscores numbers\nallowed start number.\nHowever, can use “illegal” names variables \ncolumns surround backticks, e.g.:Hadley can refer columns named years\npivot_longer exercise 1.","code":"\n`illegal variable` <- 42\n`illegal variable`[1] 42"},{"path":"tidy-data.html","id":"a-new-dataset-airlines","chapter":"Lesson 3 Tidy data","heading":"3.3.2 A new dataset: airlines","text":"Imagine second whole pandemic thing \ngoing planning vacation.\ncourse, want choose safest airline possible.\ndownload data incident reports.\ncan find ./data/03/ folder.Instead type_of_event n_events columns\nlike one column per type event,\nvalues count event.airlines least fatal accidents?\nhappens standardized numbers\ndistance theses airlines covered two time ranges?airlines best record comes\nfatalities per fatal accident?Create informative visualizations / tables\ncommunicate discoveries.\nmight beneficial plot e.g. highest lowest scoring Airlines.\nOne slice_ functions help .\nmake plot organized, might want \nlook fct_reorder.","code":""},{"path":"tidy-data.html","id":"resources-1","chapter":"Lesson 3 Tidy data","heading":"3.4 Resources","text":"tidyr documentationpurrr documentationstringr documentation\nworking text helpful cheatsheet \nregular expressions mentioned video","code":""},{"path":"functional-programming.html","id":"functional-programming","chapter":"Lesson 4 Functional Programming","heading":"Lesson 4 Functional Programming","text":"… functions, bringing whole tidyverse together \nexploring advanced dplyr data wrangling techniques.","code":""},{"path":"functional-programming.html","id":"todays-goal","chapter":"Lesson 4 Functional Programming","heading":"4.1 Todays goal","text":"goal today bring together everything\nlearned far solidify\nunderstanding wrangling data tidyverse.\ngoes according plan,\nmental capacity\nfreed statistics starting next week.\nunderstanding data hopefully\nenable us experiment play statistical\nconcepts without getting stuck much\ndata wrangling.\nalso means today’s lecture might\nchallenging far, \neverything learned now – \none way another – relevant.first, load libraries today usual.\nNote, cheating bit loading\ngapminder package well.\nEven though reading actual gapminder dataset\nfiles today, access \nvector country colors nice .lecture also quickly go \nimportant resources far.\nmostly concerns pure R resources,\ncover resources statistics maths\ninvolved next couple lectures.might able tell,\nmental models one favorite topics.\nstarting today powerful mental model:\niteration.","code":"\nlibrary(tidyverse)\nlibrary(gapminder)"},{"path":"functional-programming.html","id":"iteration","chapter":"Lesson 4 Functional Programming","heading":"4.2 Iteration","text":"Iteration basic idea one thing multiple times.\narea computers shine,\nchapter learn fully utilize power fingertips.example, reading multiple similar files.\nRemember gapminder dataset?\nWell, working ,\ntime, collaborator sent us one csv-file continent.\ncan find data/04/ folder.already know read one csv-file:","code":"\nread_csv(\"./data/04/Africa.csv\")"},{"path":"functional-programming.html","id":"the-imperative-programming-approach","chapter":"Lesson 4 Functional Programming","heading":"4.2.1 The Imperative Programming Approach","text":"first solution problem favorite one,\nwant show anyway sake completeness.\ngeneral, Functional Programming, tell computer want, Imperative Programming, tell computer steps .\n, tell R steps perform.\nFirst, get vector file-path’s \nfs package, stands file system.\ndir_ls means directory list, get \ncontents directory.\ncreate list store dataframes \ngoing read .\nalready define length list \nmaking data structure longer R’s strong suit \ndoesn’t know much space reserve .\niterate numbers 1 length\npaths.\niteration get path, read store\nresults list position .\nFinally bind list one dataframe:lost information Continent,\nfile name,\ndwelling long, let’s leave convoluted manual way behind explore ,\ndare say, elegant approach.","code":"\npaths <- fs::dir_ls(\"./data/04/\")\n\nresult <- vector(mode = \"list\", length = length(paths))\nfor (i in 1:length(paths)) {\n  result[[i]] <- read_csv(paths[i])\n}\n\nbind_rows(result)"},{"path":"functional-programming.html","id":"the-functional-programming-approach","chapter":"Lesson 4 Functional Programming","heading":"4.2.2 The Functional Programming Approach","text":"“course someone write -loops.\ndoesn’t .”\n— Jenny BryanWe function (read_csv) takes file path returns\n(spits ) data.\nFunctional Programming style,\nnext idea now function, takes two things:\nvector (atomic list) function.\nfeeds individual elements vector function,\none another.\nmathematics, relation set inputs set outputs called map,\nname following family functions comes .\ntidyverse, functional programming concepts live purrr package.Iterating Explicitly maps:First, create vector things want iterate , things\nfed function one :map read_csv function vector\nbind resulting list dataframes one dataframe:operation mapping vector combining resulting\nlist one dataframe actually common \nvariant map step automatically:distills everything initial -loop just one line code.\nUsing .id argument can save name file path\ncolumn dataset.\nallows us extract continent :way extracting continent file path seems magical first,\nstill refer cheat sheet stringr package lot\ndeal text:Iterating implicitly vectorized functions:first encounter iteration implicit form.\nuse\nR’s basic math operators, computer iterating behind scenes.\nTake expression:operation vectorized.\nWithout us tell R , R add first element first vector first element second vector forth.Notice, looks like operation happens time.\nreality, happens.\ncomputer just really fast adding numbers, one .mathematical operations R call another programming language \nactual addition.\nprogramming language closer way computers think,\nmaking less fun write us humans,\nalso faster instructions easier translate actions computer processor.Remember, build iteration (e.g. map function),\nfind task want apply multiple things,\nalready vectorized.\nturns , fs readr packages play \nwell together, readr can also just take vector\nfile paths combining automatically!Whenever encounter new problem, ask questions:function already ?already vectorized?, function solves problem one instance?Can map many things?purrr package contains various variants map function.map always return list.map_chr always returns atomic character (=text) vector.map_dbl always returns numbers (dbl = double precision).map_lgl always returns logical (yes , TRUE / FALSE) vectors.map_dfr always returns dataframe.-loop-version lot code, especially boilerplate, code just make construct work doesn’t convey intentions \ncode.\nFurthermore, loop focuses object iterated (file\npaths), map-version focuses happening (function, read_csv).\nloop still works.\ncan’t think way solve problem map function, absolutely OK use -loops.","code":"\npaths <- fs::dir_ls(\"./data/04/\")\nresult <- map(paths, read_csv)\nbind_rows(result)\nmap_df(paths, read_csv, .id = \"continent\")\ngapminder <- map_df(paths, read_csv, .id = \"continent\") %>% \n  mutate(continent = str_extract(continent, \"(?<=/)\\\\w+(?=\\\\.csv)\"))\n\nhead(gapminder)\n1:3 + 1:3[1] 2 4 6\nread_csv(paths, id = \"continent\")\n# map_"},{"path":"functional-programming.html","id":"if-you-copy-and-paste-the-same-code-more-than-three-times-write-a-function.","chapter":"Lesson 4 Functional Programming","heading":"4.3 “If you copy and paste the same code more than three times, write a function.”","text":"Writing functions can helpful making \ncode readable.\nallows us separate certain steps analysis\nrest, look isolation test \nvalidate , also allows us give reasonable names.also allows us re-use function across projects!\nLet’s imagine experiment read-\nmachine always certain format needs \ncleaning .\nturn function, e.g. like :can put function file (case R/my_functions)\nsource , example multiple analysis Rmarkdown documents.\nsource function nothing special, just runs R\ncode file.\ndefine functions file, functions\navailable us:Note: example function make sense use \n4 input, data days\ncourse different, hope get gist.like store regular R files (opposed Rmd files)\nfolder project called R.\nmakes already look like R package,\ncase decide later functions\nhelpful others well\nwant share easily\ncolleagues.\ncan read creating \nR packages .14","code":"\nread_experiment_data <- function(day) {\n  day <- str_pad(day, pad = 0, width = 2)\n  paths <- fs::dir_ls(paste0(\"./data/\",day,\"/\"))\n\n  gapminder <- map_df(paths, read_csv, .id = \"continent\") %>% \n    mutate(continent = str_extract(continent, \"(?<=/)\\\\w+(?=\\\\.csv)\"))\n\n  gapminder\n}\nsource(\"R/my_functions.R\")\nread_experiment_data(4)"},{"path":"functional-programming.html","id":"implicit-iteration-with-dplyr-build-many-models","chapter":"Lesson 4 Functional Programming","heading":"4.4 Implicit iteration with dplyr: build many models","text":"dplyrs idea grouping allows us express many\nideas implicitly also iterations.Let us start looking just one country first:can plot life expectancy time ggplot\nadd linear model plot \ngeom_smooth using method = \"lm\".However, geom_smooth allows us easily add smoothing\nlines linear trends plot, \ngive us information actual model.\norder need fit \nlm function:~ symbol defines formula, can read :\n“lifeExp depending year”.\ndata argument tells R look variables\nlifeExp year, namely algeria tibble.lot information model!\nbroom package provides functions cleaner\nspecialized output:Every 1 year life expectancy Algeria went half year.\ncourse, valid limited linear regime \ndatapoints.\ncan’t extrapolate indefinitely.\n, intercept tells us negative\nlife expectancy year 0.given data , good line fit ?R2 takes values 0 1, 1 perfectly\nstraight line connecting points 0 points\nplace.\n0.985 pretty good fit!Using dollar syntax, get pull one column \ntibble, can write function , given model,\nreturns R2And now come dplyr magic!\ngroup country (continent good measuere\njust don’t loose column summarizing),\ncan calculate linear model every country!Note two things: Firstly, don’t use data argument\nlm tidyverse functions already know\nlook lifeExp year \nrespecting groups.\nwithin group (.e. country), lifeExp contain life expectancy country,\nlife expectancy countries.\nSecondly, wrap part list \ncreate list column (models don’t fit atomic vector).\nOtherwise, dplyr complain.second step calculate rsqured value\nmodel mapping function created \nmodels.\nuse _dbl variant want values\natomic vector numbers, list.Finally, can add calculated R2 values column \noriginal gapminder dataset can use \nfollowing visualization., highlight irregularities (less linear countries)\nmaking transparency (= alpha value) depend\nR2 value.can highlight one continent filtering use \nggrepel package allow flexible labels.\nFurthermore check source document lecture\nvideo lecture find can\nadd figure caption control width height\nplot via knitr chunk options.\nalso showcase new way writing chunk options\nlatest version knitr package especially\nsuited longer captions.\nFigure 4.1: Figure caption\ndownward slope highlighted countries\nstarting 1990s result ravaging\nAIDS pandemic.\nprominent dips two curves, orange \nRwanda Cambodia gray, direct\nconsequences genocides.\ndire realities can way summarized\njust couple colorful lines.\nalso way qualified lecture\ntopics.\ngood friend mine, Timothy Williams,\nhowever researcher teacher field conflict violence\nfocus genocides.\nfield work Cambodia Rwanda\nbook “Complexity Evil. Perpetration Genocide” published December 18 2020.15","code":"\nalgeria <- gapminder %>% \n  filter(country == \"Algeria\")\nalgeria %>% \n  ggplot(aes(year, lifeExp)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\nmodel <- lm(lifeExp ~ year, data = algeria)\nsummary(model)\nCall:\nlm(formula = lifeExp ~ year, data = algeria)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3844 -0.5935 -0.2703  0.5339  2.4992 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.068e+03  4.380e+01  -24.38 3.07e-10 ***\nyear         5.693e-01  2.213e-02   25.73 1.81e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.323 on 10 degrees of freedom\nMultiple R-squared:  0.9851,    Adjusted R-squared:  0.9836 \nF-statistic: 661.9 on 1 and 10 DF,  p-value: 1.808e-10\nbroom::tidy(model)\nbroom::glance(model)\nget_r_squared <- function(model) {\n  broom::glance(model)$r.squared\n}\nall_models <- gapminder %>% \n  group_by(country, continent) %>% \n  summarise(\n    model = list(lm(lifeExp ~ year)),\n    rsquared = map_dbl(model, get_r_squared)\n  )\n\nhead(all_models)\ngapminder <- gapminder %>% \n  left_join(select(all_models, -model))\ngapminder %>% \n  ggplot(aes(year, lifeExp, color = country, alpha = 1/rsquared)) +\n  geom_line() +\n  guides(color = \"none\", alpha = \"none\") +\n  scale_color_manual(values = country_colors) +\n  facet_wrap(~continent, scales = \"free\") +\n  theme_minimal()\ngapminder %>% \n  filter(continent == \"Africa\") %>% \n  ggplot(aes(year, lifeExp, color = country, group = country)) +\n  geom_line(color = \"black\", alpha = 0.3) +\n  geom_line(data = filter(gapminder, rsquared <= 0.4), size = 1.1) +\n  ggrepel::geom_text_repel(aes(label = country),\n                           data = filter(gapminder, rsquared <= 0.4,\n                                         year == max(year)),\n                           nudge_x = 20,\n                           direction = \"y\"\n                           ) +\n  guides(color = \"none\", alpha = \"none\") +\n  scale_color_manual(values = country_colors) +\n  facet_wrap(~continent, scales = \"free\") +\n  labs(x = \"Year\", y = \"Life Expectancy at Birth\") +\n  theme_minimal() +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.2)))"},{"path":"functional-programming.html","id":"exercises-3","chapter":"Lesson 4 Functional Programming","heading":"4.5 Exercises","text":"want get playing around data,\nkeep mind solutions exercise\nset stone.\noften one viable way graphing\ndataset use \nOffice Hour talk advantages\ndisadvantages approaches \ncame .","code":""},{"path":"functional-programming.html","id":"roman-emperors","chapter":"Lesson 4 Functional Programming","heading":"4.5.1 Roman emperors","text":"first exercise uses dataset roman emperors\ntidytuesday project\n(link).\ncan import :slight error data dates actually BC time.\norder fix using lubridate package,\ninstalled tidyverse, automatically loaded.\nconvenience function can use fix dataset:questions answer.\nDecide , particular question best\nanswered using visualization, table, simple sentence\ncombination three.popular way rise power?common causes death among roman\nemperors? () killed ?dynasty successful?\nFirstly, often dynasty reign?\nSecondly, long reigns?\ndynasty rather part ,\ngoal live longest?\nFirstly, often dynasty reign?Secondly, long reigns?dynasty rather part ,\ngoal live longest?","code":"\nemperors <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv\")\nlibrary(tidyverse)\nlibrary(lubridate)\n\nfix_emperors <- function(data) {\n  data %>% \n    mutate(\n      birth = case_when(\n        index %in% c(1, 2, 4, 6) ~ update(birth, year = -year(birth)),\n        TRUE                     ~ birth\n      ),\n      reign_start = case_when(\n        index == 1 ~ update(reign_start, year = -year(reign_start)),\n        TRUE       ~ reign_start\n      )\n    )\n}"},{"path":"functional-programming.html","id":"dairy-products-in-the-us","chapter":"Lesson 4 Functional Programming","heading":"4.5.2 Dairy Products in the US","text":"Another dataset\n(link)\nconcerns dairy product consumption per person US across number years.\nLoad :masses given lbs (pounds),\ncan convert kg?products lost customer base time,\nones won? products greatest absolute\nchange production estimated straight line?, fun! make interesting\nfindings along way, go ahead produce plots\nhighlight .","code":"\ndairy <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/milk_products_facts.csv\")"},{"path":"functional-programming.html","id":"resources-2","chapter":"Lesson 4 Functional Programming","heading":"4.6 Resources","text":"purrr documentationstringr documentationdplyr documentation","code":""},{"path":"probability-and-hypothesis-testing.html","id":"probability-and-hypothesis-testing","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"Lesson 5 Probability and Hypothesis Testing","text":"… reason nature randomness \ndiscover various statistical tests.","code":""},{"path":"probability-and-hypothesis-testing.html","id":"motivation","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.1 Motivation","text":"first four lectures covered fundamentals handling data R.\nNow, shift focus away towards \ndata analysis. talk different statistical tests, common mistakes,\navoid spot research. course, \nusing R. still learn one useful function \ntechnique along way. instances clear use R\nsolely demonstrate idea statistics code just included \ncurious, whether code something likely also use \nanalysis. open questions things unclear two\ncases. purely aesthetic code might also speed typing edit.longer text parts might helpful look script watching video pause frequently take notes (Rmarkdown great lecture notes well!).","code":"\nlibrary(tidyverse)"},{"path":"probability-and-hypothesis-testing.html","id":"statistically-significant","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.2 Statistically Significant…","text":"…keep using word. don’t think means think means.statistically significantYou hear phrases “statistically significant”, “significant” even\n“significant” thrown around quite bit academic literature . \noften used carelessly, clearly defined meaning. meaning\nuncover today. meaning related concept called\np-values, equally bad reputation frequently misused. \np p-value stands probability, order understand p-values, \nneed understand probability learn deal randomness, chance, \nluck . …","code":""},{"path":"probability-and-hypothesis-testing.html","id":"getting-our-hands-dirty-with-probability","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.3 Getting our Hands dirty with Probability","text":"understand statistics means understanding nature randomness first.\nFigure 5.1: ggplot chessboard\nSay friend playing game chess, friend proudly\nproclaims:\n“definitely better player!”.\n“Proof !”, reply.\n“’s easy”, says: “won 7 8 rounds played today.”\n“Pah! ’s just luck.” less witty slightly stubborn response.expected, shall using R resolve vital conflict.R rainbow","code":""},{"path":"probability-and-hypothesis-testing.html","id":"definitions-hypothesis","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.3.1 Definitions: Hypothesis","text":"involuntarily uttered hypothesis, testable assumption. \nwant test hypothesis using statistics. first hypothesis (“\nbetter player.”) call alternative hypothesis (\\(H_1\\)). \nname can bit confusing, often, actual scientific\nhypothesis, thing interested . , alternative ? \nalternative called null hypothesis (\\(H_0\\)), second\nstatement (“just luck”). null hypothesis provides sort baseline\nfindings. usually goes along lines “\nobservations just based chance alone?”, “chance” can source\nrandom variation system.tricky part way directly test alternative\nHypothesis, can test null hypothesis. null\nhypothesis discard, always multiple alternative hypothesis \nexplain data. example, even end discarding idea \nfriend’s chess success luck, prove \nalternative hypothesis better player (still \ncheating example). keep mind transfer \nscientific setting. Just show something unlikely \narisen chance mean favorite alternative hypothesis \nautomatically true., words warning, let’s test null hypothesis!","code":""},{"path":"probability-and-hypothesis-testing.html","id":"testing-the-null-hypothesis-with-a-simulation","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.3.2 Testing the Null Hypothesis with a Simulation","text":"start building little simulation. testing \nhypothesis, important defined \\(H_0\\) \\(H_1\\) properly, \nprevious section. need little specific. Winning \nchance entail completely random process, can model coin\nflip. R lovely function sample take number things \nvector, without replacement taking thing:giving number things draw just shuffles vector, \nfairly boring case just two tings. can’t sample 10 things \nvector two elementsBut can, put thing back every time:, let’s make little specific question:run script million times, resulting proportion\nrandom wins , close 50-50 \nused fair coin. However, don’t time play much Chess \nsure don’t money run million replicates experiment \nlab. , little simulated world, near infinite\nresources (simulation computationally costly).One trick used : calculate e.g. sum mean,\nR automatically converts TRUE 1 FALSE 0.Let’s create function returns random number wins friend \ngotten pure chance number rounds N.number different every time, change?histogram type plot shows often value occurs \nvector. Usually, values put bins first, grouping close values\ntogether continuous values, case makes sense just one\nvalue per bin dealing discrete values (e.g. half-wins).\nHistograms can either display raw counts frequency e.g. \npercentage. ggplot, use geom_bar don’t need binning, just\ncounting occurrences, geom_histogram need bin continuous\nvalues.expected, common number wins 8 4 (unless got really\nunlucky compiling script). Let us see, distribution\nchanges different values N. First, set grid numbers (\npossible combinations) can run bunch simulations:use trusty ggplot visualize distributions.fair coin, common number wins half number \ncoin flips. Note, still possible flip coin 15 times \nwin single time. just unlikely bars small \ncan’t see .Let us go back original debate. first statement: “better.” \nsomething can never definitively proven. always \npossibility, matter small, result arisen pure\nchance alone. Even wins 100 times don’t take single game \n, sort outcome still impossible appear just flipping \ncoin. can , calculate, likely certain event \nassumption null hypothesis (chance). can also decide \nthreshold \\(\\alpha\\) reject null hypothesis. called \nsignificance threshold. make observation calculate \nprobability observation like extreme smaller \nthreshold, deem result statistically significant. probability\nthus created called p-value.simulation, find probability win 7 8 rounds \nnull hypothesis :smaller commonly used significance threshold \\(\\alpha=0.05\\)\n(.e. \\(5\\%\\)). 7 8 wins, reject null hypothesis.\nnote threshold, matter commonly thoughtlessly used\nthroughout academic research, completely arbitrary.","code":"\ncoin <- c(\"heads\", \"tails\")\nsample(coin)[1] \"heads\" \"tails\"\nsample(coin, size = 10)Error in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when 'replace = FALSE'\nsample(coin, 10, replace = TRUE) [1] \"tails\" \"heads\" \"heads\" \"tails\" \"heads\" \"tails\" \"heads\" \"tails\" \"tails\"\n[10] \"tails\"\nwinner <- c(\"you\", \"friend\")\nrandom_winners <- sample(winner, size = 8, replace = TRUE)\nrandom_winners[1] \"friend\" \"you\"    \"friend\" \"you\"    \"you\"    \"friend\" \"you\"    \"you\"   \nrandom_winners == \"friend\"[1]  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE\n1 + TRUE[1] 2\n1 + FALSE[1] 1\nsum(random_winners == \"friend\")[1] 3\nmean(random_winners == \"friend\")[1] 0.375\nget_n_win <- function(N) {\n  winner <- c(\"you\", \"friend\")\n  random_winners <- sample(winner, size = N, replace = TRUE)\n  sum(random_winners == \"friend\")\n}\n\nget_n_win(8)[1] 4\nresult <- map_dbl(rep(8, 1000), get_n_win)\nhead(result)[1] 5 5 6 4 1 3\ntibble(result) %>% \n  ggplot(aes(x = result)) +\n  geom_bar() +\n  labs(x = \"N wins for friend\",\n       title = \"Throwing a coin 8 times\") +\n  scale_x_continuous(breaks = 0:8)\nsimulation <- crossing(\n   N = 1:15,\n   rep = 1:1000\n) %>% \n  mutate(\n    wins = map_dbl(N, get_n_win)\n  )\nsimulation %>% \n  ggplot(aes(wins)) +\n  geom_bar() +\n  facet_wrap(~N, labeller = label_both) +\n  labs(title = \"Flipping a coin N times\")\nsimulation %>% \n  filter(N == 8) %>% \n  summarise(\n    mean(wins >= 7)\n  )"},{"path":"probability-and-hypothesis-testing.html","id":"getting-precise-with-the-binomial-distribution","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.3.3 Getting precise with the Binomial Distribution","text":"Now, just simulation 1000 trials, number can’t \narbitrarily precise, mathematical formula probability.\ncreated counting number successes series yes--trials\nbinomial distribution. common distributions, R provides \nset functions. functions starting d give us probability\ndensity function. case discrete values like counting wins, \nequivalent actual probability, continuous values obtain \nprobability taking integral. get integrals \ncorresponding functions starting p (probability).probability win exactly 7 8 games. wanted\nprobability 7 8! move integral. \npart can get bit confusing, default pbinom \nlower.tail = TRUE, according help page means probabilities\nreturns \\(P[X \\le x]\\).set lower.tail FALSE , get \\(P[X > x]\\), probability \nrandom variable X bigger number x. get probability \ninterested , need replace 7 6 well:simulation pretty close! exact values agrees reject \nnull hypothesis opponents equally good.\nfull graph probability density function binomial\ndistribution.integral, probability \\(P[X \\le x]\\).two functions want showcase family. third \ncalled quantile function. Quantiles divide probability distribution\npieces equal probability. One example quantile 50th\npercentile, also known median, divides values half \nvalues half . can keep dividing two halves\nwell, end quantiles. Eventually, arrive \nquantile function. inverse probability function, obtain\nswapping axis.Quantiles also useful \ndeciding random sample follows certain distribution\nquantile-quantile plots.Lastly, always also r variant function, gives us \nnumber random numbers distribution.","code":"\ndbinom(x = 7, size = 8, prob = 0.5) [1] 0.03125\npbinom(q = 7, size = 8, prob = 0.5)[1] 0.9960938\npbinom(q = 6, size = 8, prob = 0.5, lower.tail = FALSE)[1] 0.03515625\nggplot() +\n  stat_function(fun = function(x) dbinom(x = x, size = 8, prob = 0.5),\n                geom = \"step\",\n                n = 9) +\n  scale_x_continuous(n.breaks = 9, limits = c(0, 8))\nggplot() +\n  stat_function(fun = function(q) pbinom(q = q, size = 8, prob = 0.5),\n                geom = \"step\",\n                n = 9) +\n  scale_x_continuous(n.breaks = 9, limits = c(0, 8))\nggplot() +\n  stat_function(fun = function(p) qbinom(p = p, size = 8, prob = 0.5),\n                geom = \"step\",\n                n = 9) +\n  scale_x_continuous(n.breaks = 10, limits = c(0, 1))\nrbinom(10, 8, 0.5) [1] 6 5 5 3 5 6 4 4 2 4"},{"path":"probability-and-hypothesis-testing.html","id":"but-how-much-better-understanding-effect-size-and-power-false-positives-and-false-negatives","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.3.4 But how much better? Understanding Effect Size and Power, False Positives and False Negatives","text":"decided abandon null hypothesis players equally good,\nequates 50% win-chance player. determined\nmuch better . much better need us \nreliably discard null hypothesis just 8 games? generalization \nmuch better part, true difference, called effect\nsize.ability decide something statistically significant \nfact true difference called statistical power. depends \neffect size, significance threshold \\(\\alpha\\) sample size \\(n\\) (\nnumber games). can explore concept another simulation.also introduced new piece advanced dplyr syntax. rowwise similar \ngroup_by essentially puts row group. can useful\nworking list columns running function varying arguments \nallows us treat inside mutate bit like using one \nmap functions. information, see documentation\narticle.leaves us 10000 simulated numbers wins N games different\ntrue probabilities winning (.e. much better friend ). \ncalculate probability greater number wins \nnull hypothesis (equal probability win loss), words: \np-value.notice couple things plot. number games\nplayed approaches high numbers, p-values \ncase null hypothesis fact true (players \nchance winning), start following uniform distribution,\nmeaning true null hypothesis, p-values equally likely.\nseems counterintuitive first, direct consequence\ndefinition p-value.\nconsequence , apply regular significance\nthreshold 5%, definition say true\ndifference, even though none (.e. null hypothesis true\nfalsely reject favor alternative hypothesis).\ncalled false positive. definition, get \nleast \\(\\alpha\\) false positives experiments.\nLater, learn, real number false positives \neven higher.\nAnother name false positives Type errors.side coin, also cases\ntrue difference (used winning probabilities\n0.8 0.9), don’t reject null hypothesis \nget p-values larger \\(alpha\\).\nfalse negatives rate sometimes\nreferred \\(\\beta\\).\nAnother name false negatives Type II errors.\nPeople don’t particularly like talking negative things like errors,\ninstead often see inverse \\(\\beta\\), \nStatistical Power \\(1-\\beta\\).\nproportion correctly identified positives \nactual positives also shown plot .\nexample, say true win probability 90%\nplay 8 games. experiment runs infinite\nnumber parallel universes, conclude \nbetter chance 80% .\nset significance threshold higher detect\ntrue positives, \nalso increase false positives.also packages , function\ncompute power binomial test, think\nsimulation way approachable.\ncool thing simulations also, work\neven analytical solution, \ncan use play around planning experiment.","code":"\nreps <- 10000\nsimulation <- crossing(\n  N = c(8, 100, 1000, 10000),\n  true_prob = c(0.5, 0.8, 0.9)\n) %>% \n  rowwise() %>% \n  mutate(\n    wins = list(rbinom(n = reps, size = N,  prob = true_prob)),\n  ) %>% \n  unnest(wins) %>% \n  mutate(\n    p = pbinom(q = wins - 1, size = N, prob = 0.5, lower.tail = FALSE)\n  )\n\nhead(simulation)\nsimulation %>%\n  ggplot(aes(p)) +\n  geom_histogram() +\n  facet_wrap(~ true_prob + N,\n             labeller = label_both,\n             scales = \"free_y\",\n             ncol = 4) +\n  geom_vline(xintercept = 0.05, color = \"red\") +\n  labs(x = \"p-value\",\n       y = \"frequency\") +\n  scale_y_continuous(breaks = NULL)\nsimulation %>%\n  group_by(true_prob, N) %>%\n  summarise(signif = mean(p <= 0.05)) %>% \n  ggplot(aes(true_prob, signif, fill = true_prob == 0.5)) +\n  geom_col(color = \"black\") +\n  geom_text(aes(label = signif), vjust = -0.2) +\n  facet_wrap(~N,\n             labeller = label_both) +\n  scale_y_continuous(expand = expansion(c(0, 0.1))) +\n  scale_fill_viridis_d() +\n  labs(y = \"Proportion of significant results\")"},{"path":"probability-and-hypothesis-testing.html","id":"p-value-pitfalls","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.4 P-Value Pitfalls","text":"Let us look pitfalls p-values.\nRemember definition p-values, get\nsignificant result even true difference \n5% cases (assuming use alpha)?\nWell, test bunch things?\ncalled Multiple Testing problem\nassociated :test 20 different things, statistical\ntest produce significant result chance alone\n5% cases, expected number significant results 1.\nsurprised.\nSpeaking surprised: book, available free online,\n“Statistics done wrong”, Alex Reinhart\ndescribes p-values “measure surprise”:»p value measure right ,\nsignificant difference ;\n’s measure surprised actual difference\ngroups, got data suggesting .\nbigger difference, one backed data,\nsuggests surprise smaller p value.«\n— Alex Reinhart16So, surprised, focus hard \none significant result, trouble ensues.\n“publish perish” mentality, can easily happen,\nnegative findings published nearly enough,\npublished findings likely exaggerated.\nJohn Bohannon showcased beautifully \nrunning study chocolate consumption \ngetting published:\nFooled Millions Thinking Chocolate Helps Weight Loss. ’s .can ?","code":""},{"path":"probability-and-hypothesis-testing.html","id":"multiple-testing-correction","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.4.1 Multiple Testing Correction","text":"simplest approach take p-values calculate\nrunning large number comparisons \ndividing number tests performed.\ncalled Bonferroni correctionOf course, looses statistical power\n(remember, free lunch).\nslightly sophisticated approach \ncontrolling false discovery rate (FDR)\nBenjamini-Hochberg procedure. retains\nbit power. happens:Sort p-values ascending order.Choose FDR \\(q\\) willing accept\ncall number tests done \\(m\\).Find largest p-value :\n\\(p \\leq iq/m\\) index \\(\\).new threshold significanceScale p-values accordinglyAnd R:","code":"\np_values <- c(0.5, 0.05, 0.3, 0.0001, 0.003)\np.adjust(p_values, method = \"bonferroni\")[1] 1.0000 0.2500 1.0000 0.0005 0.0150\np.adjust(p_values, method = \"fdr\")[1] 0.50000000 0.08333333 0.37500000 0.00050000 0.00750000"},{"path":"probability-and-hypothesis-testing.html","id":"other-forms-of-p-hacking","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.4.2 Other forms of p-hacking","text":"sort multiple testing fairly obvious.\nnotice , end large\nnumber p-values, example genetic\nscreening testing thousands genes.\nrelated problems harder spot.\nsingle research question often different\nstatistical tests run, trying\nchoosing one best\nagrees hypothesis option!\nLikewise, simply looking data form \ncomparison influences choice statistical test.\nIdeally, first run exploratory experiments\nmeant test hypothesis, \ndecide tests need, sample size \nwant particular power run actual\nexperiments designed test hypothesis.point, another shout-\nAlex Reinharts book.17\npleasant read\nalso shines light \nforms p-hacking.","code":""},{"path":"probability-and-hypothesis-testing.html","id":"bayesian-statistics-and-the-base-rate-fallacy","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.5 Bayesian Statistics and the Base Rate Fallacy","text":"another subtle problem called \nbase rate fallacy. example, assume\nmedical test, testing certain condition.\nmedical testing, different words used\nconcepts defined above18., :Sensitivity = Power = true positive rate = \\(1-\\beta\\)Specificity = true negative rate = \\(1-\\alpha\\)Let us assume test \nsensitivity 90% specificity\n92%. visit doctor \nget test, get positive result,\nprobability, \nfact positive (.e. true positive)?\nWell, test specificity 92%,\nnegative, detected\n92% cases, mean, can\n92% certain, actually positive?Well, . ignoring \nbase rate, diseases called\nprevalence. proportion \ndisease exists general population., let us say, picking 1000 people\nrandom population testing\n. dealing hypothetical\ncondition affects 1% people,\nassume 10 people sample positive.\n10 people, 9 tested positive\n(due sensitivity),\ntrue positives.\nremaining 1 false negative.\nHowever, course also testing\nnegatives (knew ahead time\npoint testing) \ndue specificity, 8% also \ntested positive, 0.08 * 990, \nget 79 false positives.\nmany negatives \nsample, even relatively high specificity\nproduce lot false positives.\nactual probability \npositive positive test result \\[\\frac{true~positives}{true~positives + false~positives}=10\\%\\]Formally, described Bayes’s Formula\\[P(|B)=\\frac{P(B|)*P()}{P(B)}\\]Read: probability given B probability\nB given times probability divided \nprobability B.bayesian statistics, prevalences known\npriors.","code":""},{"path":"probability-and-hypothesis-testing.html","id":"concepts-discussed-today","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.6 Concepts discussed today","text":"today familiar following concepts:Null alternative hypothesisP-values statistical significanceBinomial distributionProbability density, probability quantile functionsEffect size statistical powerFalse positives, false negativesMultiple testing p-hackingBayes’s Theorem","code":""},{"path":"probability-and-hypothesis-testing.html","id":"exercises-4","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.7 Exercises","text":"","code":""},{"path":"probability-and-hypothesis-testing.html","id":"an-fair-coin","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.8 An Fair Coin","text":"regular old coin flip 100 times.\nGiven significance threshold \\(\\alpha\\) 0.05,\nprobability (mistakenly) reject null hypothesis .e.\nconclude coin fair even though ?\nCan show simulation?\ntip can tell due vectorized nature\nfunctions involved won’t need map loop.\nshortest version think uses 3 functions.","code":""},{"path":"probability-and-hypothesis-testing.html","id":"an-unfair-game","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.9 An Unfair Game","text":"playing game roll sixes order win.\nSomeone trying fool us using loaded die.\ndie manipulated chance rolling\nsix 35% instead usual 1/6.\nsignificance threshold , \nchance us rejecting null hypothesis (= fair die)\nthus concluding correctly tricked\nrolling die 20 times?\nrun simulation .","code":""},{"path":"probability-and-hypothesis-testing.html","id":"discovering-a-new-distribution","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.10 Discovering a new Distribution","text":"binomial distribution concerned sampling\nreplacement (can get head tails number\ntimes without using coin). exercise\nexplore sampling without replacement.\ncommon model urn two\ndifferent colored balls .\nresulting distribution called \nhypergeometric distribution \ncorresponding R functions <r/d/p/q>hyperImagine zoo manager.\ngot gift another zoo! consists\n8 red pandas 2 giant pandas.\nprobability end \nproperly separated, randomly take 8 animals,\nput one enclosure put rest another?\npenguin colony hatched eggs \nbunch newcomers. 15 males \n10 females. look random subset \n12 penguins, distribution \nnumber males look like? number \nlikely? likely , get least\n9 males sample?\ngot gift another zoo! consists\n8 red pandas 2 giant pandas.\nprobability end \nproperly separated, randomly take 8 animals,\nput one enclosure put rest another?penguin colony hatched eggs \nbunch newcomers. 15 males \n10 females. look random subset \n12 penguins, distribution \nnumber males look like? number \nlikely? likely , get least\n9 males sample?","code":""},{"path":"probability-and-hypothesis-testing.html","id":"resources-3","chapter":"Lesson 5 Probability and Hypothesis Testing","heading":"5.11 Resources","text":"https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108https://jimgruman.netlify.app/post/education-r/P-Value histograms blogpost David Robinson“Statistics done wrong”","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"distributions-summaries-and-dimensionality-reduction","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","text":"… explore continuous distributions spotify data,\nfind central limit theorem related statistical tests\nbecome N-dimensional whale sharks.just notes lecture \nfilled recording.\nCheck back later completed script.","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"some-preparation","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.1 Some Preparation","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"sidenote-on-reproducible-environments-with-renv","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.1.1 Sidenote on Reproducible Environments with renv","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"all-models-are-wrong-but-some-are-useful","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.2 All models are wrong, but some are useful","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"types-of-models","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.2.1 Types of Models","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"say-hello-to-spotify-data","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.3 Say Hello to Spotify Data","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"visualising-continuous-distributions","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.4 Visualising Continuous Distributions","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"summary-statistics","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.4.1 Summary Statistics…","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"or-how-to-lie-with-graphs","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.4.2 … or: How to Lie with Graphs","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"graphic-devices-fonts-and-the-ggplot-book","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.5 Graphic Devices, Fonts and the ggplot Book","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"ggplot-book","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.5.1 ggplot book","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"graphics-devics","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.5.2 Graphics Devics","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"the-normal-distribution-and-the-central-limit-theorem","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.6 The Normal Distribution and the Central Limit Theorem","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"log-normality","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.6.1 Log-normality","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"the-t-distribution","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.7 The T-Distribution","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"students-t-test","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.8 Student’s T-Test","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"wilcoxon-rank-sum-test","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.9 Wilcoxon rank-sum test","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"direction-of-testing","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.9.1 Direction of Testing","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"confidence-intervals","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.9.2 Confidence Intervals","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"chrunching-dimensions-with-dimensionality-reduction-pca","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.10 Chrunching Dimensions with Dimensionality Reduction: PCA","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"exercises-5","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.11 Exercises","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"the-plotty-horror-picture-show","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.11.1 The Plotty Horror Picture Show","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"take-a-sad-plot-and-make-it-better","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.11.2 Take a Sad Plot and Make it Better","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"stats-time","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.11.3 Stats Time","text":"","code":""},{"path":"distributions-summaries-and-dimensionality-reduction.html","id":"resources-4","chapter":"Lesson 6 Distributions, Summaries and Dimensionality Reduction","heading":"6.12 Resources","text":"Tidymodels websiteTidymodels bookggplot bookragg graphics device","code":""},{"path":"fallacies-correlation-and-regression.html","id":"fallacies-correlation-and-regression","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"Lesson 7 Fallacies, Correlation and Regression","text":"… hear Stories Warplanes,\nCorrelation Regression explore Datasaurus Dozen.just notes lecture \nfilled recording.\nCheck back later completed script.","code":""},{"path":"fallacies-correlation-and-regression.html","id":"data-considerations","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.1 Data Considerations","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"section","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.1.1 1943","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"the-story-of-abraham-wald","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.1.2 The Story of Abraham Wald","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"thinking-further","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.1.3 Thinking further","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"miscelaneous","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.2 Miscelaneous","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"glue","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.2.1 Glue","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"svgs","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.2.2 SVGs","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"best-practices","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.2.3 Best Practices","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"covariance-correlation-and-regression","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.3 Covariance, Correlation and Regression","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"introducing-the-dataset","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.3.1 Introducing the Dataset","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"pearson-vs.-spearman-not-a-boxing-match","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.3.2 Pearson vs. Spearman (not a Boxing Match)","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"linear-regression","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.3.3 Linear Regression","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"non-linear-least-squares","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.4 Non-linear Least Squares","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"exercises-6","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.5 Exercises","text":"","code":""},{"path":"fallacies-correlation-and-regression.html","id":"the-datasaurus-dozen","chapter":"Lesson 7 Fallacies, Correlation and Regression","heading":"7.5.1 The Datasaurus Dozen","text":"","code":""},{"path":"freestyle.html","id":"freestyle","chapter":"Lesson 8 Freestyle","heading":"Lesson 8 Freestyle","text":"… venture unknown show example data\nanalysis.just notes lecture \nfilled recording.\nCheck back later completed script.","code":""},{"path":"freestyle.html","id":"feedback","chapter":"Lesson 8 Freestyle","heading":"8.1 Feedback","text":"send round link feedback form.\nanonymous.","code":""},{"path":"resources-5.html","id":"resources-5","chapter":"Resources","heading":"Resources","text":"Learning R can quite journey.\ncollecting useful links resources extra page.\nhelp understand topics covered, dive deeper interesting want discover cool things can R.","code":""},{"path":"resources-5.html","id":"learning-the-tidyverse","chapter":"Resources","heading":"8.2 Learning the tidyverse","text":"R Data Science19The ggplot2 bookR4DS online CommunityRStudio Cheat Sheets!Modern Dive20RStudio Education","code":""},{"path":"resources-5.html","id":"learning-rmarkdown","chapter":"Resources","heading":"8.3 Learning Rmarkdown","text":"rmarkdown cheatsheetrmarkdown referencepandoc manual (advanced)rmarkdown reproducible analysisrmarkdown website","code":""},{"path":"resources-5.html","id":"learning-r-in-general","chapter":"Resources","heading":"8.4 Learning R in general","text":"Advanced R21Hands Programming R22R Packages23Data Visualization: Practical Introduction24Graph Cookbook25","code":""},{"path":"resources-5.html","id":"learning-statistics","chapter":"Resources","heading":"8.5 Learning Statistics","text":"Intuitive Biostatistics26Statistics Done Wrong27StatQuest!!! Josh StarnerModern Statistics Modern Biology","code":""},{"path":"resources-5.html","id":"helpful-tools","chapter":"Resources","heading":"8.6 Helpful tools","text":"Generate ggplots via graphical user interface esquisee","code":""},{"path":"resources-5.html","id":"talks-podcasts-blogs-videos","chapter":"Resources","heading":"8.7 Talks, Podcasts, Blogs, Videos","text":"Just people inspiring blogposts, videos likes.David Robinson\nYouTube\nwebsite\nYouTubewebsiteJulia Silge\nYouTube\nwebsite\nYouTubewebsiteAlison Hill\nwebsite\nwebsiteThomas Lin Pedersen\nwebsite\nwebsite","code":""},{"path":"resources-5.html","id":"misc","chapter":"Resources","heading":"8.8 Misc","text":"Cute insightful illustrations28Happy Git R","code":""},{"path":"resources-5.html","id":"package-documentation-1","chapter":"Resources","heading":"8.9 Package Documentation","text":"tidyversetidymodelsrmarkdownreadrdplyrggplottidyrstringrpurrrragg","code":""},{"path":"resources-5.html","id":"books-and-manuals","chapter":"Resources","heading":"8.10 Books and Manuals","text":"Tidymodels bookggplot bookRmarkdown CookbookRmarkdown Book","code":""},{"path":"resources-5.html","id":"getting-help-1","chapter":"Resources","heading":"8.11 Getting Help","text":"find helpR4DS online learning community","code":""},{"path":"resources-5.html","id":"lists-of-resources","chapter":"Resources","heading":"8.12 Lists of Resources","text":"meta section. list lists:big book Rr rest us","code":""},{"path":"resources-5.html","id":"packages-that-enable-this-lecture-format","chapter":"Resources","heading":"8.13 Packages that enable this lecture format","text":"R R Core Team29knitr Yihui Xie30rmarkdown JJ Allaire et al.31xaringan Yihui Xie32","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
